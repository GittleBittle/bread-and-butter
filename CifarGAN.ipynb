{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of CifarGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GittleBittle/bread-and-butter/blob/main/CifarGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJp-D51g0IDd"
      },
      "source": [
        "## **1) Importing Python Packages for GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k5mFBuzzl2a",
        "outputId": "8986941d-deeb-4d08-9a5f-b6c56acb57ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "!mkdir generated_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘generated_images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-eZOzg0X79"
      },
      "source": [
        "## **2) Parameters for Neural Networks & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RThZMDruz9cB",
        "outputId": "2846c8bc-2193-45ca-ffcc-399986dd9379"
      },
      "source": [
        "img_width = 32\n",
        "img_height = 32\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 300\n",
        "adam = Adam(lr=0.0002)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3bcJZZg0cqy"
      },
      "source": [
        "## **3) Building Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdiqZpri0iQh",
        "outputId": "8bf15ffa-fbe0-41cb-e83f-f5d59e4b1ebe"
      },
      "source": [
        "from keras.backend import conv2d\n",
        "from numpy.core.fromnumeric import reshape\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256 * 4 * 4, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((4,4,256)))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add((Conv2D(3, (3,3), activation='tanh', padding='same')))\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "generator = build_generator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 4096)              1232896   \n",
            "                                                                 \n",
            " leaky_re_lu_51 (LeakyReLU)  (None, 4096)              0         \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_27 (Conv2D  (None, 8, 8, 128)        524416    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_52 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_28 (Conv2D  (None, 16, 16, 128)      262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_53 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_29 (Conv2D  (None, 32, 32, 128)      262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_54 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 3)         3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,285,315\n",
            "Trainable params: 2,285,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6QsJCW0mcI"
      },
      "source": [
        "## **4) Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2JzEAPv0lKt",
        "outputId": "74b65df7-280d-487d-ba43-f7eaf048aaad"
      },
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3,3), padding='same', input_shape=img_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(64, (3,3), padding='same', input_shape=img_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, (3,3), padding='same', input_shape=img_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128, (3,3), padding='same', input_shape=img_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(256, (3,3), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(256, (3,3), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(256, (3,3), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " leaky_re_lu_55 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " leaky_re_lu_56 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_57 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " leaky_re_lu_58 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " leaky_re_lu_59 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " leaky_re_lu_60 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " leaky_re_lu_61 (LeakyReLU)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 262144)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 262144)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 262145    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,997,633\n",
            "Trainable params: 1,997,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcKcKmA0q2S"
      },
      "source": [
        "## **5) Connecting Neural Networks to build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ue3TEd0xLy"
      },
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPqU8dZDaQmE"
      },
      "source": [
        "#GAN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaNhBDwRwTG"
      },
      "source": [
        "## **6) Outputting Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEJ0WbjRppy"
      },
      "source": [
        "#@title\n",
        "## **7) Outputting Images**\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 2, 2\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "    # print(\"%.8f\" % save_name)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "    # gen_imgs = gen_imgs * 255\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE57Lk5V0xs2"
      },
      "source": [
        "## **7) Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egSJJvik00Iq",
        "outputId": "adfaf286-9bd0-4830-b56e-6ca7cc5c455b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(epochs, batch_size=64, save_interval=200):\n",
        "  (X_train, _), (_, _) = cifar10.load_data()\n",
        "\n",
        "  # print(X_train.shape)\n",
        "  #Rescale data between -1 and 1\n",
        "  X_train = X_train / 127.5 -1.\n",
        "  bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "  # X_train = np.expand_dims(X_train, axis=3)\n",
        "  # print(X_train.shape)\n",
        "\n",
        "  #Create our Y for our Neural Networks\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for j in range(bat_per_epo):\n",
        "    #Get Random Batch\n",
        "      idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs = X_train[idx]\n",
        "\n",
        "    #Generate Fake Images\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    #Train discriminator\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    \n",
        "    #inverse y label\n",
        "    g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "    print(\"******* %d %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, j, d_loss[0], 100* d_loss[1], g_loss))\n",
        "\n",
        "    if(epoch % save_interval) == 0:\n",
        "      save_imgs(epoch)\n",
        "\n",
        "\n",
        "train(30000, batch_size=64, save_interval=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******* 0 780 [D loss: 0.164041, acc: 92.97%] [G loss: 6.614654]\n",
            "******* 1 780 [D loss: 0.114996, acc: 94.53%] [G loss: 7.548945]\n",
            "******* 2 780 [D loss: 0.115054, acc: 96.09%] [G loss: 6.486835]\n",
            "******* 3 780 [D loss: 0.216823, acc: 89.06%] [G loss: 6.403454]\n",
            "******* 4 780 [D loss: 0.168672, acc: 92.97%] [G loss: 6.212219]\n",
            "******* 5 780 [D loss: 0.134640, acc: 95.31%] [G loss: 7.452126]\n",
            "******* 6 780 [D loss: 0.162966, acc: 93.75%] [G loss: 7.844760]\n",
            "******* 7 780 [D loss: 0.137042, acc: 94.53%] [G loss: 7.259841]\n",
            "******* 8 780 [D loss: 0.158641, acc: 95.31%] [G loss: 7.466525]\n",
            "******* 9 780 [D loss: 0.160528, acc: 96.09%] [G loss: 6.846779]\n",
            "******* 10 780 [D loss: 0.148726, acc: 92.19%] [G loss: 6.480263]\n",
            "******* 11 780 [D loss: 0.208474, acc: 88.28%] [G loss: 8.223677]\n",
            "******* 12 780 [D loss: 0.219742, acc: 90.62%] [G loss: 6.637879]\n",
            "******* 13 780 [D loss: 0.256052, acc: 89.84%] [G loss: 5.693517]\n",
            "******* 14 780 [D loss: 0.396984, acc: 81.25%] [G loss: 5.371883]\n",
            "******* 15 780 [D loss: 0.352204, acc: 82.03%] [G loss: 4.990847]\n",
            "******* 16 780 [D loss: 0.148495, acc: 96.09%] [G loss: 5.173019]\n",
            "******* 17 780 [D loss: 0.267283, acc: 88.28%] [G loss: 5.100327]\n",
            "******* 18 780 [D loss: 0.345348, acc: 89.06%] [G loss: 4.471195]\n",
            "******* 19 780 [D loss: 0.414071, acc: 80.47%] [G loss: 3.476460]\n",
            "******* 20 780 [D loss: 0.330292, acc: 78.91%] [G loss: 3.197938]\n",
            "******* 21 780 [D loss: 0.242034, acc: 91.41%] [G loss: 2.420865]\n",
            "******* 22 780 [D loss: 0.338027, acc: 83.59%] [G loss: 2.210903]\n",
            "******* 23 780 [D loss: 0.277354, acc: 90.62%] [G loss: 2.350704]\n",
            "******* 24 780 [D loss: 0.269518, acc: 88.28%] [G loss: 2.508074]\n",
            "******* 25 780 [D loss: 0.151541, acc: 93.75%] [G loss: 3.483601]\n",
            "******* 26 780 [D loss: 0.226281, acc: 95.31%] [G loss: 4.163450]\n",
            "******* 27 780 [D loss: 0.157658, acc: 94.53%] [G loss: 4.098480]\n",
            "******* 28 780 [D loss: 0.199392, acc: 92.97%] [G loss: 4.188961]\n",
            "******* 29 780 [D loss: 0.117356, acc: 96.88%] [G loss: 3.512897]\n",
            "******* 30 780 [D loss: 0.097940, acc: 97.66%] [G loss: 4.015934]\n",
            "******* 31 780 [D loss: 0.114842, acc: 97.66%] [G loss: 4.072982]\n",
            "******* 32 780 [D loss: 0.102097, acc: 96.88%] [G loss: 5.264824]\n",
            "******* 33 780 [D loss: 0.057110, acc: 98.44%] [G loss: 5.240193]\n",
            "******* 34 780 [D loss: 0.059333, acc: 98.44%] [G loss: 5.298470]\n",
            "******* 35 780 [D loss: 0.064388, acc: 99.22%] [G loss: 5.032657]\n",
            "******* 36 780 [D loss: 0.041644, acc: 99.22%] [G loss: 4.937784]\n",
            "******* 37 780 [D loss: 0.050080, acc: 98.44%] [G loss: 5.037532]\n",
            "******* 38 780 [D loss: 0.040166, acc: 98.44%] [G loss: 5.641115]\n",
            "******* 39 780 [D loss: 0.081894, acc: 96.88%] [G loss: 5.796356]\n",
            "******* 40 780 [D loss: 0.085345, acc: 96.88%] [G loss: 5.545590]\n",
            "******* 41 780 [D loss: 0.025459, acc: 100.00%] [G loss: 5.468565]\n",
            "******* 42 780 [D loss: 0.035423, acc: 98.44%] [G loss: 5.790259]\n",
            "******* 43 780 [D loss: 0.035059, acc: 99.22%] [G loss: 7.200232]\n",
            "******* 44 780 [D loss: 0.057726, acc: 98.44%] [G loss: 7.155363]\n",
            "******* 45 780 [D loss: 0.028518, acc: 100.00%] [G loss: 5.902719]\n",
            "******* 46 780 [D loss: 0.054916, acc: 98.44%] [G loss: 5.785933]\n",
            "******* 47 780 [D loss: 0.031782, acc: 100.00%] [G loss: 6.355510]\n",
            "******* 48 780 [D loss: 0.033518, acc: 100.00%] [G loss: 6.483010]\n",
            "******* 49 780 [D loss: 0.097642, acc: 95.31%] [G loss: 4.353999]\n",
            "******* 50 780 [D loss: 0.130866, acc: 93.75%] [G loss: 6.851880]\n",
            "******* 51 780 [D loss: 0.043627, acc: 98.44%] [G loss: 10.704870]\n",
            "******* 52 780 [D loss: 0.130020, acc: 95.31%] [G loss: 9.946579]\n",
            "******* 53 780 [D loss: 0.107092, acc: 95.31%] [G loss: 6.563439]\n",
            "******* 54 780 [D loss: 0.150424, acc: 94.53%] [G loss: 5.590074]\n",
            "******* 55 780 [D loss: 0.064619, acc: 98.44%] [G loss: 7.430825]\n",
            "******* 56 780 [D loss: 0.113386, acc: 94.53%] [G loss: 6.851325]\n",
            "******* 57 780 [D loss: 0.084626, acc: 98.44%] [G loss: 6.690469]\n",
            "******* 58 780 [D loss: 0.091727, acc: 95.31%] [G loss: 7.198970]\n",
            "******* 59 780 [D loss: 0.151178, acc: 92.97%] [G loss: 7.314973]\n",
            "******* 60 780 [D loss: 0.117788, acc: 96.09%] [G loss: 7.184055]\n",
            "******* 61 780 [D loss: 0.085534, acc: 96.09%] [G loss: 7.110203]\n",
            "******* 62 780 [D loss: 0.115545, acc: 96.09%] [G loss: 6.814538]\n",
            "******* 63 780 [D loss: 0.143367, acc: 94.53%] [G loss: 7.200437]\n",
            "******* 64 780 [D loss: 0.155720, acc: 92.97%] [G loss: 6.625187]\n",
            "******* 65 780 [D loss: 0.166658, acc: 89.84%] [G loss: 6.072442]\n",
            "******* 66 780 [D loss: 0.087397, acc: 96.09%] [G loss: 5.185253]\n",
            "******* 67 780 [D loss: 0.257975, acc: 91.41%] [G loss: 5.242466]\n",
            "******* 68 780 [D loss: 0.113631, acc: 94.53%] [G loss: 6.014928]\n",
            "******* 69 780 [D loss: 0.214401, acc: 92.19%] [G loss: 5.193453]\n",
            "******* 70 780 [D loss: 0.072923, acc: 96.88%] [G loss: 5.469493]\n",
            "******* 71 780 [D loss: 0.221169, acc: 91.41%] [G loss: 5.659816]\n",
            "******* 72 780 [D loss: 0.340729, acc: 88.28%] [G loss: 4.947936]\n",
            "******* 73 780 [D loss: 0.257483, acc: 87.50%] [G loss: 4.251187]\n",
            "******* 74 780 [D loss: 0.197497, acc: 90.62%] [G loss: 4.220309]\n",
            "******* 75 780 [D loss: 0.308399, acc: 88.28%] [G loss: 3.988904]\n",
            "******* 76 780 [D loss: 0.170007, acc: 89.84%] [G loss: 4.620112]\n",
            "******* 77 780 [D loss: 0.152983, acc: 95.31%] [G loss: 4.348650]\n",
            "******* 78 780 [D loss: 0.342854, acc: 82.81%] [G loss: 2.526419]\n",
            "******* 79 780 [D loss: 0.175803, acc: 92.97%] [G loss: 3.068655]\n",
            "******* 80 780 [D loss: 0.179339, acc: 95.31%] [G loss: 3.552026]\n",
            "******* 81 780 [D loss: 0.134174, acc: 96.88%] [G loss: 4.431050]\n",
            "******* 82 780 [D loss: 0.127465, acc: 96.09%] [G loss: 5.294275]\n",
            "******* 83 780 [D loss: 0.128197, acc: 96.09%] [G loss: 4.339191]\n",
            "******* 84 780 [D loss: 0.080263, acc: 98.44%] [G loss: 3.862710]\n",
            "******* 85 780 [D loss: 0.097353, acc: 96.88%] [G loss: 4.174740]\n",
            "******* 86 780 [D loss: 0.090301, acc: 96.88%] [G loss: 3.751105]\n",
            "******* 87 780 [D loss: 0.113552, acc: 96.88%] [G loss: 3.913155]\n",
            "******* 88 780 [D loss: 0.066025, acc: 99.22%] [G loss: 3.731697]\n",
            "******* 89 780 [D loss: 0.107133, acc: 96.09%] [G loss: 3.276267]\n",
            "******* 90 780 [D loss: 0.068647, acc: 100.00%] [G loss: 3.095860]\n",
            "******* 91 780 [D loss: 0.084778, acc: 98.44%] [G loss: 3.228334]\n",
            "******* 92 780 [D loss: 0.102981, acc: 97.66%] [G loss: 3.469064]\n",
            "******* 93 780 [D loss: 0.108861, acc: 96.09%] [G loss: 3.539982]\n",
            "******* 94 780 [D loss: 0.099582, acc: 97.66%] [G loss: 2.937709]\n",
            "******* 95 780 [D loss: 0.107453, acc: 98.44%] [G loss: 3.641159]\n",
            "******* 96 780 [D loss: 0.103721, acc: 96.88%] [G loss: 3.903746]\n",
            "******* 97 780 [D loss: 0.079749, acc: 98.44%] [G loss: 3.944913]\n",
            "******* 98 780 [D loss: 0.131451, acc: 95.31%] [G loss: 3.452248]\n",
            "******* 99 780 [D loss: 0.165306, acc: 96.88%] [G loss: 3.844104]\n",
            "******* 100 780 [D loss: 0.168936, acc: 93.75%] [G loss: 2.884598]\n",
            "******* 101 780 [D loss: 0.153229, acc: 95.31%] [G loss: 3.375303]\n",
            "******* 102 780 [D loss: 0.165219, acc: 92.19%] [G loss: 4.088091]\n",
            "******* 103 780 [D loss: 0.356488, acc: 85.94%] [G loss: 2.534976]\n",
            "******* 104 780 [D loss: 0.295889, acc: 86.72%] [G loss: 4.252355]\n",
            "******* 105 780 [D loss: 0.435520, acc: 82.81%] [G loss: 5.316172]\n",
            "******* 106 780 [D loss: 0.251331, acc: 89.06%] [G loss: 4.597331]\n",
            "******* 107 780 [D loss: 0.326287, acc: 86.72%] [G loss: 2.449095]\n",
            "******* 108 780 [D loss: 0.368147, acc: 83.59%] [G loss: 3.557240]\n",
            "******* 109 780 [D loss: 0.149627, acc: 92.97%] [G loss: 4.582673]\n",
            "******* 110 780 [D loss: 0.385351, acc: 85.94%] [G loss: 4.785584]\n",
            "******* 111 780 [D loss: 0.390977, acc: 82.03%] [G loss: 3.778722]\n",
            "******* 112 780 [D loss: 0.378706, acc: 82.03%] [G loss: 3.374167]\n",
            "******* 113 780 [D loss: 0.242717, acc: 88.28%] [G loss: 2.895545]\n",
            "******* 114 780 [D loss: 0.280799, acc: 89.06%] [G loss: 2.501606]\n",
            "******* 115 780 [D loss: 0.154608, acc: 96.09%] [G loss: 2.410511]\n",
            "******* 116 780 [D loss: 0.215442, acc: 90.62%] [G loss: 2.502839]\n",
            "******* 117 780 [D loss: 0.254167, acc: 92.19%] [G loss: 2.429159]\n",
            "******* 118 780 [D loss: 0.091897, acc: 99.22%] [G loss: 3.025133]\n",
            "******* 119 780 [D loss: 0.144960, acc: 96.09%] [G loss: 3.273915]\n",
            "******* 120 780 [D loss: 0.241214, acc: 92.19%] [G loss: 3.062693]\n",
            "******* 121 780 [D loss: 0.143234, acc: 97.66%] [G loss: 2.803038]\n",
            "******* 122 780 [D loss: 0.184170, acc: 92.19%] [G loss: 3.577411]\n",
            "******* 123 780 [D loss: 0.095714, acc: 96.88%] [G loss: 4.486938]\n",
            "******* 124 780 [D loss: 0.155417, acc: 94.53%] [G loss: 4.545278]\n",
            "******* 125 780 [D loss: 0.181111, acc: 95.31%] [G loss: 3.485357]\n",
            "******* 126 780 [D loss: 0.148500, acc: 93.75%] [G loss: 3.404917]\n",
            "******* 127 780 [D loss: 0.192333, acc: 91.41%] [G loss: 3.499446]\n",
            "******* 128 780 [D loss: 0.283814, acc: 89.84%] [G loss: 3.846507]\n",
            "******* 129 780 [D loss: 0.315215, acc: 87.50%] [G loss: 3.236391]\n",
            "******* 130 780 [D loss: 0.359681, acc: 85.16%] [G loss: 3.637311]\n",
            "******* 131 780 [D loss: 0.141977, acc: 93.75%] [G loss: 4.909480]\n",
            "******* 132 780 [D loss: 0.237375, acc: 89.84%] [G loss: 4.618789]\n",
            "******* 133 780 [D loss: 0.207342, acc: 94.53%] [G loss: 4.083600]\n",
            "******* 134 780 [D loss: 0.176681, acc: 92.97%] [G loss: 4.481379]\n",
            "******* 135 780 [D loss: 0.145477, acc: 92.97%] [G loss: 4.328606]\n",
            "******* 136 780 [D loss: 0.128761, acc: 95.31%] [G loss: 4.927119]\n",
            "******* 137 780 [D loss: 0.059691, acc: 98.44%] [G loss: 5.154783]\n",
            "******* 138 780 [D loss: 0.071975, acc: 98.44%] [G loss: 4.829991]\n",
            "******* 139 780 [D loss: 0.116102, acc: 96.09%] [G loss: 4.258469]\n",
            "******* 140 780 [D loss: 0.115305, acc: 96.88%] [G loss: 3.840708]\n",
            "******* 141 780 [D loss: 0.100053, acc: 96.88%] [G loss: 4.558853]\n",
            "******* 142 780 [D loss: 0.054063, acc: 98.44%] [G loss: 5.104429]\n",
            "******* 143 780 [D loss: 0.093127, acc: 95.31%] [G loss: 5.617319]\n",
            "******* 144 780 [D loss: 0.059641, acc: 97.66%] [G loss: 5.818344]\n",
            "******* 145 780 [D loss: 0.060649, acc: 98.44%] [G loss: 6.866104]\n",
            "******* 146 780 [D loss: 0.054688, acc: 97.66%] [G loss: 6.632281]\n",
            "******* 147 780 [D loss: 0.049558, acc: 98.44%] [G loss: 5.631807]\n",
            "******* 148 780 [D loss: 0.161052, acc: 94.53%] [G loss: 6.253042]\n",
            "******* 149 780 [D loss: 0.075538, acc: 96.88%] [G loss: 7.579501]\n",
            "******* 150 780 [D loss: 0.097424, acc: 96.88%] [G loss: 7.268619]\n",
            "******* 151 780 [D loss: 0.086905, acc: 95.31%] [G loss: 7.342990]\n",
            "******* 152 780 [D loss: 0.011817, acc: 100.00%] [G loss: 8.386728]\n",
            "******* 153 780 [D loss: 0.074260, acc: 97.66%] [G loss: 9.298788]\n",
            "******* 154 780 [D loss: 0.146584, acc: 95.31%] [G loss: 7.234130]\n",
            "******* 155 780 [D loss: 0.287380, acc: 88.28%] [G loss: 8.437668]\n",
            "******* 156 780 [D loss: 0.150637, acc: 96.09%] [G loss: 9.496046]\n",
            "******* 157 780 [D loss: 0.753510, acc: 78.12%] [G loss: 16.315992]\n",
            "******* 158 780 [D loss: 2.464793, acc: 75.78%] [G loss: 16.932068]\n",
            "******* 159 780 [D loss: 1.868342, acc: 75.00%] [G loss: 11.454432]\n",
            "******* 160 780 [D loss: 0.687198, acc: 82.03%] [G loss: 5.656022]\n",
            "******* 161 780 [D loss: 0.477229, acc: 77.34%] [G loss: 3.240163]\n",
            "******* 162 780 [D loss: 0.594159, acc: 82.03%] [G loss: 5.331358]\n",
            "******* 163 780 [D loss: 0.287962, acc: 88.28%] [G loss: 5.753353]\n",
            "******* 164 780 [D loss: 0.364347, acc: 87.50%] [G loss: 3.789916]\n",
            "******* 165 780 [D loss: 0.228168, acc: 92.97%] [G loss: 2.126472]\n",
            "******* 166 780 [D loss: 0.386953, acc: 89.06%] [G loss: 2.003352]\n",
            "******* 167 780 [D loss: 0.194593, acc: 92.19%] [G loss: 3.583751]\n",
            "******* 168 780 [D loss: 0.193406, acc: 94.53%] [G loss: 4.011621]\n",
            "******* 169 780 [D loss: 0.289961, acc: 87.50%] [G loss: 3.685732]\n",
            "******* 170 780 [D loss: 0.203457, acc: 90.62%] [G loss: 2.581257]\n",
            "******* 171 780 [D loss: 0.190229, acc: 95.31%] [G loss: 2.420084]\n",
            "******* 172 780 [D loss: 0.257208, acc: 82.03%] [G loss: 2.612325]\n",
            "******* 173 780 [D loss: 0.128703, acc: 98.44%] [G loss: 3.009258]\n",
            "******* 174 780 [D loss: 0.104734, acc: 98.44%] [G loss: 3.457761]\n",
            "******* 175 780 [D loss: 0.153517, acc: 93.75%] [G loss: 3.180414]\n",
            "******* 176 780 [D loss: 0.211270, acc: 92.19%] [G loss: 2.840285]\n",
            "******* 177 780 [D loss: 0.299753, acc: 85.16%] [G loss: 2.242707]\n",
            "******* 178 780 [D loss: 0.473772, acc: 82.81%] [G loss: 3.301402]\n",
            "******* 179 780 [D loss: 0.282116, acc: 90.62%] [G loss: 5.080660]\n",
            "******* 180 780 [D loss: 0.251477, acc: 91.41%] [G loss: 5.270251]\n",
            "******* 181 780 [D loss: 0.255659, acc: 89.84%] [G loss: 5.918653]\n",
            "******* 182 780 [D loss: 0.257157, acc: 90.62%] [G loss: 6.238723]\n",
            "******* 183 780 [D loss: 0.171543, acc: 92.97%] [G loss: 5.585984]\n",
            "******* 184 780 [D loss: 0.154911, acc: 93.75%] [G loss: 5.315323]\n",
            "******* 185 780 [D loss: 0.125522, acc: 96.09%] [G loss: 5.259693]\n",
            "******* 186 780 [D loss: 0.109365, acc: 96.88%] [G loss: 4.563479]\n",
            "******* 187 780 [D loss: 0.120194, acc: 93.75%] [G loss: 3.203689]\n",
            "******* 188 780 [D loss: 0.182047, acc: 91.41%] [G loss: 3.388594]\n",
            "******* 189 780 [D loss: 0.145128, acc: 95.31%] [G loss: 3.828910]\n",
            "******* 190 780 [D loss: 0.218642, acc: 93.75%] [G loss: 3.408308]\n",
            "******* 191 780 [D loss: 0.122873, acc: 96.88%] [G loss: 3.264236]\n",
            "******* 192 780 [D loss: 0.117859, acc: 96.09%] [G loss: 3.581120]\n",
            "******* 193 780 [D loss: 0.115893, acc: 93.75%] [G loss: 4.007503]\n",
            "******* 194 780 [D loss: 0.244016, acc: 89.06%] [G loss: 4.366166]\n",
            "******* 195 780 [D loss: 0.226790, acc: 92.97%] [G loss: 4.378499]\n",
            "******* 196 780 [D loss: 0.119666, acc: 94.53%] [G loss: 3.649772]\n",
            "******* 197 780 [D loss: 0.178554, acc: 93.75%] [G loss: 3.421081]\n",
            "******* 198 780 [D loss: 0.152084, acc: 93.75%] [G loss: 3.671123]\n",
            "******* 199 780 [D loss: 0.070640, acc: 98.44%] [G loss: 4.433141]\n",
            "******* 200 780 [D loss: 0.105198, acc: 96.09%] [G loss: 3.799014]\n",
            "******* 201 780 [D loss: 0.109148, acc: 96.09%] [G loss: 3.773418]\n",
            "******* 202 780 [D loss: 0.083417, acc: 97.66%] [G loss: 3.695562]\n",
            "******* 203 780 [D loss: 0.062451, acc: 98.44%] [G loss: 4.238174]\n",
            "******* 204 780 [D loss: 0.085136, acc: 96.88%] [G loss: 4.490439]\n",
            "******* 205 780 [D loss: 0.045565, acc: 99.22%] [G loss: 4.590127]\n",
            "******* 206 780 [D loss: 0.235223, acc: 89.06%] [G loss: 3.552716]\n",
            "******* 207 780 [D loss: 0.221263, acc: 92.19%] [G loss: 3.766528]\n",
            "******* 208 780 [D loss: 0.113114, acc: 96.09%] [G loss: 5.548037]\n",
            "******* 209 780 [D loss: 0.205595, acc: 94.53%] [G loss: 4.695379]\n",
            "******* 210 780 [D loss: 0.194318, acc: 93.75%] [G loss: 4.433640]\n",
            "******* 211 780 [D loss: 0.275164, acc: 84.38%] [G loss: 5.718445]\n",
            "******* 212 780 [D loss: 0.203500, acc: 90.62%] [G loss: 6.549933]\n",
            "******* 213 780 [D loss: 0.444235, acc: 86.72%] [G loss: 5.050063]\n",
            "******* 214 780 [D loss: 0.461037, acc: 84.38%] [G loss: 4.595483]\n",
            "******* 215 780 [D loss: 0.281744, acc: 89.84%] [G loss: 5.603609]\n",
            "******* 216 780 [D loss: 0.500240, acc: 88.28%] [G loss: 4.745898]\n",
            "******* 217 780 [D loss: 0.572914, acc: 83.59%] [G loss: 3.347379]\n",
            "******* 218 780 [D loss: 0.641676, acc: 76.56%] [G loss: 3.017929]\n",
            "******* 219 780 [D loss: 0.350008, acc: 88.28%] [G loss: 3.853943]\n",
            "******* 220 780 [D loss: 0.374406, acc: 79.69%] [G loss: 3.519711]\n",
            "******* 221 780 [D loss: 0.328478, acc: 85.16%] [G loss: 2.554796]\n",
            "******* 222 780 [D loss: 0.259234, acc: 88.28%] [G loss: 2.411164]\n",
            "******* 223 780 [D loss: 0.288464, acc: 89.84%] [G loss: 2.335221]\n",
            "******* 224 780 [D loss: 0.176342, acc: 96.09%] [G loss: 2.582641]\n",
            "******* 225 780 [D loss: 0.134985, acc: 96.09%] [G loss: 2.892588]\n",
            "******* 226 780 [D loss: 0.145178, acc: 96.09%] [G loss: 3.241190]\n",
            "******* 227 780 [D loss: 0.137205, acc: 94.53%] [G loss: 3.055396]\n",
            "******* 228 780 [D loss: 0.248032, acc: 93.75%] [G loss: 2.521277]\n",
            "******* 229 780 [D loss: 0.114792, acc: 98.44%] [G loss: 2.928795]\n",
            "******* 230 780 [D loss: 0.069509, acc: 99.22%] [G loss: 3.270142]\n",
            "******* 231 780 [D loss: 0.147123, acc: 94.53%] [G loss: 3.374922]\n",
            "******* 232 780 [D loss: 0.333202, acc: 88.28%] [G loss: 2.830184]\n",
            "******* 233 780 [D loss: 0.227674, acc: 89.84%] [G loss: 3.521451]\n",
            "******* 234 780 [D loss: 0.254640, acc: 87.50%] [G loss: 4.632192]\n",
            "******* 235 780 [D loss: 0.226911, acc: 91.41%] [G loss: 3.900221]\n",
            "******* 236 780 [D loss: 0.165839, acc: 94.53%] [G loss: 3.753328]\n",
            "******* 237 780 [D loss: 0.186328, acc: 92.97%] [G loss: 3.859623]\n",
            "******* 238 780 [D loss: 0.091324, acc: 96.09%] [G loss: 4.473198]\n",
            "******* 239 780 [D loss: 0.140866, acc: 96.09%] [G loss: 4.523256]\n",
            "******* 240 780 [D loss: 0.215230, acc: 92.97%] [G loss: 4.458268]\n",
            "******* 241 780 [D loss: 0.191659, acc: 93.75%] [G loss: 3.773379]\n",
            "******* 242 780 [D loss: 0.134088, acc: 96.09%] [G loss: 3.835715]\n",
            "******* 243 780 [D loss: 0.412530, acc: 85.16%] [G loss: 3.501916]\n",
            "******* 244 780 [D loss: 0.282758, acc: 89.06%] [G loss: 3.703617]\n",
            "******* 245 780 [D loss: 0.276496, acc: 89.84%] [G loss: 4.027822]\n",
            "******* 246 780 [D loss: 0.271291, acc: 89.06%] [G loss: 3.327952]\n",
            "******* 247 780 [D loss: 0.262402, acc: 88.28%] [G loss: 2.477144]\n",
            "******* 248 780 [D loss: 0.306592, acc: 85.16%] [G loss: 3.061822]\n",
            "******* 249 780 [D loss: 0.179969, acc: 96.09%] [G loss: 3.549445]\n",
            "******* 250 780 [D loss: 0.345270, acc: 82.03%] [G loss: 3.335765]\n",
            "******* 251 780 [D loss: 0.271022, acc: 87.50%] [G loss: 2.894559]\n",
            "******* 252 780 [D loss: 0.208833, acc: 93.75%] [G loss: 2.332531]\n",
            "******* 253 780 [D loss: 0.205793, acc: 92.19%] [G loss: 2.733322]\n",
            "******* 254 780 [D loss: 0.152114, acc: 95.31%] [G loss: 3.864129]\n",
            "******* 255 780 [D loss: 0.200930, acc: 93.75%] [G loss: 4.157446]\n",
            "******* 256 780 [D loss: 0.141478, acc: 93.75%] [G loss: 3.801175]\n",
            "******* 257 780 [D loss: 0.232927, acc: 92.19%] [G loss: 3.037781]\n",
            "******* 258 780 [D loss: 0.151747, acc: 96.88%] [G loss: 3.688037]\n",
            "******* 259 780 [D loss: 0.108638, acc: 96.09%] [G loss: 4.079263]\n",
            "******* 260 780 [D loss: 0.204041, acc: 92.19%] [G loss: 3.871532]\n",
            "******* 261 780 [D loss: 0.317036, acc: 84.38%] [G loss: 4.168687]\n",
            "******* 262 780 [D loss: 0.113619, acc: 97.66%] [G loss: 4.211477]\n",
            "******* 263 780 [D loss: 0.134605, acc: 96.09%] [G loss: 5.114106]\n",
            "******* 264 780 [D loss: 0.072843, acc: 96.09%] [G loss: 5.716454]\n",
            "******* 265 780 [D loss: 0.192919, acc: 92.19%] [G loss: 4.024220]\n",
            "******* 266 780 [D loss: 0.418117, acc: 82.81%] [G loss: 3.781274]\n",
            "******* 267 780 [D loss: 0.328285, acc: 86.72%] [G loss: 4.333961]\n",
            "******* 268 780 [D loss: 0.240086, acc: 91.41%] [G loss: 4.901961]\n",
            "******* 269 780 [D loss: 0.354445, acc: 88.28%] [G loss: 4.455250]\n",
            "******* 270 780 [D loss: 0.542591, acc: 78.12%] [G loss: 5.013383]\n",
            "******* 271 780 [D loss: 0.717288, acc: 74.22%] [G loss: 4.756415]\n",
            "******* 272 780 [D loss: 0.659384, acc: 75.78%] [G loss: 3.088423]\n",
            "******* 273 780 [D loss: 0.730990, acc: 76.56%] [G loss: 2.190564]\n",
            "******* 274 780 [D loss: 0.356203, acc: 83.59%] [G loss: 3.100103]\n",
            "******* 275 780 [D loss: 0.259522, acc: 89.84%] [G loss: 3.664475]\n",
            "******* 276 780 [D loss: 0.350724, acc: 88.28%] [G loss: 3.174390]\n",
            "******* 277 780 [D loss: 0.216433, acc: 92.97%] [G loss: 3.330550]\n",
            "******* 278 780 [D loss: 0.325019, acc: 88.28%] [G loss: 3.586149]\n",
            "******* 279 780 [D loss: 0.597002, acc: 81.25%] [G loss: 2.768989]\n",
            "******* 280 780 [D loss: 0.303626, acc: 85.16%] [G loss: 2.538604]\n",
            "******* 281 780 [D loss: 0.192126, acc: 91.41%] [G loss: 2.955925]\n",
            "******* 282 780 [D loss: 0.161150, acc: 91.41%] [G loss: 3.650704]\n",
            "******* 283 780 [D loss: 0.114117, acc: 97.66%] [G loss: 3.321706]\n",
            "******* 284 780 [D loss: 0.110709, acc: 97.66%] [G loss: 3.799381]\n",
            "******* 285 780 [D loss: 0.175238, acc: 92.97%] [G loss: 3.227278]\n",
            "******* 286 780 [D loss: 0.098617, acc: 98.44%] [G loss: 3.468832]\n",
            "******* 287 780 [D loss: 0.043998, acc: 100.00%] [G loss: 3.859774]\n",
            "******* 288 780 [D loss: 0.038054, acc: 100.00%] [G loss: 4.550303]\n",
            "******* 289 780 [D loss: 0.064760, acc: 97.66%] [G loss: 4.780319]\n",
            "******* 290 780 [D loss: 0.084460, acc: 95.31%] [G loss: 4.284469]\n",
            "******* 291 780 [D loss: 0.045044, acc: 100.00%] [G loss: 3.971895]\n",
            "******* 292 780 [D loss: 0.095435, acc: 97.66%] [G loss: 3.683929]\n",
            "******* 293 780 [D loss: 0.064665, acc: 99.22%] [G loss: 4.735903]\n",
            "******* 294 780 [D loss: 0.054224, acc: 99.22%] [G loss: 5.504987]\n",
            "******* 295 780 [D loss: 0.137188, acc: 95.31%] [G loss: 6.039646]\n",
            "******* 296 780 [D loss: 0.057521, acc: 98.44%] [G loss: 5.596747]\n",
            "******* 297 780 [D loss: 0.068726, acc: 96.88%] [G loss: 4.242170]\n",
            "******* 298 780 [D loss: 0.111680, acc: 98.44%] [G loss: 5.066642]\n",
            "******* 299 780 [D loss: 0.162338, acc: 92.97%] [G loss: 5.728397]\n",
            "******* 300 780 [D loss: 0.254136, acc: 91.41%] [G loss: 4.318871]\n",
            "******* 301 780 [D loss: 0.173255, acc: 92.19%] [G loss: 4.263245]\n",
            "******* 302 780 [D loss: 0.120028, acc: 96.09%] [G loss: 4.854199]\n",
            "******* 303 780 [D loss: 0.161563, acc: 92.97%] [G loss: 6.182044]\n",
            "******* 304 780 [D loss: 0.242982, acc: 90.62%] [G loss: 4.425464]\n",
            "******* 305 780 [D loss: 0.271741, acc: 90.62%] [G loss: 3.911563]\n",
            "******* 306 780 [D loss: 0.072586, acc: 97.66%] [G loss: 5.126060]\n",
            "******* 307 780 [D loss: 0.085631, acc: 97.66%] [G loss: 6.754290]\n",
            "******* 308 780 [D loss: 0.082753, acc: 97.66%] [G loss: 6.294945]\n",
            "******* 309 780 [D loss: 0.041246, acc: 99.22%] [G loss: 6.808093]\n",
            "******* 310 780 [D loss: 0.038332, acc: 99.22%] [G loss: 7.162725]\n",
            "******* 311 780 [D loss: 0.012936, acc: 100.00%] [G loss: 8.074027]\n",
            "******* 312 780 [D loss: 0.039705, acc: 98.44%] [G loss: 8.996180]\n",
            "******* 313 780 [D loss: 0.025984, acc: 100.00%] [G loss: 8.739149]\n",
            "******* 314 780 [D loss: 0.116244, acc: 95.31%] [G loss: 11.223301]\n",
            "******* 315 780 [D loss: 0.060928, acc: 98.44%] [G loss: 10.268950]\n",
            "******* 316 780 [D loss: 0.109771, acc: 96.88%] [G loss: 9.724515]\n",
            "******* 317 780 [D loss: 0.055108, acc: 96.88%] [G loss: 8.051684]\n",
            "******* 318 780 [D loss: 0.067778, acc: 96.88%] [G loss: 9.338346]\n",
            "******* 319 780 [D loss: 0.054960, acc: 98.44%] [G loss: 9.469178]\n",
            "******* 320 780 [D loss: 0.022199, acc: 98.44%] [G loss: 9.045641]\n",
            "******* 321 780 [D loss: 0.017129, acc: 99.22%] [G loss: 8.591418]\n",
            "******* 322 780 [D loss: 0.050881, acc: 97.66%] [G loss: 11.078447]\n",
            "******* 323 780 [D loss: 0.067363, acc: 96.88%] [G loss: 12.834393]\n",
            "******* 324 780 [D loss: 0.097091, acc: 96.88%] [G loss: 12.384817]\n",
            "******* 325 780 [D loss: 0.056996, acc: 98.44%] [G loss: 11.526719]\n",
            "******* 326 780 [D loss: 0.068951, acc: 97.66%] [G loss: 9.348514]\n",
            "******* 327 780 [D loss: 0.077567, acc: 95.31%] [G loss: 7.007254]\n",
            "******* 328 780 [D loss: 0.103597, acc: 95.31%] [G loss: 8.292788]\n",
            "******* 329 780 [D loss: 0.062021, acc: 97.66%] [G loss: 12.420094]\n",
            "******* 330 780 [D loss: 0.150151, acc: 96.09%] [G loss: 11.863608]\n",
            "******* 331 780 [D loss: 0.056137, acc: 97.66%] [G loss: 10.784349]\n",
            "******* 332 780 [D loss: 0.067448, acc: 97.66%] [G loss: 8.903603]\n",
            "******* 333 780 [D loss: 0.021848, acc: 99.22%] [G loss: 7.998234]\n",
            "******* 334 780 [D loss: 0.066706, acc: 98.44%] [G loss: 7.653280]\n",
            "******* 335 780 [D loss: 0.046100, acc: 99.22%] [G loss: 6.927906]\n",
            "******* 336 780 [D loss: 0.049962, acc: 97.66%] [G loss: 6.993858]\n",
            "******* 337 780 [D loss: 0.053110, acc: 98.44%] [G loss: 7.767423]\n",
            "******* 338 780 [D loss: 0.086428, acc: 96.88%] [G loss: 7.776811]\n",
            "******* 339 780 [D loss: 0.108865, acc: 97.66%] [G loss: 8.218878]\n",
            "******* 340 780 [D loss: 0.108951, acc: 96.88%] [G loss: 7.257308]\n",
            "******* 341 780 [D loss: 0.144418, acc: 95.31%] [G loss: 6.212233]\n",
            "******* 342 780 [D loss: 0.099736, acc: 95.31%] [G loss: 6.776960]\n",
            "******* 343 780 [D loss: 0.106270, acc: 95.31%] [G loss: 8.290619]\n",
            "******* 344 780 [D loss: 0.073986, acc: 98.44%] [G loss: 9.938822]\n",
            "******* 345 780 [D loss: 0.051477, acc: 98.44%] [G loss: 12.289471]\n",
            "******* 346 780 [D loss: 0.087224, acc: 96.88%] [G loss: 11.814518]\n",
            "******* 347 780 [D loss: 0.181392, acc: 92.19%] [G loss: 11.785503]\n",
            "******* 348 780 [D loss: 0.154182, acc: 93.75%] [G loss: 12.342710]\n",
            "******* 349 780 [D loss: 0.080851, acc: 97.66%] [G loss: 14.884394]\n",
            "******* 350 780 [D loss: 0.102892, acc: 97.66%] [G loss: 18.877892]\n",
            "******* 351 780 [D loss: 0.198130, acc: 92.97%] [G loss: 16.023659]\n",
            "******* 352 780 [D loss: 0.145149, acc: 96.09%] [G loss: 11.557498]\n",
            "******* 353 780 [D loss: 0.111900, acc: 96.09%] [G loss: 8.827032]\n",
            "******* 354 780 [D loss: 0.056936, acc: 96.88%] [G loss: 6.639694]\n",
            "******* 355 780 [D loss: 0.033563, acc: 99.22%] [G loss: 7.722795]\n",
            "******* 356 780 [D loss: 0.054521, acc: 98.44%] [G loss: 7.512989]\n",
            "******* 357 780 [D loss: 0.042207, acc: 98.44%] [G loss: 8.693820]\n",
            "******* 358 780 [D loss: 0.047764, acc: 99.22%] [G loss: 9.685919]\n",
            "******* 359 780 [D loss: 0.366212, acc: 92.97%] [G loss: 5.626276]\n",
            "******* 360 780 [D loss: 0.036947, acc: 99.22%] [G loss: 7.610795]\n",
            "******* 361 780 [D loss: 0.106014, acc: 96.88%] [G loss: 6.631981]\n",
            "******* 362 780 [D loss: 0.456184, acc: 86.72%] [G loss: 13.836851]\n",
            "******* 363 780 [D loss: 0.241046, acc: 93.75%] [G loss: 26.671677]\n",
            "******* 364 780 [D loss: 1.131592, acc: 82.03%] [G loss: 19.419018]\n",
            "******* 365 780 [D loss: 1.285738, acc: 81.25%] [G loss: 9.225538]\n",
            "******* 366 780 [D loss: 0.175745, acc: 95.31%] [G loss: 5.336362]\n",
            "******* 367 780 [D loss: 0.340923, acc: 89.84%] [G loss: 2.768191]\n",
            "******* 368 780 [D loss: 0.374799, acc: 88.28%] [G loss: 2.907364]\n",
            "******* 369 780 [D loss: 0.302149, acc: 87.50%] [G loss: 3.410485]\n",
            "******* 370 780 [D loss: 0.199781, acc: 90.62%] [G loss: 3.173484]\n",
            "******* 371 780 [D loss: 0.209223, acc: 90.62%] [G loss: 3.282967]\n",
            "******* 372 780 [D loss: 0.254607, acc: 86.72%] [G loss: 3.552014]\n",
            "******* 373 780 [D loss: 0.178819, acc: 91.41%] [G loss: 4.283790]\n",
            "******* 374 780 [D loss: 0.193354, acc: 92.97%] [G loss: 4.380733]\n",
            "******* 375 780 [D loss: 0.159067, acc: 93.75%] [G loss: 4.214301]\n",
            "******* 376 780 [D loss: 0.152880, acc: 96.88%] [G loss: 3.308566]\n",
            "******* 377 780 [D loss: 0.155598, acc: 96.09%] [G loss: 3.307966]\n",
            "******* 378 780 [D loss: 0.136168, acc: 96.88%] [G loss: 3.316566]\n",
            "******* 379 780 [D loss: 0.132498, acc: 97.66%] [G loss: 3.178695]\n",
            "******* 380 780 [D loss: 0.152309, acc: 95.31%] [G loss: 3.309304]\n",
            "******* 381 780 [D loss: 0.129256, acc: 96.09%] [G loss: 3.269639]\n",
            "******* 382 780 [D loss: 0.121713, acc: 96.88%] [G loss: 3.629966]\n",
            "******* 383 780 [D loss: 0.167213, acc: 96.09%] [G loss: 3.758324]\n",
            "******* 384 780 [D loss: 0.144785, acc: 96.88%] [G loss: 4.089991]\n",
            "******* 385 780 [D loss: 0.111403, acc: 96.88%] [G loss: 4.180905]\n",
            "******* 386 780 [D loss: 0.085068, acc: 98.44%] [G loss: 4.364982]\n",
            "******* 387 780 [D loss: 0.067006, acc: 98.44%] [G loss: 4.767212]\n",
            "******* 388 780 [D loss: 0.146793, acc: 93.75%] [G loss: 5.344465]\n",
            "******* 389 780 [D loss: 0.118506, acc: 94.53%] [G loss: 6.889643]\n",
            "******* 390 780 [D loss: 0.062361, acc: 99.22%] [G loss: 7.410438]\n",
            "******* 391 780 [D loss: 0.078048, acc: 98.44%] [G loss: 7.843667]\n",
            "******* 392 780 [D loss: 0.072131, acc: 99.22%] [G loss: 6.131526]\n",
            "******* 393 780 [D loss: 0.137704, acc: 96.09%] [G loss: 4.158928]\n",
            "******* 394 780 [D loss: 0.122478, acc: 98.44%] [G loss: 4.626102]\n",
            "******* 395 780 [D loss: 0.123017, acc: 93.75%] [G loss: 5.956077]\n",
            "******* 396 780 [D loss: 0.122451, acc: 95.31%] [G loss: 7.646269]\n",
            "******* 397 780 [D loss: 0.192083, acc: 92.19%] [G loss: 6.346292]\n",
            "******* 398 780 [D loss: 0.131338, acc: 96.09%] [G loss: 4.684564]\n",
            "******* 399 780 [D loss: 0.095657, acc: 97.66%] [G loss: 5.364810]\n",
            "******* 400 780 [D loss: 0.040187, acc: 98.44%] [G loss: 6.014668]\n",
            "******* 401 780 [D loss: 0.044424, acc: 98.44%] [G loss: 6.095623]\n",
            "******* 402 780 [D loss: 0.069391, acc: 97.66%] [G loss: 6.193094]\n",
            "******* 403 780 [D loss: 0.041329, acc: 97.66%] [G loss: 6.224136]\n",
            "******* 404 780 [D loss: 0.027347, acc: 99.22%] [G loss: 6.301824]\n",
            "******* 405 780 [D loss: 0.041355, acc: 98.44%] [G loss: 6.667862]\n",
            "******* 406 780 [D loss: 0.037782, acc: 99.22%] [G loss: 8.191076]\n",
            "******* 407 780 [D loss: 0.038102, acc: 98.44%] [G loss: 9.086100]\n",
            "******* 408 780 [D loss: 0.029989, acc: 98.44%] [G loss: 7.157958]\n",
            "******* 409 780 [D loss: 0.043631, acc: 100.00%] [G loss: 5.852261]\n",
            "******* 410 780 [D loss: 0.074697, acc: 98.44%] [G loss: 5.822753]\n",
            "******* 411 780 [D loss: 0.106056, acc: 98.44%] [G loss: 5.224246]\n",
            "******* 412 780 [D loss: 0.036877, acc: 99.22%] [G loss: 5.649727]\n",
            "******* 413 780 [D loss: 0.046946, acc: 99.22%] [G loss: 6.773640]\n",
            "******* 414 780 [D loss: 0.038721, acc: 99.22%] [G loss: 6.970042]\n",
            "******* 415 780 [D loss: 0.083008, acc: 96.88%] [G loss: 6.044526]\n",
            "******* 416 780 [D loss: 0.063236, acc: 96.88%] [G loss: 6.191709]\n",
            "******* 417 780 [D loss: 0.038247, acc: 97.66%] [G loss: 7.047299]\n",
            "******* 418 780 [D loss: 0.037056, acc: 98.44%] [G loss: 7.783056]\n",
            "******* 419 780 [D loss: 0.111137, acc: 96.88%] [G loss: 7.346280]\n",
            "******* 420 780 [D loss: 0.022541, acc: 100.00%] [G loss: 7.639122]\n",
            "******* 421 780 [D loss: 0.053165, acc: 97.66%] [G loss: 7.385161]\n",
            "******* 422 780 [D loss: 0.059918, acc: 97.66%] [G loss: 6.273275]\n",
            "******* 423 780 [D loss: 0.021527, acc: 100.00%] [G loss: 6.242601]\n",
            "******* 424 780 [D loss: 0.067459, acc: 97.66%] [G loss: 6.553514]\n",
            "******* 425 780 [D loss: 0.032843, acc: 99.22%] [G loss: 8.948993]\n",
            "******* 426 780 [D loss: 0.033017, acc: 99.22%] [G loss: 9.388494]\n",
            "******* 427 780 [D loss: 0.038810, acc: 98.44%] [G loss: 9.792434]\n",
            "******* 428 780 [D loss: 0.166989, acc: 95.31%] [G loss: 8.495789]\n",
            "******* 429 780 [D loss: 0.205642, acc: 92.19%] [G loss: 7.916652]\n",
            "******* 430 780 [D loss: 0.143926, acc: 96.09%] [G loss: 11.057607]\n",
            "******* 431 780 [D loss: 0.540519, acc: 87.50%] [G loss: 7.849535]\n",
            "******* 432 780 [D loss: 0.432324, acc: 83.59%] [G loss: 7.037064]\n",
            "******* 433 780 [D loss: 0.216709, acc: 92.19%] [G loss: 6.515347]\n",
            "******* 434 780 [D loss: 0.102527, acc: 98.44%] [G loss: 8.176842]\n",
            "******* 435 780 [D loss: 0.130111, acc: 96.88%] [G loss: 8.094005]\n",
            "******* 436 780 [D loss: 0.125379, acc: 95.31%] [G loss: 5.454404]\n",
            "******* 437 780 [D loss: 0.220326, acc: 90.62%] [G loss: 4.727118]\n",
            "******* 438 780 [D loss: 0.200311, acc: 92.19%] [G loss: 4.650155]\n",
            "******* 439 780 [D loss: 0.121126, acc: 96.09%] [G loss: 6.451221]\n",
            "******* 440 780 [D loss: 0.257953, acc: 89.84%] [G loss: 5.750076]\n",
            "******* 441 780 [D loss: 0.152417, acc: 93.75%] [G loss: 7.104930]\n",
            "******* 442 780 [D loss: 0.129254, acc: 96.09%] [G loss: 5.506964]\n",
            "******* 443 780 [D loss: 0.164400, acc: 92.97%] [G loss: 4.749578]\n",
            "******* 444 780 [D loss: 0.139944, acc: 94.53%] [G loss: 5.937816]\n",
            "******* 445 780 [D loss: 0.098894, acc: 97.66%] [G loss: 7.499000]\n",
            "******* 446 780 [D loss: 0.190793, acc: 93.75%] [G loss: 6.837048]\n",
            "******* 447 780 [D loss: 0.247593, acc: 89.84%] [G loss: 3.852419]\n",
            "******* 448 780 [D loss: 0.223058, acc: 92.19%] [G loss: 5.528569]\n",
            "******* 449 780 [D loss: 0.173518, acc: 93.75%] [G loss: 5.723866]\n",
            "******* 450 780 [D loss: 0.359318, acc: 87.50%] [G loss: 3.764857]\n",
            "******* 451 780 [D loss: 0.378248, acc: 86.72%] [G loss: 3.661658]\n",
            "******* 452 780 [D loss: 0.213100, acc: 89.84%] [G loss: 5.054132]\n",
            "******* 453 780 [D loss: 0.167931, acc: 93.75%] [G loss: 5.988382]\n",
            "******* 454 780 [D loss: 0.103852, acc: 96.88%] [G loss: 5.692050]\n",
            "******* 455 780 [D loss: 0.157782, acc: 93.75%] [G loss: 4.239544]\n",
            "******* 456 780 [D loss: 0.287797, acc: 89.84%] [G loss: 4.069657]\n",
            "******* 457 780 [D loss: 0.154412, acc: 92.19%] [G loss: 4.235689]\n",
            "******* 458 780 [D loss: 0.268753, acc: 89.84%] [G loss: 3.268597]\n",
            "******* 459 780 [D loss: 0.192831, acc: 91.41%] [G loss: 3.959129]\n",
            "******* 460 780 [D loss: 0.114125, acc: 96.09%] [G loss: 5.579701]\n",
            "******* 461 780 [D loss: 0.062522, acc: 98.44%] [G loss: 6.161010]\n",
            "******* 462 780 [D loss: 0.052071, acc: 98.44%] [G loss: 7.030312]\n",
            "******* 463 780 [D loss: 0.059570, acc: 97.66%] [G loss: 7.575701]\n",
            "******* 464 780 [D loss: 0.057147, acc: 99.22%] [G loss: 7.006167]\n",
            "******* 465 780 [D loss: 0.068812, acc: 96.88%] [G loss: 7.368375]\n",
            "******* 466 780 [D loss: 0.028541, acc: 99.22%] [G loss: 7.502798]\n",
            "******* 467 780 [D loss: 0.058378, acc: 97.66%] [G loss: 7.733862]\n",
            "******* 468 780 [D loss: 0.123125, acc: 93.75%] [G loss: 6.208977]\n",
            "******* 469 780 [D loss: 0.101707, acc: 96.88%] [G loss: 7.870589]\n",
            "******* 470 780 [D loss: 0.046397, acc: 99.22%] [G loss: 8.781897]\n",
            "******* 471 780 [D loss: 0.063836, acc: 98.44%] [G loss: 9.891890]\n",
            "******* 472 780 [D loss: 0.115966, acc: 95.31%] [G loss: 8.649744]\n",
            "******* 473 780 [D loss: 0.081182, acc: 98.44%] [G loss: 6.289589]\n",
            "******* 474 780 [D loss: 0.046657, acc: 99.22%] [G loss: 6.276563]\n",
            "******* 475 780 [D loss: 0.062785, acc: 98.44%] [G loss: 5.500357]\n",
            "******* 476 780 [D loss: 0.111520, acc: 95.31%] [G loss: 5.719823]\n",
            "******* 477 780 [D loss: 0.132729, acc: 95.31%] [G loss: 5.081424]\n",
            "******* 478 780 [D loss: 0.098710, acc: 96.88%] [G loss: 5.999422]\n",
            "******* 479 780 [D loss: 0.274777, acc: 92.97%] [G loss: 4.346751]\n",
            "******* 480 780 [D loss: 0.175202, acc: 94.53%] [G loss: 3.790898]\n",
            "******* 481 780 [D loss: 0.263267, acc: 87.50%] [G loss: 3.671322]\n",
            "******* 482 780 [D loss: 0.373638, acc: 89.06%] [G loss: 4.348359]\n",
            "******* 483 780 [D loss: 0.434839, acc: 84.38%] [G loss: 4.696951]\n",
            "******* 484 780 [D loss: 0.360987, acc: 87.50%] [G loss: 3.632148]\n",
            "******* 485 780 [D loss: 0.324582, acc: 84.38%] [G loss: 3.206184]\n",
            "******* 486 780 [D loss: 0.117156, acc: 95.31%] [G loss: 4.813253]\n",
            "******* 487 780 [D loss: 0.147151, acc: 93.75%] [G loss: 6.247060]\n",
            "******* 488 780 [D loss: 0.308382, acc: 88.28%] [G loss: 3.787457]\n",
            "******* 489 780 [D loss: 0.232515, acc: 91.41%] [G loss: 3.033565]\n",
            "******* 490 780 [D loss: 0.131479, acc: 95.31%] [G loss: 4.791432]\n",
            "******* 491 780 [D loss: 0.053608, acc: 98.44%] [G loss: 5.586318]\n",
            "******* 492 780 [D loss: 0.094597, acc: 95.31%] [G loss: 5.787050]\n",
            "******* 493 780 [D loss: 0.241446, acc: 90.62%] [G loss: 4.315096]\n",
            "******* 494 780 [D loss: 0.138354, acc: 93.75%] [G loss: 4.146057]\n",
            "******* 495 780 [D loss: 0.161925, acc: 94.53%] [G loss: 3.886622]\n",
            "******* 496 780 [D loss: 0.162420, acc: 93.75%] [G loss: 3.710169]\n",
            "******* 497 780 [D loss: 0.128740, acc: 97.66%] [G loss: 4.463962]\n",
            "******* 498 780 [D loss: 0.142331, acc: 96.09%] [G loss: 4.477563]\n",
            "******* 499 780 [D loss: 0.087895, acc: 97.66%] [G loss: 4.614394]\n",
            "******* 500 780 [D loss: 0.109713, acc: 95.31%] [G loss: 5.576373]\n",
            "******* 501 780 [D loss: 0.042253, acc: 98.44%] [G loss: 8.347111]\n",
            "******* 502 780 [D loss: 0.087264, acc: 97.66%] [G loss: 8.729841]\n",
            "******* 503 780 [D loss: 0.110781, acc: 97.66%] [G loss: 8.584065]\n",
            "******* 504 780 [D loss: 0.020988, acc: 99.22%] [G loss: 6.418546]\n",
            "******* 505 780 [D loss: 0.322747, acc: 89.84%] [G loss: 9.686083]\n",
            "******* 506 780 [D loss: 0.098023, acc: 96.09%] [G loss: 10.819883]\n",
            "******* 507 780 [D loss: 0.839753, acc: 78.91%] [G loss: 8.503283]\n",
            "******* 508 780 [D loss: 0.645856, acc: 88.28%] [G loss: 5.551728]\n",
            "******* 509 780 [D loss: 0.440036, acc: 87.50%] [G loss: 4.332413]\n",
            "******* 510 780 [D loss: 0.449729, acc: 79.69%] [G loss: 5.165205]\n",
            "******* 511 780 [D loss: 0.316895, acc: 85.94%] [G loss: 7.097877]\n",
            "******* 512 780 [D loss: 0.436835, acc: 86.72%] [G loss: 7.220152]\n",
            "******* 513 780 [D loss: 0.541207, acc: 82.81%] [G loss: 6.984521]\n",
            "******* 514 780 [D loss: 0.535090, acc: 86.72%] [G loss: 4.721453]\n",
            "******* 515 780 [D loss: 0.406426, acc: 85.16%] [G loss: 4.224999]\n",
            "******* 516 780 [D loss: 0.203286, acc: 91.41%] [G loss: 4.661951]\n",
            "******* 517 780 [D loss: 0.189447, acc: 93.75%] [G loss: 4.350239]\n",
            "******* 518 780 [D loss: 0.305383, acc: 90.62%] [G loss: 5.987769]\n",
            "******* 519 780 [D loss: 0.165373, acc: 94.53%] [G loss: 8.809875]\n",
            "******* 520 780 [D loss: 0.355717, acc: 88.28%] [G loss: 6.284663]\n",
            "******* 521 780 [D loss: 0.150869, acc: 95.31%] [G loss: 5.584358]\n",
            "******* 522 780 [D loss: 0.149185, acc: 95.31%] [G loss: 6.772580]\n",
            "******* 523 780 [D loss: 0.265568, acc: 92.19%] [G loss: 6.649302]\n",
            "******* 524 780 [D loss: 0.126146, acc: 95.31%] [G loss: 7.031372]\n",
            "******* 525 780 [D loss: 0.115547, acc: 97.66%] [G loss: 6.160055]\n",
            "******* 526 780 [D loss: 0.076447, acc: 98.44%] [G loss: 5.844841]\n",
            "******* 527 780 [D loss: 0.038668, acc: 99.22%] [G loss: 5.863887]\n",
            "******* 528 780 [D loss: 0.070262, acc: 97.66%] [G loss: 4.967622]\n",
            "******* 529 780 [D loss: 0.078716, acc: 95.31%] [G loss: 6.384088]\n",
            "******* 530 780 [D loss: 0.090203, acc: 93.75%] [G loss: 6.353177]\n",
            "******* 531 780 [D loss: 0.079869, acc: 97.66%] [G loss: 5.842368]\n",
            "******* 532 780 [D loss: 0.074250, acc: 96.88%] [G loss: 4.264395]\n",
            "******* 533 780 [D loss: 0.251071, acc: 89.84%] [G loss: 3.798113]\n",
            "******* 534 780 [D loss: 0.264529, acc: 92.19%] [G loss: 3.108494]\n",
            "******* 535 780 [D loss: 0.218838, acc: 92.19%] [G loss: 3.267821]\n",
            "******* 536 780 [D loss: 0.157206, acc: 95.31%] [G loss: 3.383796]\n",
            "******* 537 780 [D loss: 0.196691, acc: 92.19%] [G loss: 3.469067]\n",
            "******* 538 780 [D loss: 0.189113, acc: 93.75%] [G loss: 3.481627]\n",
            "******* 539 780 [D loss: 0.316968, acc: 88.28%] [G loss: 2.875838]\n",
            "******* 540 780 [D loss: 0.188490, acc: 95.31%] [G loss: 2.792925]\n",
            "******* 541 780 [D loss: 0.150339, acc: 95.31%] [G loss: 2.446844]\n",
            "******* 542 780 [D loss: 0.189321, acc: 92.19%] [G loss: 2.901420]\n",
            "******* 543 780 [D loss: 0.184089, acc: 92.19%] [G loss: 3.218017]\n",
            "******* 544 780 [D loss: 0.147544, acc: 96.09%] [G loss: 3.278666]\n",
            "******* 545 780 [D loss: 0.122713, acc: 95.31%] [G loss: 3.458240]\n",
            "******* 546 780 [D loss: 0.190100, acc: 94.53%] [G loss: 3.793998]\n",
            "******* 547 780 [D loss: 0.186398, acc: 91.41%] [G loss: 3.328499]\n",
            "******* 548 780 [D loss: 0.241790, acc: 88.28%] [G loss: 2.873851]\n",
            "******* 549 780 [D loss: 0.173990, acc: 92.19%] [G loss: 2.837573]\n",
            "******* 550 780 [D loss: 0.168838, acc: 93.75%] [G loss: 3.079546]\n",
            "******* 551 780 [D loss: 0.117726, acc: 94.53%] [G loss: 3.551410]\n",
            "******* 552 780 [D loss: 0.165342, acc: 95.31%] [G loss: 3.892717]\n",
            "******* 553 780 [D loss: 0.126747, acc: 95.31%] [G loss: 4.400841]\n",
            "******* 554 780 [D loss: 0.193026, acc: 91.41%] [G loss: 4.051989]\n",
            "******* 555 780 [D loss: 0.190905, acc: 91.41%] [G loss: 3.663673]\n",
            "******* 556 780 [D loss: 0.270914, acc: 89.06%] [G loss: 3.542317]\n",
            "******* 557 780 [D loss: 0.210945, acc: 90.62%] [G loss: 3.270574]\n",
            "******* 558 780 [D loss: 0.104650, acc: 96.09%] [G loss: 3.647813]\n",
            "******* 559 780 [D loss: 0.145095, acc: 94.53%] [G loss: 3.865086]\n",
            "******* 560 780 [D loss: 0.116016, acc: 95.31%] [G loss: 4.312002]\n",
            "******* 561 780 [D loss: 0.212980, acc: 92.19%] [G loss: 4.990225]\n",
            "******* 562 780 [D loss: 0.120971, acc: 95.31%] [G loss: 4.194328]\n",
            "******* 563 780 [D loss: 0.103777, acc: 96.09%] [G loss: 3.805500]\n",
            "******* 564 780 [D loss: 0.117417, acc: 96.09%] [G loss: 4.033840]\n",
            "******* 565 780 [D loss: 0.072718, acc: 97.66%] [G loss: 4.073204]\n",
            "******* 566 780 [D loss: 0.218586, acc: 87.50%] [G loss: 3.904325]\n",
            "******* 567 780 [D loss: 0.149297, acc: 94.53%] [G loss: 4.384189]\n",
            "******* 568 780 [D loss: 0.116322, acc: 95.31%] [G loss: 4.232880]\n",
            "******* 569 780 [D loss: 0.154760, acc: 94.53%] [G loss: 4.270671]\n",
            "******* 570 780 [D loss: 0.099700, acc: 96.09%] [G loss: 4.204395]\n",
            "******* 571 780 [D loss: 0.079736, acc: 97.66%] [G loss: 4.106476]\n",
            "******* 572 780 [D loss: 0.084277, acc: 97.66%] [G loss: 4.395563]\n",
            "******* 573 780 [D loss: 0.133204, acc: 95.31%] [G loss: 4.067537]\n",
            "******* 574 780 [D loss: 0.143666, acc: 96.88%] [G loss: 4.430045]\n",
            "******* 575 780 [D loss: 0.133706, acc: 96.88%] [G loss: 3.989326]\n",
            "******* 576 780 [D loss: 0.136743, acc: 95.31%] [G loss: 3.482472]\n",
            "******* 577 780 [D loss: 0.110386, acc: 96.09%] [G loss: 3.430778]\n",
            "******* 578 780 [D loss: 0.107164, acc: 97.66%] [G loss: 4.643182]\n",
            "******* 579 780 [D loss: 0.063721, acc: 97.66%] [G loss: 5.193766]\n",
            "******* 580 780 [D loss: 0.096476, acc: 97.66%] [G loss: 4.072209]\n",
            "******* 581 780 [D loss: 0.138067, acc: 94.53%] [G loss: 4.473630]\n",
            "******* 582 780 [D loss: 0.074825, acc: 97.66%] [G loss: 5.228326]\n",
            "******* 583 780 [D loss: 0.067680, acc: 97.66%] [G loss: 6.591604]\n",
            "******* 584 780 [D loss: 0.124827, acc: 96.09%] [G loss: 5.373495]\n",
            "******* 585 780 [D loss: 0.096858, acc: 96.88%] [G loss: 3.872804]\n",
            "******* 586 780 [D loss: 0.207239, acc: 92.19%] [G loss: 4.545308]\n",
            "******* 587 780 [D loss: 0.046350, acc: 98.44%] [G loss: 6.002472]\n",
            "******* 588 780 [D loss: 0.084899, acc: 96.88%] [G loss: 6.666101]\n",
            "******* 589 780 [D loss: 0.155115, acc: 95.31%] [G loss: 4.210795]\n",
            "******* 590 780 [D loss: 0.309289, acc: 86.72%] [G loss: 4.164416]\n",
            "******* 591 780 [D loss: 0.092289, acc: 96.88%] [G loss: 5.409708]\n",
            "******* 592 780 [D loss: 0.420832, acc: 89.06%] [G loss: 3.409824]\n",
            "******* 593 780 [D loss: 0.210320, acc: 92.97%] [G loss: 3.174425]\n",
            "******* 594 780 [D loss: 0.090316, acc: 97.66%] [G loss: 5.181523]\n",
            "******* 595 780 [D loss: 0.128394, acc: 97.66%] [G loss: 5.345638]\n",
            "******* 596 780 [D loss: 0.261020, acc: 90.62%] [G loss: 5.722857]\n",
            "******* 597 780 [D loss: 0.127299, acc: 96.88%] [G loss: 6.975590]\n",
            "******* 598 780 [D loss: 0.358433, acc: 89.06%] [G loss: 7.491763]\n",
            "******* 599 780 [D loss: 0.176332, acc: 92.97%] [G loss: 6.051171]\n",
            "******* 600 780 [D loss: 0.349867, acc: 92.19%] [G loss: 3.897537]\n",
            "******* 601 780 [D loss: 0.304546, acc: 91.41%] [G loss: 5.292046]\n",
            "******* 602 780 [D loss: 0.202546, acc: 95.31%] [G loss: 6.580412]\n",
            "******* 603 780 [D loss: 0.133120, acc: 94.53%] [G loss: 6.037316]\n",
            "******* 604 780 [D loss: 0.894744, acc: 75.78%] [G loss: 9.029979]\n",
            "******* 605 780 [D loss: 1.032684, acc: 78.12%] [G loss: 9.261586]\n",
            "******* 606 780 [D loss: 1.531548, acc: 72.66%] [G loss: 7.075706]\n",
            "******* 607 780 [D loss: 0.389372, acc: 89.06%] [G loss: 6.012966]\n",
            "******* 608 780 [D loss: 0.078489, acc: 96.88%] [G loss: 6.216424]\n",
            "******* 609 780 [D loss: 0.093184, acc: 95.31%] [G loss: 7.475612]\n",
            "******* 610 780 [D loss: 0.335850, acc: 89.06%] [G loss: 11.209457]\n",
            "******* 611 780 [D loss: 0.206218, acc: 93.75%] [G loss: 12.409324]\n",
            "******* 612 780 [D loss: 0.060590, acc: 98.44%] [G loss: 11.492420]\n",
            "******* 613 780 [D loss: 0.220728, acc: 96.09%] [G loss: 7.157865]\n",
            "******* 614 780 [D loss: 0.142690, acc: 94.53%] [G loss: 8.646491]\n",
            "******* 615 780 [D loss: 0.215346, acc: 92.19%] [G loss: 10.380726]\n",
            "******* 616 780 [D loss: 0.077017, acc: 97.66%] [G loss: 12.444624]\n",
            "******* 617 780 [D loss: 0.394951, acc: 89.06%] [G loss: 7.435783]\n",
            "******* 618 780 [D loss: 0.195920, acc: 92.97%] [G loss: 4.541401]\n",
            "******* 619 780 [D loss: 0.186117, acc: 92.19%] [G loss: 6.135490]\n",
            "******* 620 780 [D loss: 0.094256, acc: 96.09%] [G loss: 7.845547]\n",
            "******* 621 780 [D loss: 0.312171, acc: 89.84%] [G loss: 6.466255]\n",
            "******* 622 780 [D loss: 0.429845, acc: 82.03%] [G loss: 4.002700]\n",
            "******* 623 780 [D loss: 0.214828, acc: 91.41%] [G loss: 3.260948]\n",
            "******* 624 780 [D loss: 0.300322, acc: 86.72%] [G loss: 4.904566]\n",
            "******* 625 780 [D loss: 0.070868, acc: 98.44%] [G loss: 6.122257]\n",
            "******* 626 780 [D loss: 0.180681, acc: 92.19%] [G loss: 6.706801]\n",
            "******* 627 780 [D loss: 0.146136, acc: 92.97%] [G loss: 6.294631]\n",
            "******* 628 780 [D loss: 0.191387, acc: 92.19%] [G loss: 5.413139]\n",
            "******* 629 780 [D loss: 0.149717, acc: 93.75%] [G loss: 4.670824]\n",
            "******* 630 780 [D loss: 0.249862, acc: 91.41%] [G loss: 3.983856]\n",
            "******* 631 780 [D loss: 0.252158, acc: 92.97%] [G loss: 4.437394]\n",
            "******* 632 780 [D loss: 0.122079, acc: 95.31%] [G loss: 5.455747]\n",
            "******* 633 780 [D loss: 0.140803, acc: 93.75%] [G loss: 5.950227]\n",
            "******* 634 780 [D loss: 0.125340, acc: 95.31%] [G loss: 5.725064]\n",
            "******* 635 780 [D loss: 0.148805, acc: 93.75%] [G loss: 5.349166]\n",
            "******* 636 780 [D loss: 0.156119, acc: 92.97%] [G loss: 5.341185]\n",
            "******* 637 780 [D loss: 0.099458, acc: 96.88%] [G loss: 5.587642]\n",
            "******* 638 780 [D loss: 0.070530, acc: 97.66%] [G loss: 4.861458]\n",
            "******* 639 780 [D loss: 0.088700, acc: 96.88%] [G loss: 4.102215]\n",
            "******* 640 780 [D loss: 0.121706, acc: 97.66%] [G loss: 5.394032]\n",
            "******* 641 780 [D loss: 0.086630, acc: 96.88%] [G loss: 5.001617]\n",
            "******* 642 780 [D loss: 0.058318, acc: 96.88%] [G loss: 6.655003]\n",
            "******* 643 780 [D loss: 0.102110, acc: 96.88%] [G loss: 7.013737]\n",
            "******* 644 780 [D loss: 0.078254, acc: 96.88%] [G loss: 6.590918]\n",
            "******* 645 780 [D loss: 0.070164, acc: 96.88%] [G loss: 5.843821]\n",
            "******* 646 780 [D loss: 0.088599, acc: 96.88%] [G loss: 6.266359]\n",
            "******* 647 780 [D loss: 0.087725, acc: 96.88%] [G loss: 6.015573]\n",
            "******* 648 780 [D loss: 0.114988, acc: 98.44%] [G loss: 8.509779]\n",
            "******* 649 780 [D loss: 0.088773, acc: 96.09%] [G loss: 7.812582]\n",
            "******* 650 780 [D loss: 0.270161, acc: 90.62%] [G loss: 5.153897]\n",
            "******* 651 780 [D loss: 0.139285, acc: 92.97%] [G loss: 4.663992]\n",
            "******* 652 780 [D loss: 0.161336, acc: 92.97%] [G loss: 5.425195]\n",
            "******* 653 780 [D loss: 0.201740, acc: 93.75%] [G loss: 5.777435]\n",
            "******* 654 780 [D loss: 0.156056, acc: 95.31%] [G loss: 6.131435]\n",
            "******* 655 780 [D loss: 0.106702, acc: 96.09%] [G loss: 5.065157]\n",
            "******* 656 780 [D loss: 0.217259, acc: 92.19%] [G loss: 3.286473]\n",
            "******* 657 780 [D loss: 0.166187, acc: 95.31%] [G loss: 3.090285]\n",
            "******* 658 780 [D loss: 0.151886, acc: 97.66%] [G loss: 3.685801]\n",
            "******* 659 780 [D loss: 0.172922, acc: 92.97%] [G loss: 4.516266]\n",
            "******* 660 780 [D loss: 0.287588, acc: 87.50%] [G loss: 3.480894]\n",
            "******* 661 780 [D loss: 0.190466, acc: 92.19%] [G loss: 2.993097]\n",
            "******* 662 780 [D loss: 0.386344, acc: 80.47%] [G loss: 2.566716]\n",
            "******* 663 780 [D loss: 0.229399, acc: 89.84%] [G loss: 2.856973]\n",
            "******* 664 780 [D loss: 0.164608, acc: 92.97%] [G loss: 3.562854]\n",
            "******* 665 780 [D loss: 0.169926, acc: 92.97%] [G loss: 3.304501]\n",
            "******* 666 780 [D loss: 0.169405, acc: 92.19%] [G loss: 3.209305]\n",
            "******* 667 780 [D loss: 0.215298, acc: 92.19%] [G loss: 2.593876]\n",
            "******* 668 780 [D loss: 0.308407, acc: 88.28%] [G loss: 2.066586]\n",
            "******* 669 780 [D loss: 0.181604, acc: 94.53%] [G loss: 3.155224]\n",
            "******* 670 780 [D loss: 0.129682, acc: 96.88%] [G loss: 3.648814]\n",
            "******* 671 780 [D loss: 0.134253, acc: 94.53%] [G loss: 4.008096]\n",
            "******* 672 780 [D loss: 0.149610, acc: 94.53%] [G loss: 3.569488]\n",
            "******* 673 780 [D loss: 0.146482, acc: 94.53%] [G loss: 3.052505]\n",
            "******* 674 780 [D loss: 0.091296, acc: 97.66%] [G loss: 3.236647]\n",
            "******* 675 780 [D loss: 0.129878, acc: 95.31%] [G loss: 3.503080]\n",
            "******* 676 780 [D loss: 0.138695, acc: 95.31%] [G loss: 3.959848]\n",
            "******* 677 780 [D loss: 0.197361, acc: 92.97%] [G loss: 3.529967]\n",
            "******* 678 780 [D loss: 0.137436, acc: 95.31%] [G loss: 3.546467]\n",
            "******* 679 780 [D loss: 0.126908, acc: 94.53%] [G loss: 4.125849]\n",
            "******* 680 780 [D loss: 0.132487, acc: 96.09%] [G loss: 3.644378]\n",
            "******* 681 780 [D loss: 0.109091, acc: 96.09%] [G loss: 3.474022]\n",
            "******* 682 780 [D loss: 0.122275, acc: 96.88%] [G loss: 3.718892]\n",
            "******* 683 780 [D loss: 0.154573, acc: 93.75%] [G loss: 3.717779]\n",
            "******* 684 780 [D loss: 0.140224, acc: 96.09%] [G loss: 3.829069]\n",
            "******* 685 780 [D loss: 0.145796, acc: 95.31%] [G loss: 3.834973]\n",
            "******* 686 780 [D loss: 0.219433, acc: 92.19%] [G loss: 3.940854]\n",
            "******* 687 780 [D loss: 0.164825, acc: 92.19%] [G loss: 3.768565]\n",
            "******* 688 780 [D loss: 0.111755, acc: 95.31%] [G loss: 3.575411]\n",
            "******* 689 780 [D loss: 0.166008, acc: 92.97%] [G loss: 3.758210]\n",
            "******* 690 780 [D loss: 0.143888, acc: 94.53%] [G loss: 4.240263]\n",
            "******* 691 780 [D loss: 0.248516, acc: 92.97%] [G loss: 3.947605]\n",
            "******* 692 780 [D loss: 0.334831, acc: 87.50%] [G loss: 2.705926]\n",
            "******* 693 780 [D loss: 0.158596, acc: 96.09%] [G loss: 3.261670]\n",
            "******* 694 780 [D loss: 0.160414, acc: 94.53%] [G loss: 3.498044]\n",
            "******* 695 780 [D loss: 0.134807, acc: 96.09%] [G loss: 4.090160]\n",
            "******* 696 780 [D loss: 0.128308, acc: 98.44%] [G loss: 3.816440]\n",
            "******* 697 780 [D loss: 0.071196, acc: 97.66%] [G loss: 3.513128]\n",
            "******* 698 780 [D loss: 0.077787, acc: 97.66%] [G loss: 3.668565]\n",
            "******* 699 780 [D loss: 0.064749, acc: 99.22%] [G loss: 4.212479]\n",
            "******* 700 780 [D loss: 0.077737, acc: 96.09%] [G loss: 4.250392]\n",
            "******* 701 780 [D loss: 0.052417, acc: 98.44%] [G loss: 4.495194]\n",
            "******* 702 780 [D loss: 0.048043, acc: 99.22%] [G loss: 4.438763]\n",
            "******* 703 780 [D loss: 0.053070, acc: 98.44%] [G loss: 4.696061]\n",
            "******* 704 780 [D loss: 0.076969, acc: 97.66%] [G loss: 4.330633]\n",
            "******* 705 780 [D loss: 0.062219, acc: 97.66%] [G loss: 4.237915]\n",
            "******* 706 780 [D loss: 0.092153, acc: 98.44%] [G loss: 3.675206]\n",
            "******* 707 780 [D loss: 0.070985, acc: 97.66%] [G loss: 4.198790]\n",
            "******* 708 780 [D loss: 0.029896, acc: 100.00%] [G loss: 5.405102]\n",
            "******* 709 780 [D loss: 0.053406, acc: 96.88%] [G loss: 5.663548]\n",
            "******* 710 780 [D loss: 0.026375, acc: 99.22%] [G loss: 5.072163]\n",
            "******* 711 780 [D loss: 0.028204, acc: 100.00%] [G loss: 5.057152]\n",
            "******* 712 780 [D loss: 0.020318, acc: 99.22%] [G loss: 4.526916]\n",
            "******* 713 780 [D loss: 0.151279, acc: 94.53%] [G loss: 3.734305]\n",
            "******* 714 780 [D loss: 0.086813, acc: 98.44%] [G loss: 3.712841]\n",
            "******* 715 780 [D loss: 0.064476, acc: 98.44%] [G loss: 4.277253]\n",
            "******* 716 780 [D loss: 0.074477, acc: 97.66%] [G loss: 4.154497]\n",
            "******* 717 780 [D loss: 0.095139, acc: 97.66%] [G loss: 4.091919]\n",
            "******* 718 780 [D loss: 0.163907, acc: 91.41%] [G loss: 3.788152]\n",
            "******* 719 780 [D loss: 0.105263, acc: 96.88%] [G loss: 4.677138]\n",
            "******* 720 780 [D loss: 0.124773, acc: 95.31%] [G loss: 4.421189]\n",
            "******* 721 780 [D loss: 0.125045, acc: 94.53%] [G loss: 4.072079]\n",
            "******* 722 780 [D loss: 0.126768, acc: 96.09%] [G loss: 4.663307]\n",
            "******* 723 780 [D loss: 0.260224, acc: 87.50%] [G loss: 3.791425]\n",
            "******* 724 780 [D loss: 0.203664, acc: 92.19%] [G loss: 4.334024]\n",
            "******* 725 780 [D loss: 0.147938, acc: 96.09%] [G loss: 5.522611]\n",
            "******* 726 780 [D loss: 0.167434, acc: 92.97%] [G loss: 4.841405]\n",
            "******* 727 780 [D loss: 0.213925, acc: 90.62%] [G loss: 4.808140]\n",
            "******* 728 780 [D loss: 0.204053, acc: 92.97%] [G loss: 5.283195]\n",
            "******* 729 780 [D loss: 0.111736, acc: 95.31%] [G loss: 5.636493]\n",
            "******* 730 780 [D loss: 0.094024, acc: 96.88%] [G loss: 4.639973]\n",
            "******* 731 780 [D loss: 0.286632, acc: 88.28%] [G loss: 5.739063]\n",
            "******* 732 780 [D loss: 0.098340, acc: 96.88%] [G loss: 6.153406]\n",
            "******* 733 780 [D loss: 0.218354, acc: 88.28%] [G loss: 3.816902]\n",
            "******* 734 780 [D loss: 0.241635, acc: 88.28%] [G loss: 3.404530]\n",
            "******* 735 780 [D loss: 0.061696, acc: 99.22%] [G loss: 6.373335]\n",
            "******* 736 780 [D loss: 0.132819, acc: 92.97%] [G loss: 6.323619]\n",
            "******* 737 780 [D loss: 0.051465, acc: 98.44%] [G loss: 5.852930]\n",
            "******* 738 780 [D loss: 0.071985, acc: 97.66%] [G loss: 5.112586]\n",
            "******* 739 780 [D loss: 0.070884, acc: 97.66%] [G loss: 4.218783]\n",
            "******* 740 780 [D loss: 0.057853, acc: 98.44%] [G loss: 4.694963]\n",
            "******* 741 780 [D loss: 0.056692, acc: 97.66%] [G loss: 5.254181]\n",
            "******* 742 780 [D loss: 0.050105, acc: 99.22%] [G loss: 5.493076]\n",
            "******* 743 780 [D loss: 0.057414, acc: 97.66%] [G loss: 4.708177]\n",
            "******* 744 780 [D loss: 0.066974, acc: 97.66%] [G loss: 4.101720]\n",
            "******* 745 780 [D loss: 0.067781, acc: 97.66%] [G loss: 4.467659]\n",
            "******* 746 780 [D loss: 0.030349, acc: 99.22%] [G loss: 5.028785]\n",
            "******* 747 780 [D loss: 0.125457, acc: 96.88%] [G loss: 5.430108]\n",
            "******* 748 780 [D loss: 0.119077, acc: 94.53%] [G loss: 5.436234]\n",
            "******* 749 780 [D loss: 0.176062, acc: 92.97%] [G loss: 6.385283]\n",
            "******* 750 780 [D loss: 0.223302, acc: 92.19%] [G loss: 6.095853]\n",
            "******* 751 780 [D loss: 0.253792, acc: 92.97%] [G loss: 5.410647]\n",
            "******* 752 780 [D loss: 0.042214, acc: 98.44%] [G loss: 5.111686]\n",
            "******* 753 780 [D loss: 0.062456, acc: 98.44%] [G loss: 5.602368]\n",
            "******* 754 780 [D loss: 0.085392, acc: 95.31%] [G loss: 5.554450]\n",
            "******* 755 780 [D loss: 0.045311, acc: 98.44%] [G loss: 6.146218]\n",
            "******* 756 780 [D loss: 0.096955, acc: 96.88%] [G loss: 6.072189]\n",
            "******* 757 780 [D loss: 0.065236, acc: 98.44%] [G loss: 6.301805]\n",
            "******* 758 780 [D loss: 0.059035, acc: 98.44%] [G loss: 5.647396]\n",
            "******* 759 780 [D loss: 0.028049, acc: 99.22%] [G loss: 7.082901]\n",
            "******* 760 780 [D loss: 0.055608, acc: 96.88%] [G loss: 7.275215]\n",
            "******* 761 780 [D loss: 0.060511, acc: 96.88%] [G loss: 7.283775]\n",
            "******* 762 780 [D loss: 0.137433, acc: 96.09%] [G loss: 5.667948]\n",
            "******* 763 780 [D loss: 0.353360, acc: 86.72%] [G loss: 7.676010]\n",
            "******* 764 780 [D loss: 0.351136, acc: 91.41%] [G loss: 9.848686]\n",
            "******* 765 780 [D loss: 0.338975, acc: 87.50%] [G loss: 6.785032]\n",
            "******* 766 780 [D loss: 0.556460, acc: 77.34%] [G loss: 8.401696]\n",
            "******* 767 780 [D loss: 0.219164, acc: 92.97%] [G loss: 10.093019]\n",
            "******* 768 780 [D loss: 0.452205, acc: 94.53%] [G loss: 7.920985]\n",
            "******* 769 780 [D loss: 0.334911, acc: 92.19%] [G loss: 4.515486]\n",
            "******* 770 780 [D loss: 0.312067, acc: 89.06%] [G loss: 2.628233]\n",
            "******* 771 780 [D loss: 0.199872, acc: 89.84%] [G loss: 3.563620]\n",
            "******* 772 780 [D loss: 0.108251, acc: 96.88%] [G loss: 4.857178]\n",
            "******* 773 780 [D loss: 0.160144, acc: 92.19%] [G loss: 4.785508]\n",
            "******* 774 780 [D loss: 0.132970, acc: 95.31%] [G loss: 5.496720]\n",
            "******* 775 780 [D loss: 0.368464, acc: 86.72%] [G loss: 4.181603]\n",
            "******* 776 780 [D loss: 0.092298, acc: 96.09%] [G loss: 3.523179]\n",
            "******* 777 780 [D loss: 0.203581, acc: 92.97%] [G loss: 3.682956]\n",
            "******* 778 780 [D loss: 0.204369, acc: 92.97%] [G loss: 4.018132]\n",
            "******* 779 780 [D loss: 0.147433, acc: 93.75%] [G loss: 5.036391]\n",
            "******* 780 780 [D loss: 0.162969, acc: 95.31%] [G loss: 5.356170]\n",
            "******* 781 780 [D loss: 0.268962, acc: 88.28%] [G loss: 4.471906]\n",
            "******* 782 780 [D loss: 0.156543, acc: 92.97%] [G loss: 3.450091]\n",
            "******* 783 780 [D loss: 0.092072, acc: 98.44%] [G loss: 3.371704]\n",
            "******* 784 780 [D loss: 0.144570, acc: 96.09%] [G loss: 4.047512]\n",
            "******* 785 780 [D loss: 0.129778, acc: 96.88%] [G loss: 4.248172]\n",
            "******* 786 780 [D loss: 0.201180, acc: 92.97%] [G loss: 3.986714]\n",
            "******* 787 780 [D loss: 0.114194, acc: 96.88%] [G loss: 3.548786]\n",
            "******* 788 780 [D loss: 0.051806, acc: 99.22%] [G loss: 3.758938]\n",
            "******* 789 780 [D loss: 0.036384, acc: 99.22%] [G loss: 4.646324]\n",
            "******* 790 780 [D loss: 0.048302, acc: 97.66%] [G loss: 5.526770]\n",
            "******* 791 780 [D loss: 0.114593, acc: 96.88%] [G loss: 5.498790]\n",
            "******* 792 780 [D loss: 0.070097, acc: 97.66%] [G loss: 5.142349]\n",
            "******* 793 780 [D loss: 0.032020, acc: 100.00%] [G loss: 4.764729]\n",
            "******* 794 780 [D loss: 0.061957, acc: 98.44%] [G loss: 3.892575]\n",
            "******* 795 780 [D loss: 0.070587, acc: 98.44%] [G loss: 3.535036]\n",
            "******* 796 780 [D loss: 0.053672, acc: 98.44%] [G loss: 4.200611]\n",
            "******* 797 780 [D loss: 0.040655, acc: 99.22%] [G loss: 4.370702]\n",
            "******* 798 780 [D loss: 0.125200, acc: 95.31%] [G loss: 4.128101]\n",
            "******* 799 780 [D loss: 0.057756, acc: 99.22%] [G loss: 4.065203]\n",
            "******* 800 780 [D loss: 0.055086, acc: 99.22%] [G loss: 4.158686]\n",
            "******* 801 780 [D loss: 0.075318, acc: 97.66%] [G loss: 4.908761]\n",
            "******* 802 780 [D loss: 0.049807, acc: 99.22%] [G loss: 5.829395]\n",
            "******* 803 780 [D loss: 0.030938, acc: 99.22%] [G loss: 6.443930]\n",
            "******* 804 780 [D loss: 0.076994, acc: 96.88%] [G loss: 6.316072]\n",
            "******* 805 780 [D loss: 0.118763, acc: 96.09%] [G loss: 5.784789]\n",
            "******* 806 780 [D loss: 0.118966, acc: 92.97%] [G loss: 5.505421]\n",
            "******* 807 780 [D loss: 0.128778, acc: 96.09%] [G loss: 5.609787]\n",
            "******* 808 780 [D loss: 0.312959, acc: 87.50%] [G loss: 5.345198]\n",
            "******* 809 780 [D loss: 0.150986, acc: 94.53%] [G loss: 5.344258]\n",
            "******* 810 780 [D loss: 0.182243, acc: 93.75%] [G loss: 5.413675]\n",
            "******* 811 780 [D loss: 0.320824, acc: 85.16%] [G loss: 6.589599]\n",
            "******* 812 780 [D loss: 0.143244, acc: 95.31%] [G loss: 5.978824]\n",
            "******* 813 780 [D loss: 0.198612, acc: 91.41%] [G loss: 5.770527]\n",
            "******* 814 780 [D loss: 0.095799, acc: 96.88%] [G loss: 5.800705]\n",
            "******* 815 780 [D loss: 0.195931, acc: 93.75%] [G loss: 4.607002]\n",
            "******* 816 780 [D loss: 0.132816, acc: 96.88%] [G loss: 4.516312]\n",
            "******* 817 780 [D loss: 0.119647, acc: 97.66%] [G loss: 5.798301]\n",
            "******* 818 780 [D loss: 0.334459, acc: 90.62%] [G loss: 4.625336]\n",
            "******* 819 780 [D loss: 0.142777, acc: 95.31%] [G loss: 3.933649]\n",
            "******* 820 780 [D loss: 0.136244, acc: 93.75%] [G loss: 4.404604]\n",
            "******* 821 780 [D loss: 0.426539, acc: 85.94%] [G loss: 3.591653]\n",
            "******* 822 780 [D loss: 0.367944, acc: 87.50%] [G loss: 3.705928]\n",
            "******* 823 780 [D loss: 0.323806, acc: 89.06%] [G loss: 3.489887]\n",
            "******* 824 780 [D loss: 0.252227, acc: 89.06%] [G loss: 4.166386]\n",
            "******* 825 780 [D loss: 0.393130, acc: 85.16%] [G loss: 4.510731]\n",
            "******* 826 780 [D loss: 0.318444, acc: 87.50%] [G loss: 3.613762]\n",
            "******* 827 780 [D loss: 0.227992, acc: 91.41%] [G loss: 3.609587]\n",
            "******* 828 780 [D loss: 0.213363, acc: 94.53%] [G loss: 3.860855]\n",
            "******* 829 780 [D loss: 0.197962, acc: 91.41%] [G loss: 4.505946]\n",
            "******* 830 780 [D loss: 0.251209, acc: 89.06%] [G loss: 3.564049]\n",
            "******* 831 780 [D loss: 0.164850, acc: 94.53%] [G loss: 3.225945]\n",
            "******* 832 780 [D loss: 0.248044, acc: 89.06%] [G loss: 3.793984]\n",
            "******* 833 780 [D loss: 0.182899, acc: 93.75%] [G loss: 4.206474]\n",
            "******* 834 780 [D loss: 0.106229, acc: 95.31%] [G loss: 3.842251]\n",
            "******* 835 780 [D loss: 0.195168, acc: 89.84%] [G loss: 3.929397]\n",
            "******* 836 780 [D loss: 0.107504, acc: 95.31%] [G loss: 3.882108]\n",
            "******* 837 780 [D loss: 0.104353, acc: 96.09%] [G loss: 4.028690]\n",
            "******* 838 780 [D loss: 0.144087, acc: 93.75%] [G loss: 3.813370]\n",
            "******* 839 780 [D loss: 0.111882, acc: 97.66%] [G loss: 3.776011]\n",
            "******* 840 780 [D loss: 0.186546, acc: 92.97%] [G loss: 3.441872]\n",
            "******* 841 780 [D loss: 0.189459, acc: 96.88%] [G loss: 2.999144]\n",
            "******* 842 780 [D loss: 0.151705, acc: 95.31%] [G loss: 3.960814]\n",
            "******* 843 780 [D loss: 0.158256, acc: 92.97%] [G loss: 3.981103]\n",
            "******* 844 780 [D loss: 0.128085, acc: 95.31%] [G loss: 3.858150]\n",
            "******* 845 780 [D loss: 0.128864, acc: 94.53%] [G loss: 3.406302]\n",
            "******* 846 780 [D loss: 0.113205, acc: 97.66%] [G loss: 4.028899]\n",
            "******* 847 780 [D loss: 0.073545, acc: 97.66%] [G loss: 4.307340]\n",
            "******* 848 780 [D loss: 0.070340, acc: 98.44%] [G loss: 4.405542]\n",
            "******* 849 780 [D loss: 0.124063, acc: 94.53%] [G loss: 4.215415]\n",
            "******* 850 780 [D loss: 0.097152, acc: 96.09%] [G loss: 3.681551]\n",
            "******* 851 780 [D loss: 0.133452, acc: 93.75%] [G loss: 4.360888]\n",
            "******* 852 780 [D loss: 0.105065, acc: 97.66%] [G loss: 5.200202]\n",
            "******* 853 780 [D loss: 0.100857, acc: 96.88%] [G loss: 5.520167]\n",
            "******* 854 780 [D loss: 0.085623, acc: 97.66%] [G loss: 4.593690]\n",
            "******* 855 780 [D loss: 0.130191, acc: 96.88%] [G loss: 4.473430]\n",
            "******* 856 780 [D loss: 0.153608, acc: 96.09%] [G loss: 4.822488]\n",
            "******* 857 780 [D loss: 0.134067, acc: 96.88%] [G loss: 4.971750]\n",
            "******* 858 780 [D loss: 0.305835, acc: 88.28%] [G loss: 3.571662]\n",
            "******* 859 780 [D loss: 0.184756, acc: 93.75%] [G loss: 5.294341]\n",
            "******* 860 780 [D loss: 0.195787, acc: 92.19%] [G loss: 5.648885]\n",
            "******* 861 780 [D loss: 0.289807, acc: 89.84%] [G loss: 4.836076]\n",
            "******* 862 780 [D loss: 0.228026, acc: 89.06%] [G loss: 4.442766]\n",
            "******* 863 780 [D loss: 0.237080, acc: 89.06%] [G loss: 5.262367]\n",
            "******* 864 780 [D loss: 0.409704, acc: 85.16%] [G loss: 4.300409]\n",
            "******* 865 780 [D loss: 0.428306, acc: 78.91%] [G loss: 5.200706]\n",
            "******* 866 780 [D loss: 0.403840, acc: 83.59%] [G loss: 4.760543]\n",
            "******* 867 780 [D loss: 0.680419, acc: 79.69%] [G loss: 2.439571]\n",
            "******* 868 780 [D loss: 0.423831, acc: 82.03%] [G loss: 2.979266]\n",
            "******* 869 780 [D loss: 0.199395, acc: 93.75%] [G loss: 4.215970]\n",
            "******* 870 780 [D loss: 0.196681, acc: 92.19%] [G loss: 4.365382]\n",
            "******* 871 780 [D loss: 0.141816, acc: 93.75%] [G loss: 2.834425]\n",
            "******* 872 780 [D loss: 0.208264, acc: 90.62%] [G loss: 3.170376]\n",
            "******* 873 780 [D loss: 0.141240, acc: 95.31%] [G loss: 4.184813]\n",
            "******* 874 780 [D loss: 0.104511, acc: 95.31%] [G loss: 4.101165]\n",
            "******* 875 780 [D loss: 0.171183, acc: 92.97%] [G loss: 3.728575]\n",
            "******* 876 780 [D loss: 0.070648, acc: 98.44%] [G loss: 4.515670]\n",
            "******* 877 780 [D loss: 0.136286, acc: 93.75%] [G loss: 4.694674]\n",
            "******* 878 780 [D loss: 0.069214, acc: 98.44%] [G loss: 4.696228]\n",
            "******* 879 780 [D loss: 0.105157, acc: 96.88%] [G loss: 5.273386]\n",
            "******* 880 780 [D loss: 0.113226, acc: 95.31%] [G loss: 5.964213]\n",
            "******* 881 780 [D loss: 0.118991, acc: 94.53%] [G loss: 5.888038]\n",
            "******* 882 780 [D loss: 0.063656, acc: 99.22%] [G loss: 5.332221]\n",
            "******* 883 780 [D loss: 0.128688, acc: 94.53%] [G loss: 4.193230]\n",
            "******* 884 780 [D loss: 0.243360, acc: 88.28%] [G loss: 4.552936]\n",
            "******* 885 780 [D loss: 0.202315, acc: 95.31%] [G loss: 5.231742]\n",
            "******* 886 780 [D loss: 0.169943, acc: 95.31%] [G loss: 5.823365]\n",
            "******* 887 780 [D loss: 0.220496, acc: 91.41%] [G loss: 5.151605]\n",
            "******* 888 780 [D loss: 0.054802, acc: 97.66%] [G loss: 4.558186]\n",
            "******* 889 780 [D loss: 0.163315, acc: 96.09%] [G loss: 4.437964]\n",
            "******* 890 780 [D loss: 0.179501, acc: 91.41%] [G loss: 4.555072]\n",
            "******* 891 780 [D loss: 0.099207, acc: 96.09%] [G loss: 5.289606]\n",
            "******* 892 780 [D loss: 0.205692, acc: 92.19%] [G loss: 5.203343]\n",
            "******* 893 780 [D loss: 0.121772, acc: 92.97%] [G loss: 5.060339]\n",
            "******* 894 780 [D loss: 0.190361, acc: 92.19%] [G loss: 3.458976]\n",
            "******* 895 780 [D loss: 0.167372, acc: 94.53%] [G loss: 3.911779]\n",
            "******* 896 780 [D loss: 0.097993, acc: 97.66%] [G loss: 4.695143]\n",
            "******* 897 780 [D loss: 0.176435, acc: 94.53%] [G loss: 4.393920]\n",
            "******* 898 780 [D loss: 0.202053, acc: 90.62%] [G loss: 3.668851]\n",
            "******* 899 780 [D loss: 0.176808, acc: 93.75%] [G loss: 4.234096]\n",
            "******* 900 780 [D loss: 0.112659, acc: 95.31%] [G loss: 4.244101]\n",
            "******* 901 780 [D loss: 0.117236, acc: 96.09%] [G loss: 3.581587]\n",
            "******* 902 780 [D loss: 0.146842, acc: 94.53%] [G loss: 3.441972]\n",
            "******* 903 780 [D loss: 0.091426, acc: 98.44%] [G loss: 3.719444]\n",
            "******* 904 780 [D loss: 0.132052, acc: 96.09%] [G loss: 4.531291]\n",
            "******* 905 780 [D loss: 0.141139, acc: 93.75%] [G loss: 4.411854]\n",
            "******* 906 780 [D loss: 0.072326, acc: 99.22%] [G loss: 3.793678]\n",
            "******* 907 780 [D loss: 0.117156, acc: 95.31%] [G loss: 4.947143]\n",
            "******* 908 780 [D loss: 0.082653, acc: 96.88%] [G loss: 3.968445]\n",
            "******* 909 780 [D loss: 0.100863, acc: 97.66%] [G loss: 4.608952]\n",
            "******* 910 780 [D loss: 0.064382, acc: 99.22%] [G loss: 4.325671]\n",
            "******* 911 780 [D loss: 0.114134, acc: 95.31%] [G loss: 4.158376]\n",
            "******* 912 780 [D loss: 0.122731, acc: 95.31%] [G loss: 3.655053]\n",
            "******* 913 780 [D loss: 0.046318, acc: 99.22%] [G loss: 4.663002]\n",
            "******* 914 780 [D loss: 0.086134, acc: 96.88%] [G loss: 4.336450]\n",
            "******* 915 780 [D loss: 0.062180, acc: 98.44%] [G loss: 4.343101]\n",
            "******* 916 780 [D loss: 0.075138, acc: 98.44%] [G loss: 5.173392]\n",
            "******* 917 780 [D loss: 0.035484, acc: 99.22%] [G loss: 6.090765]\n",
            "******* 918 780 [D loss: 0.050976, acc: 98.44%] [G loss: 5.794522]\n",
            "******* 919 780 [D loss: 0.025374, acc: 100.00%] [G loss: 5.985127]\n",
            "******* 920 780 [D loss: 0.018639, acc: 100.00%] [G loss: 6.427487]\n",
            "******* 921 780 [D loss: 0.062312, acc: 98.44%] [G loss: 6.088462]\n",
            "******* 922 780 [D loss: 0.023126, acc: 99.22%] [G loss: 6.054572]\n",
            "******* 923 780 [D loss: 0.125764, acc: 93.75%] [G loss: 5.752649]\n",
            "******* 924 780 [D loss: 0.085139, acc: 97.66%] [G loss: 6.258219]\n",
            "******* 925 780 [D loss: 0.046700, acc: 98.44%] [G loss: 6.124559]\n",
            "******* 926 780 [D loss: 0.059467, acc: 97.66%] [G loss: 5.594032]\n",
            "******* 927 780 [D loss: 0.163572, acc: 93.75%] [G loss: 6.763727]\n",
            "******* 928 780 [D loss: 0.125225, acc: 94.53%] [G loss: 6.920537]\n",
            "******* 929 780 [D loss: 0.310493, acc: 85.16%] [G loss: 7.959700]\n",
            "******* 930 780 [D loss: 0.373010, acc: 89.06%] [G loss: 4.066656]\n",
            "******* 931 780 [D loss: 1.200867, acc: 60.94%] [G loss: 11.381254]\n",
            "******* 932 780 [D loss: 1.777227, acc: 64.84%] [G loss: 7.216375]\n",
            "******* 933 780 [D loss: 0.532807, acc: 80.47%] [G loss: 2.230503]\n",
            "******* 934 780 [D loss: 0.774815, acc: 70.31%] [G loss: 3.030574]\n",
            "******* 935 780 [D loss: 0.080767, acc: 96.88%] [G loss: 5.085557]\n",
            "******* 936 780 [D loss: 0.054373, acc: 99.22%] [G loss: 6.357779]\n",
            "******* 937 780 [D loss: 0.209908, acc: 89.06%] [G loss: 5.619982]\n",
            "******* 938 780 [D loss: 0.342528, acc: 87.50%] [G loss: 4.101760]\n",
            "******* 939 780 [D loss: 0.265801, acc: 89.84%] [G loss: 3.074368]\n",
            "******* 940 780 [D loss: 0.441390, acc: 82.81%] [G loss: 3.058161]\n",
            "******* 941 780 [D loss: 0.248781, acc: 90.62%] [G loss: 3.565855]\n",
            "******* 942 780 [D loss: 0.105530, acc: 96.09%] [G loss: 4.812004]\n",
            "******* 943 780 [D loss: 0.212408, acc: 95.31%] [G loss: 5.305799]\n",
            "******* 944 780 [D loss: 0.185349, acc: 90.62%] [G loss: 4.663574]\n",
            "******* 945 780 [D loss: 0.121576, acc: 95.31%] [G loss: 4.297198]\n",
            "******* 946 780 [D loss: 0.177056, acc: 94.53%] [G loss: 4.257039]\n",
            "******* 947 780 [D loss: 0.103108, acc: 97.66%] [G loss: 3.826855]\n",
            "******* 948 780 [D loss: 0.203610, acc: 95.31%] [G loss: 3.407714]\n",
            "******* 949 780 [D loss: 0.161863, acc: 92.97%] [G loss: 3.829886]\n",
            "******* 950 780 [D loss: 0.080614, acc: 98.44%] [G loss: 4.220966]\n",
            "******* 951 780 [D loss: 0.166415, acc: 94.53%] [G loss: 4.036464]\n",
            "******* 952 780 [D loss: 0.129714, acc: 93.75%] [G loss: 4.416401]\n",
            "******* 953 780 [D loss: 0.159083, acc: 91.41%] [G loss: 3.783702]\n",
            "******* 954 780 [D loss: 0.079350, acc: 98.44%] [G loss: 3.616906]\n",
            "******* 955 780 [D loss: 0.113732, acc: 96.09%] [G loss: 4.458379]\n",
            "******* 956 780 [D loss: 0.057715, acc: 98.44%] [G loss: 4.884870]\n",
            "******* 957 780 [D loss: 0.101766, acc: 96.88%] [G loss: 5.600566]\n",
            "******* 958 780 [D loss: 0.080609, acc: 96.88%] [G loss: 5.930236]\n",
            "******* 959 780 [D loss: 0.154172, acc: 92.97%] [G loss: 6.105828]\n",
            "******* 960 780 [D loss: 0.095798, acc: 96.09%] [G loss: 6.156841]\n",
            "******* 961 780 [D loss: 0.054217, acc: 98.44%] [G loss: 5.706453]\n",
            "******* 962 780 [D loss: 0.083077, acc: 97.66%] [G loss: 5.525845]\n",
            "******* 963 780 [D loss: 0.222122, acc: 92.97%] [G loss: 4.831603]\n",
            "******* 964 780 [D loss: 0.156572, acc: 96.88%] [G loss: 5.498531]\n",
            "******* 965 780 [D loss: 0.067396, acc: 97.66%] [G loss: 5.856774]\n",
            "******* 966 780 [D loss: 0.094410, acc: 97.66%] [G loss: 5.506164]\n",
            "******* 967 780 [D loss: 0.143045, acc: 93.75%] [G loss: 5.388488]\n",
            "******* 968 780 [D loss: 0.120586, acc: 95.31%] [G loss: 4.989107]\n",
            "******* 969 780 [D loss: 0.133085, acc: 96.88%] [G loss: 4.243765]\n",
            "******* 970 780 [D loss: 0.212770, acc: 92.97%] [G loss: 3.843606]\n",
            "******* 971 780 [D loss: 0.287856, acc: 88.28%] [G loss: 4.377478]\n",
            "******* 972 780 [D loss: 0.087009, acc: 96.88%] [G loss: 5.091240]\n",
            "******* 973 780 [D loss: 0.157075, acc: 92.19%] [G loss: 4.336511]\n",
            "******* 974 780 [D loss: 0.108488, acc: 98.44%] [G loss: 4.531629]\n",
            "******* 975 780 [D loss: 0.127586, acc: 96.88%] [G loss: 3.940090]\n",
            "******* 976 780 [D loss: 0.147383, acc: 95.31%] [G loss: 4.448045]\n",
            "******* 977 780 [D loss: 0.072331, acc: 97.66%] [G loss: 5.311340]\n",
            "******* 978 780 [D loss: 0.066307, acc: 98.44%] [G loss: 5.818250]\n",
            "******* 979 780 [D loss: 0.146398, acc: 96.09%] [G loss: 4.582297]\n",
            "******* 980 780 [D loss: 0.410956, acc: 78.91%] [G loss: 7.680115]\n",
            "******* 981 780 [D loss: 0.249562, acc: 91.41%] [G loss: 10.661476]\n",
            "******* 982 780 [D loss: 0.665339, acc: 85.16%] [G loss: 5.920559]\n",
            "******* 983 780 [D loss: 0.533297, acc: 84.38%] [G loss: 5.023736]\n",
            "******* 984 780 [D loss: 0.059376, acc: 98.44%] [G loss: 5.577654]\n",
            "******* 985 780 [D loss: 0.167505, acc: 92.97%] [G loss: 4.896155]\n",
            "******* 986 780 [D loss: 0.393477, acc: 82.81%] [G loss: 3.683626]\n",
            "******* 987 780 [D loss: 0.276974, acc: 82.81%] [G loss: 4.319936]\n",
            "******* 988 780 [D loss: 0.151186, acc: 94.53%] [G loss: 5.018593]\n",
            "******* 989 780 [D loss: 0.084207, acc: 96.88%] [G loss: 5.483775]\n",
            "******* 990 780 [D loss: 0.143401, acc: 93.75%] [G loss: 5.404516]\n",
            "******* 991 780 [D loss: 0.125221, acc: 93.75%] [G loss: 5.157887]\n",
            "******* 992 780 [D loss: 0.291407, acc: 87.50%] [G loss: 4.207254]\n",
            "******* 993 780 [D loss: 0.109640, acc: 96.09%] [G loss: 3.840557]\n",
            "******* 994 780 [D loss: 0.123461, acc: 96.88%] [G loss: 3.803446]\n",
            "******* 995 780 [D loss: 0.072680, acc: 97.66%] [G loss: 4.316734]\n",
            "******* 996 780 [D loss: 0.089459, acc: 96.88%] [G loss: 4.290669]\n",
            "******* 997 780 [D loss: 0.084741, acc: 96.09%] [G loss: 4.109326]\n",
            "******* 998 780 [D loss: 0.099235, acc: 96.88%] [G loss: 4.500711]\n",
            "******* 999 780 [D loss: 0.063392, acc: 98.44%] [G loss: 4.202561]\n",
            "******* 1000 780 [D loss: 0.094770, acc: 96.88%] [G loss: 3.780116]\n",
            "******* 1001 780 [D loss: 0.147315, acc: 94.53%] [G loss: 3.595123]\n",
            "******* 1002 780 [D loss: 0.118978, acc: 96.09%] [G loss: 3.713791]\n",
            "******* 1003 780 [D loss: 0.092635, acc: 98.44%] [G loss: 3.248035]\n",
            "******* 1004 780 [D loss: 0.133392, acc: 96.88%] [G loss: 3.236741]\n",
            "******* 1005 780 [D loss: 0.133822, acc: 95.31%] [G loss: 3.287751]\n",
            "******* 1006 780 [D loss: 0.118067, acc: 97.66%] [G loss: 3.685521]\n",
            "******* 1007 780 [D loss: 0.143837, acc: 94.53%] [G loss: 4.439130]\n",
            "******* 1008 780 [D loss: 0.228321, acc: 91.41%] [G loss: 3.762073]\n",
            "******* 1009 780 [D loss: 0.279558, acc: 87.50%] [G loss: 3.762814]\n",
            "******* 1010 780 [D loss: 0.204596, acc: 90.62%] [G loss: 3.699288]\n",
            "******* 1011 780 [D loss: 0.157333, acc: 94.53%] [G loss: 4.473623]\n",
            "******* 1012 780 [D loss: 0.226897, acc: 91.41%] [G loss: 4.888003]\n",
            "******* 1013 780 [D loss: 0.127279, acc: 93.75%] [G loss: 4.661750]\n",
            "******* 1014 780 [D loss: 0.175633, acc: 94.53%] [G loss: 4.187172]\n",
            "******* 1015 780 [D loss: 0.159279, acc: 95.31%] [G loss: 4.807961]\n",
            "******* 1016 780 [D loss: 0.138110, acc: 94.53%] [G loss: 5.569914]\n",
            "******* 1017 780 [D loss: 0.080510, acc: 99.22%] [G loss: 5.363520]\n",
            "******* 1018 780 [D loss: 0.167533, acc: 92.97%] [G loss: 4.794432]\n",
            "******* 1019 780 [D loss: 0.122441, acc: 96.88%] [G loss: 5.190159]\n",
            "******* 1020 780 [D loss: 0.050267, acc: 98.44%] [G loss: 6.414689]\n",
            "******* 1021 780 [D loss: 0.171979, acc: 95.31%] [G loss: 5.347119]\n",
            "******* 1022 780 [D loss: 0.206970, acc: 90.62%] [G loss: 4.643022]\n",
            "******* 1023 780 [D loss: 0.071112, acc: 98.44%] [G loss: 5.433496]\n",
            "******* 1024 780 [D loss: 0.109861, acc: 96.09%] [G loss: 6.185050]\n",
            "******* 1025 780 [D loss: 0.352405, acc: 87.50%] [G loss: 3.791659]\n",
            "******* 1026 780 [D loss: 0.995808, acc: 76.56%] [G loss: 9.346073]\n",
            "******* 1027 780 [D loss: 0.759970, acc: 75.78%] [G loss: 6.618262]\n",
            "******* 1028 780 [D loss: 0.678917, acc: 76.56%] [G loss: 4.671677]\n",
            "******* 1029 780 [D loss: 0.619053, acc: 78.12%] [G loss: 2.881622]\n",
            "******* 1030 780 [D loss: 0.384330, acc: 81.25%] [G loss: 3.576238]\n",
            "******* 1031 780 [D loss: 0.200864, acc: 92.97%] [G loss: 5.000329]\n",
            "******* 1032 780 [D loss: 0.515715, acc: 86.72%] [G loss: 4.348026]\n",
            "******* 1033 780 [D loss: 0.270350, acc: 85.94%] [G loss: 3.404639]\n",
            "******* 1034 780 [D loss: 0.279595, acc: 90.62%] [G loss: 3.904248]\n",
            "******* 1035 780 [D loss: 0.262930, acc: 87.50%] [G loss: 4.155341]\n",
            "******* 1036 780 [D loss: 0.281085, acc: 90.62%] [G loss: 2.926676]\n",
            "******* 1037 780 [D loss: 0.301702, acc: 88.28%] [G loss: 3.512806]\n",
            "******* 1038 780 [D loss: 0.315291, acc: 88.28%] [G loss: 4.195218]\n",
            "******* 1039 780 [D loss: 0.156590, acc: 95.31%] [G loss: 4.714428]\n",
            "******* 1040 780 [D loss: 0.223159, acc: 89.84%] [G loss: 4.744025]\n",
            "******* 1041 780 [D loss: 0.297560, acc: 88.28%] [G loss: 3.705788]\n",
            "******* 1042 780 [D loss: 0.088488, acc: 96.88%] [G loss: 3.930475]\n",
            "******* 1043 780 [D loss: 0.115774, acc: 96.09%] [G loss: 4.801781]\n",
            "******* 1044 780 [D loss: 0.211685, acc: 92.97%] [G loss: 4.677016]\n",
            "******* 1045 780 [D loss: 0.221150, acc: 91.41%] [G loss: 3.945823]\n",
            "******* 1046 780 [D loss: 0.104466, acc: 97.66%] [G loss: 4.110277]\n",
            "******* 1047 780 [D loss: 0.097893, acc: 95.31%] [G loss: 4.616749]\n",
            "******* 1048 780 [D loss: 0.116107, acc: 96.88%] [G loss: 4.661301]\n",
            "******* 1049 780 [D loss: 0.157883, acc: 94.53%] [G loss: 3.965215]\n",
            "******* 1050 780 [D loss: 0.119455, acc: 96.88%] [G loss: 4.531625]\n",
            "******* 1051 780 [D loss: 0.112651, acc: 96.09%] [G loss: 5.087258]\n",
            "******* 1052 780 [D loss: 0.137599, acc: 93.75%] [G loss: 5.474567]\n",
            "******* 1053 780 [D loss: 0.193680, acc: 92.97%] [G loss: 3.478443]\n",
            "******* 1054 780 [D loss: 0.129301, acc: 94.53%] [G loss: 4.118277]\n",
            "******* 1055 780 [D loss: 0.085051, acc: 96.88%] [G loss: 4.282939]\n",
            "******* 1056 780 [D loss: 0.153016, acc: 92.97%] [G loss: 4.448110]\n",
            "******* 1057 780 [D loss: 0.072609, acc: 96.88%] [G loss: 5.041926]\n",
            "******* 1058 780 [D loss: 0.221067, acc: 93.75%] [G loss: 4.900854]\n",
            "******* 1059 780 [D loss: 0.155632, acc: 94.53%] [G loss: 4.038489]\n",
            "******* 1060 780 [D loss: 0.145247, acc: 93.75%] [G loss: 3.968806]\n",
            "******* 1061 780 [D loss: 0.161837, acc: 93.75%] [G loss: 4.618015]\n",
            "******* 1062 780 [D loss: 0.138360, acc: 95.31%] [G loss: 5.533327]\n",
            "******* 1063 780 [D loss: 0.219436, acc: 92.19%] [G loss: 4.513662]\n",
            "******* 1064 780 [D loss: 0.194308, acc: 89.84%] [G loss: 4.266859]\n",
            "******* 1065 780 [D loss: 0.145766, acc: 92.97%] [G loss: 4.522516]\n",
            "******* 1066 780 [D loss: 0.079067, acc: 98.44%] [G loss: 4.873900]\n",
            "******* 1067 780 [D loss: 0.156995, acc: 93.75%] [G loss: 4.816646]\n",
            "******* 1068 780 [D loss: 0.111069, acc: 96.09%] [G loss: 5.253316]\n",
            "******* 1069 780 [D loss: 0.218288, acc: 92.19%] [G loss: 3.732852]\n",
            "******* 1070 780 [D loss: 0.212905, acc: 92.19%] [G loss: 3.543850]\n",
            "******* 1071 780 [D loss: 0.156959, acc: 96.09%] [G loss: 4.564989]\n",
            "******* 1072 780 [D loss: 0.118680, acc: 95.31%] [G loss: 4.687743]\n",
            "******* 1073 780 [D loss: 0.127143, acc: 95.31%] [G loss: 4.234635]\n",
            "******* 1074 780 [D loss: 0.198558, acc: 90.62%] [G loss: 3.644045]\n",
            "******* 1075 780 [D loss: 0.172915, acc: 92.19%] [G loss: 4.423935]\n",
            "******* 1076 780 [D loss: 0.167338, acc: 92.97%] [G loss: 4.211456]\n",
            "******* 1077 780 [D loss: 0.161076, acc: 93.75%] [G loss: 3.914158]\n",
            "******* 1078 780 [D loss: 0.140714, acc: 96.09%] [G loss: 3.099062]\n",
            "******* 1079 780 [D loss: 0.161094, acc: 90.62%] [G loss: 3.824737]\n",
            "******* 1080 780 [D loss: 0.099050, acc: 97.66%] [G loss: 4.288071]\n",
            "******* 1081 780 [D loss: 0.064863, acc: 98.44%] [G loss: 4.816320]\n",
            "******* 1082 780 [D loss: 0.156502, acc: 94.53%] [G loss: 5.080219]\n",
            "******* 1083 780 [D loss: 0.155582, acc: 92.97%] [G loss: 4.535647]\n",
            "******* 1084 780 [D loss: 0.104899, acc: 98.44%] [G loss: 4.070968]\n",
            "******* 1085 780 [D loss: 0.204048, acc: 90.62%] [G loss: 4.814396]\n",
            "******* 1086 780 [D loss: 0.114452, acc: 96.09%] [G loss: 3.739675]\n",
            "******* 1087 780 [D loss: 0.156633, acc: 96.09%] [G loss: 4.105258]\n",
            "******* 1088 780 [D loss: 0.078006, acc: 97.66%] [G loss: 4.168818]\n",
            "******* 1089 780 [D loss: 0.126818, acc: 96.09%] [G loss: 3.719428]\n",
            "******* 1090 780 [D loss: 0.233356, acc: 91.41%] [G loss: 3.090400]\n",
            "******* 1091 780 [D loss: 0.161409, acc: 95.31%] [G loss: 2.950929]\n",
            "******* 1092 780 [D loss: 0.208471, acc: 89.84%] [G loss: 4.321959]\n",
            "******* 1093 780 [D loss: 0.082184, acc: 98.44%] [G loss: 5.113174]\n",
            "******* 1094 780 [D loss: 0.070453, acc: 96.88%] [G loss: 6.036142]\n",
            "******* 1095 780 [D loss: 0.146074, acc: 93.75%] [G loss: 6.565884]\n",
            "******* 1096 780 [D loss: 0.200413, acc: 92.19%] [G loss: 4.135032]\n",
            "******* 1097 780 [D loss: 0.328628, acc: 86.72%] [G loss: 4.358496]\n",
            "******* 1098 780 [D loss: 0.069428, acc: 97.66%] [G loss: 5.833817]\n",
            "******* 1099 780 [D loss: 0.226964, acc: 92.19%] [G loss: 6.088062]\n",
            "******* 1100 780 [D loss: 0.175187, acc: 93.75%] [G loss: 6.082913]\n",
            "******* 1101 780 [D loss: 0.083796, acc: 95.31%] [G loss: 5.621494]\n",
            "******* 1102 780 [D loss: 0.051705, acc: 99.22%] [G loss: 5.062817]\n",
            "******* 1103 780 [D loss: 0.180286, acc: 93.75%] [G loss: 5.243125]\n",
            "******* 1104 780 [D loss: 0.134414, acc: 95.31%] [G loss: 5.458915]\n",
            "******* 1105 780 [D loss: 0.067623, acc: 97.66%] [G loss: 6.443036]\n",
            "******* 1106 780 [D loss: 0.056943, acc: 98.44%] [G loss: 7.739394]\n",
            "******* 1107 780 [D loss: 0.062527, acc: 97.66%] [G loss: 7.262952]\n",
            "******* 1108 780 [D loss: 0.068607, acc: 96.09%] [G loss: 6.614972]\n",
            "******* 1109 780 [D loss: 0.083298, acc: 96.88%] [G loss: 5.972008]\n",
            "******* 1110 780 [D loss: 0.101659, acc: 96.09%] [G loss: 5.614250]\n",
            "******* 1111 780 [D loss: 0.140137, acc: 92.97%] [G loss: 6.254548]\n",
            "******* 1112 780 [D loss: 0.162227, acc: 94.53%] [G loss: 6.786902]\n",
            "******* 1113 780 [D loss: 0.156286, acc: 94.53%] [G loss: 5.486062]\n",
            "******* 1114 780 [D loss: 0.150886, acc: 96.88%] [G loss: 4.535763]\n",
            "******* 1115 780 [D loss: 0.216243, acc: 88.28%] [G loss: 5.622141]\n",
            "******* 1116 780 [D loss: 0.079450, acc: 96.88%] [G loss: 6.787362]\n",
            "******* 1117 780 [D loss: 0.115666, acc: 96.09%] [G loss: 7.310659]\n",
            "******* 1118 780 [D loss: 0.084169, acc: 97.66%] [G loss: 5.786895]\n",
            "******* 1119 780 [D loss: 0.149352, acc: 95.31%] [G loss: 5.288835]\n",
            "******* 1120 780 [D loss: 0.232583, acc: 89.84%] [G loss: 5.050341]\n",
            "******* 1121 780 [D loss: 0.017709, acc: 100.00%] [G loss: 7.411060]\n",
            "******* 1122 780 [D loss: 0.148602, acc: 94.53%] [G loss: 7.332911]\n",
            "******* 1123 780 [D loss: 0.129260, acc: 93.75%] [G loss: 5.998409]\n",
            "******* 1124 780 [D loss: 0.088146, acc: 96.88%] [G loss: 4.101233]\n",
            "******* 1125 780 [D loss: 0.122373, acc: 93.75%] [G loss: 4.391783]\n",
            "******* 1126 780 [D loss: 0.121685, acc: 94.53%] [G loss: 5.351721]\n",
            "******* 1127 780 [D loss: 0.052808, acc: 98.44%] [G loss: 6.640193]\n",
            "******* 1128 780 [D loss: 0.194328, acc: 95.31%] [G loss: 6.358173]\n",
            "******* 1129 780 [D loss: 0.087000, acc: 97.66%] [G loss: 5.568944]\n",
            "******* 1130 780 [D loss: 0.042311, acc: 99.22%] [G loss: 5.778734]\n",
            "******* 1131 780 [D loss: 0.031083, acc: 100.00%] [G loss: 6.010631]\n",
            "******* 1132 780 [D loss: 0.080605, acc: 96.88%] [G loss: 6.046782]\n",
            "******* 1133 780 [D loss: 0.016417, acc: 100.00%] [G loss: 6.485828]\n",
            "******* 1134 780 [D loss: 0.149530, acc: 95.31%] [G loss: 6.596639]\n",
            "******* 1135 780 [D loss: 0.050579, acc: 97.66%] [G loss: 6.001328]\n",
            "******* 1136 780 [D loss: 0.081757, acc: 96.88%] [G loss: 6.235663]\n",
            "******* 1137 780 [D loss: 0.057187, acc: 97.66%] [G loss: 6.629998]\n",
            "******* 1138 780 [D loss: 0.064707, acc: 97.66%] [G loss: 6.269179]\n",
            "******* 1139 780 [D loss: 0.085123, acc: 96.09%] [G loss: 5.613907]\n",
            "******* 1140 780 [D loss: 0.196106, acc: 92.19%] [G loss: 6.635714]\n",
            "******* 1141 780 [D loss: 0.084243, acc: 97.66%] [G loss: 9.237324]\n",
            "******* 1142 780 [D loss: 0.295667, acc: 89.84%] [G loss: 4.334906]\n",
            "******* 1143 780 [D loss: 0.747614, acc: 75.78%] [G loss: 9.887403]\n",
            "******* 1144 780 [D loss: 0.212356, acc: 91.41%] [G loss: 14.111748]\n",
            "******* 1145 780 [D loss: 1.063987, acc: 75.78%] [G loss: 8.094236]\n",
            "******* 1146 780 [D loss: 0.409843, acc: 85.16%] [G loss: 3.068638]\n",
            "******* 1147 780 [D loss: 0.580907, acc: 78.91%] [G loss: 6.069289]\n",
            "******* 1148 780 [D loss: 0.162054, acc: 92.97%] [G loss: 8.747944]\n",
            "******* 1149 780 [D loss: 0.187179, acc: 93.75%] [G loss: 9.092816]\n",
            "******* 1150 780 [D loss: 0.150397, acc: 96.09%] [G loss: 7.957705]\n",
            "******* 1151 780 [D loss: 0.156364, acc: 94.53%] [G loss: 7.295475]\n",
            "******* 1152 780 [D loss: 0.119246, acc: 96.88%] [G loss: 7.131746]\n",
            "******* 1153 780 [D loss: 0.060147, acc: 97.66%] [G loss: 7.776134]\n",
            "******* 1154 780 [D loss: 0.118476, acc: 95.31%] [G loss: 6.860905]\n",
            "******* 1155 780 [D loss: 0.117229, acc: 96.09%] [G loss: 6.941554]\n",
            "******* 1156 780 [D loss: 0.125507, acc: 94.53%] [G loss: 5.710034]\n",
            "******* 1157 780 [D loss: 0.150554, acc: 94.53%] [G loss: 6.462109]\n",
            "******* 1158 780 [D loss: 0.067405, acc: 97.66%] [G loss: 7.437710]\n",
            "******* 1159 780 [D loss: 0.337917, acc: 87.50%] [G loss: 5.906115]\n",
            "******* 1160 780 [D loss: 0.531283, acc: 83.59%] [G loss: 4.801795]\n",
            "******* 1161 780 [D loss: 0.296021, acc: 89.06%] [G loss: 5.454106]\n",
            "******* 1162 780 [D loss: 0.497738, acc: 77.34%] [G loss: 6.284022]\n",
            "******* 1163 780 [D loss: 0.201088, acc: 92.97%] [G loss: 8.701946]\n",
            "******* 1164 780 [D loss: 1.236156, acc: 71.88%] [G loss: 5.258514]\n",
            "******* 1165 780 [D loss: 0.652180, acc: 73.44%] [G loss: 2.439799]\n",
            "******* 1166 780 [D loss: 0.424148, acc: 78.12%] [G loss: 1.760958]\n",
            "******* 1167 780 [D loss: 0.339217, acc: 82.81%] [G loss: 2.355580]\n",
            "******* 1168 780 [D loss: 0.239944, acc: 89.84%] [G loss: 2.791780]\n",
            "******* 1169 780 [D loss: 0.193046, acc: 92.97%] [G loss: 3.418475]\n",
            "******* 1170 780 [D loss: 0.189085, acc: 91.41%] [G loss: 4.049985]\n",
            "******* 1171 780 [D loss: 0.179447, acc: 93.75%] [G loss: 3.829671]\n",
            "******* 1172 780 [D loss: 0.173816, acc: 92.97%] [G loss: 3.829386]\n",
            "******* 1173 780 [D loss: 0.139372, acc: 94.53%] [G loss: 3.699795]\n",
            "******* 1174 780 [D loss: 0.175420, acc: 93.75%] [G loss: 3.709635]\n",
            "******* 1175 780 [D loss: 0.133825, acc: 95.31%] [G loss: 3.559400]\n",
            "******* 1176 780 [D loss: 0.083842, acc: 98.44%] [G loss: 4.295941]\n",
            "******* 1177 780 [D loss: 0.091212, acc: 98.44%] [G loss: 4.163968]\n",
            "******* 1178 780 [D loss: 0.092931, acc: 96.09%] [G loss: 4.464265]\n",
            "******* 1179 780 [D loss: 0.087225, acc: 97.66%] [G loss: 4.400781]\n",
            "******* 1180 780 [D loss: 0.111144, acc: 96.09%] [G loss: 5.064141]\n",
            "******* 1181 780 [D loss: 0.051567, acc: 97.66%] [G loss: 4.436688]\n",
            "******* 1182 780 [D loss: 0.066328, acc: 97.66%] [G loss: 4.175588]\n",
            "******* 1183 780 [D loss: 0.080182, acc: 98.44%] [G loss: 4.084540]\n",
            "******* 1184 780 [D loss: 0.156609, acc: 95.31%] [G loss: 3.913129]\n",
            "******* 1185 780 [D loss: 0.070320, acc: 98.44%] [G loss: 4.394852]\n",
            "******* 1186 780 [D loss: 0.054305, acc: 99.22%] [G loss: 4.132188]\n",
            "******* 1187 780 [D loss: 0.206853, acc: 96.88%] [G loss: 4.553185]\n",
            "******* 1188 780 [D loss: 0.135571, acc: 96.88%] [G loss: 3.494077]\n",
            "******* 1189 780 [D loss: 0.122999, acc: 96.09%] [G loss: 3.683706]\n",
            "******* 1190 780 [D loss: 0.115459, acc: 96.09%] [G loss: 3.667789]\n",
            "******* 1191 780 [D loss: 0.113050, acc: 96.88%] [G loss: 3.130275]\n",
            "******* 1192 780 [D loss: 0.156762, acc: 95.31%] [G loss: 3.167482]\n",
            "******* 1193 780 [D loss: 0.196909, acc: 96.09%] [G loss: 3.503722]\n",
            "******* 1194 780 [D loss: 0.339122, acc: 93.75%] [G loss: 3.026907]\n",
            "******* 1195 780 [D loss: 0.212769, acc: 94.53%] [G loss: 3.355426]\n",
            "******* 1196 780 [D loss: 0.153406, acc: 95.31%] [G loss: 3.131651]\n",
            "******* 1197 780 [D loss: 0.111022, acc: 96.88%] [G loss: 3.269442]\n",
            "******* 1198 780 [D loss: 0.098557, acc: 96.09%] [G loss: 3.839900]\n",
            "******* 1199 780 [D loss: 0.181625, acc: 92.97%] [G loss: 3.235209]\n",
            "******* 1200 780 [D loss: 0.112106, acc: 96.09%] [G loss: 3.136829]\n",
            "******* 1201 780 [D loss: 0.087336, acc: 97.66%] [G loss: 3.142199]\n",
            "******* 1202 780 [D loss: 0.094197, acc: 96.09%] [G loss: 3.828875]\n",
            "******* 1203 780 [D loss: 0.105926, acc: 96.09%] [G loss: 3.784454]\n",
            "******* 1204 780 [D loss: 0.048620, acc: 99.22%] [G loss: 4.145737]\n",
            "******* 1205 780 [D loss: 0.088715, acc: 96.88%] [G loss: 4.595161]\n",
            "******* 1206 780 [D loss: 0.064464, acc: 98.44%] [G loss: 4.615650]\n",
            "******* 1207 780 [D loss: 0.042271, acc: 98.44%] [G loss: 4.278010]\n",
            "******* 1208 780 [D loss: 0.040026, acc: 98.44%] [G loss: 4.765281]\n",
            "******* 1209 780 [D loss: 0.133313, acc: 95.31%] [G loss: 3.752964]\n",
            "******* 1210 780 [D loss: 0.075781, acc: 97.66%] [G loss: 3.691995]\n",
            "******* 1211 780 [D loss: 0.084372, acc: 96.88%] [G loss: 4.984524]\n",
            "******* 1212 780 [D loss: 0.112266, acc: 96.09%] [G loss: 3.966109]\n",
            "******* 1213 780 [D loss: 0.155966, acc: 92.97%] [G loss: 3.768179]\n",
            "******* 1214 780 [D loss: 0.105618, acc: 98.44%] [G loss: 4.426572]\n",
            "******* 1215 780 [D loss: 0.073150, acc: 99.22%] [G loss: 5.685485]\n",
            "******* 1216 780 [D loss: 0.149032, acc: 93.75%] [G loss: 4.851755]\n",
            "******* 1217 780 [D loss: 0.133141, acc: 95.31%] [G loss: 4.727258]\n",
            "******* 1218 780 [D loss: 0.256238, acc: 88.28%] [G loss: 4.225988]\n",
            "******* 1219 780 [D loss: 0.182949, acc: 93.75%] [G loss: 4.161520]\n",
            "******* 1220 780 [D loss: 0.405523, acc: 84.38%] [G loss: 4.681329]\n",
            "******* 1221 780 [D loss: 0.161036, acc: 92.97%] [G loss: 4.622218]\n",
            "******* 1222 780 [D loss: 0.090202, acc: 96.09%] [G loss: 4.387204]\n",
            "******* 1223 780 [D loss: 0.167555, acc: 91.41%] [G loss: 4.209519]\n",
            "******* 1224 780 [D loss: 0.173339, acc: 96.09%] [G loss: 4.453052]\n",
            "******* 1225 780 [D loss: 0.177091, acc: 92.97%] [G loss: 4.605739]\n",
            "******* 1226 780 [D loss: 0.241554, acc: 92.97%] [G loss: 4.452922]\n",
            "******* 1227 780 [D loss: 0.232351, acc: 92.19%] [G loss: 3.987288]\n",
            "******* 1228 780 [D loss: 0.320100, acc: 85.94%] [G loss: 5.052857]\n",
            "******* 1229 780 [D loss: 0.181037, acc: 92.97%] [G loss: 5.613292]\n",
            "******* 1230 780 [D loss: 0.131960, acc: 94.53%] [G loss: 5.644086]\n",
            "******* 1231 780 [D loss: 0.289670, acc: 87.50%] [G loss: 5.378801]\n",
            "******* 1232 780 [D loss: 0.149619, acc: 93.75%] [G loss: 4.959163]\n",
            "******* 1233 780 [D loss: 0.130167, acc: 94.53%] [G loss: 7.683636]\n",
            "******* 1234 780 [D loss: 0.203127, acc: 95.31%] [G loss: 6.233942]\n",
            "******* 1235 780 [D loss: 0.050641, acc: 98.44%] [G loss: 6.152589]\n",
            "******* 1236 780 [D loss: 0.107683, acc: 96.88%] [G loss: 4.839898]\n",
            "******* 1237 780 [D loss: 0.250212, acc: 89.84%] [G loss: 5.994265]\n",
            "******* 1238 780 [D loss: 0.114143, acc: 96.09%] [G loss: 8.450940]\n",
            "******* 1239 780 [D loss: 0.135974, acc: 95.31%] [G loss: 7.420719]\n",
            "******* 1240 780 [D loss: 0.340486, acc: 92.97%] [G loss: 6.251230]\n",
            "******* 1241 780 [D loss: 0.170872, acc: 96.88%] [G loss: 5.541874]\n",
            "******* 1242 780 [D loss: 0.067288, acc: 97.66%] [G loss: 5.481056]\n",
            "******* 1243 780 [D loss: 0.123041, acc: 96.09%] [G loss: 6.351647]\n",
            "******* 1244 780 [D loss: 0.068274, acc: 99.22%] [G loss: 7.553345]\n",
            "******* 1245 780 [D loss: 0.063642, acc: 96.88%] [G loss: 6.869006]\n",
            "******* 1246 780 [D loss: 0.225395, acc: 92.97%] [G loss: 5.089227]\n",
            "******* 1247 780 [D loss: 0.192194, acc: 91.41%] [G loss: 4.120076]\n",
            "******* 1248 780 [D loss: 0.275759, acc: 90.62%] [G loss: 4.802684]\n",
            "******* 1249 780 [D loss: 0.147124, acc: 93.75%] [G loss: 4.931517]\n",
            "******* 1250 780 [D loss: 0.392398, acc: 82.03%] [G loss: 3.540936]\n",
            "******* 1251 780 [D loss: 0.410504, acc: 88.28%] [G loss: 4.985724]\n",
            "******* 1252 780 [D loss: 0.054904, acc: 96.88%] [G loss: 7.885866]\n",
            "******* 1253 780 [D loss: 0.576099, acc: 82.03%] [G loss: 5.668456]\n",
            "******* 1254 780 [D loss: 0.424434, acc: 83.59%] [G loss: 4.251894]\n",
            "******* 1255 780 [D loss: 0.260521, acc: 89.84%] [G loss: 4.755137]\n",
            "******* 1256 780 [D loss: 0.147454, acc: 93.75%] [G loss: 4.498413]\n",
            "******* 1257 780 [D loss: 0.350847, acc: 85.16%] [G loss: 5.474230]\n",
            "******* 1258 780 [D loss: 0.440441, acc: 84.38%] [G loss: 5.299121]\n",
            "******* 1259 780 [D loss: 0.317400, acc: 86.72%] [G loss: 4.280107]\n",
            "******* 1260 780 [D loss: 0.241810, acc: 88.28%] [G loss: 3.976397]\n",
            "******* 1261 780 [D loss: 0.134063, acc: 94.53%] [G loss: 3.919066]\n",
            "******* 1262 780 [D loss: 0.184353, acc: 92.19%] [G loss: 3.811414]\n",
            "******* 1263 780 [D loss: 0.199319, acc: 92.19%] [G loss: 4.342484]\n",
            "******* 1264 780 [D loss: 0.152218, acc: 95.31%] [G loss: 3.549157]\n",
            "******* 1265 780 [D loss: 0.303091, acc: 87.50%] [G loss: 4.189569]\n",
            "******* 1266 780 [D loss: 0.261231, acc: 89.06%] [G loss: 3.446890]\n",
            "******* 1267 780 [D loss: 0.247882, acc: 89.06%] [G loss: 3.849438]\n",
            "******* 1268 780 [D loss: 0.302912, acc: 89.84%] [G loss: 3.450767]\n",
            "******* 1269 780 [D loss: 0.334396, acc: 86.72%] [G loss: 3.076246]\n",
            "******* 1270 780 [D loss: 0.388641, acc: 81.25%] [G loss: 2.526732]\n",
            "******* 1271 780 [D loss: 0.390511, acc: 80.47%] [G loss: 2.278676]\n",
            "******* 1272 780 [D loss: 0.276995, acc: 91.41%] [G loss: 2.413768]\n",
            "******* 1273 780 [D loss: 0.322392, acc: 84.38%] [G loss: 3.066578]\n",
            "******* 1274 780 [D loss: 0.241993, acc: 89.06%] [G loss: 3.408803]\n",
            "******* 1275 780 [D loss: 0.283392, acc: 87.50%] [G loss: 3.449155]\n",
            "******* 1276 780 [D loss: 0.233232, acc: 90.62%] [G loss: 2.751778]\n",
            "******* 1277 780 [D loss: 0.159285, acc: 95.31%] [G loss: 2.799667]\n",
            "******* 1278 780 [D loss: 0.110402, acc: 96.88%] [G loss: 3.413227]\n",
            "******* 1279 780 [D loss: 0.142208, acc: 94.53%] [G loss: 3.356501]\n",
            "******* 1280 780 [D loss: 0.072753, acc: 98.44%] [G loss: 3.812427]\n",
            "******* 1281 780 [D loss: 0.140996, acc: 96.88%] [G loss: 3.481024]\n",
            "******* 1282 780 [D loss: 0.096518, acc: 98.44%] [G loss: 3.970827]\n",
            "******* 1283 780 [D loss: 0.088031, acc: 97.66%] [G loss: 3.833014]\n",
            "******* 1284 780 [D loss: 0.114668, acc: 96.09%] [G loss: 3.803481]\n",
            "******* 1285 780 [D loss: 0.078100, acc: 96.88%] [G loss: 3.593845]\n",
            "******* 1286 780 [D loss: 0.088735, acc: 97.66%] [G loss: 4.109081]\n",
            "******* 1287 780 [D loss: 0.066261, acc: 98.44%] [G loss: 4.224210]\n",
            "******* 1288 780 [D loss: 0.065628, acc: 97.66%] [G loss: 4.760508]\n",
            "******* 1289 780 [D loss: 0.057935, acc: 98.44%] [G loss: 4.862875]\n",
            "******* 1290 780 [D loss: 0.062869, acc: 98.44%] [G loss: 4.694844]\n",
            "******* 1291 780 [D loss: 0.097001, acc: 97.66%] [G loss: 3.528003]\n",
            "******* 1292 780 [D loss: 0.088725, acc: 96.88%] [G loss: 2.956955]\n",
            "******* 1293 780 [D loss: 0.133964, acc: 96.88%] [G loss: 3.589728]\n",
            "******* 1294 780 [D loss: 0.075129, acc: 98.44%] [G loss: 3.909150]\n",
            "******* 1295 780 [D loss: 0.048722, acc: 99.22%] [G loss: 4.915110]\n",
            "******* 1296 780 [D loss: 0.082193, acc: 95.31%] [G loss: 4.766763]\n",
            "******* 1297 780 [D loss: 0.078362, acc: 96.88%] [G loss: 4.521213]\n",
            "******* 1298 780 [D loss: 0.042341, acc: 99.22%] [G loss: 3.899570]\n",
            "******* 1299 780 [D loss: 0.108901, acc: 95.31%] [G loss: 3.952487]\n",
            "******* 1300 780 [D loss: 0.147299, acc: 93.75%] [G loss: 4.010012]\n",
            "******* 1301 780 [D loss: 0.090616, acc: 96.88%] [G loss: 4.245715]\n",
            "******* 1302 780 [D loss: 0.129223, acc: 96.88%] [G loss: 4.188238]\n",
            "******* 1303 780 [D loss: 0.159842, acc: 96.88%] [G loss: 3.717433]\n",
            "******* 1304 780 [D loss: 0.112531, acc: 95.31%] [G loss: 3.395152]\n",
            "******* 1305 780 [D loss: 0.110393, acc: 96.09%] [G loss: 3.985465]\n",
            "******* 1306 780 [D loss: 0.078528, acc: 97.66%] [G loss: 4.582006]\n",
            "******* 1307 780 [D loss: 0.055731, acc: 99.22%] [G loss: 4.953176]\n",
            "******* 1308 780 [D loss: 0.229643, acc: 89.84%] [G loss: 3.573344]\n",
            "******* 1309 780 [D loss: 0.143085, acc: 92.97%] [G loss: 4.237782]\n",
            "******* 1310 780 [D loss: 0.074256, acc: 98.44%] [G loss: 5.384161]\n",
            "******* 1311 780 [D loss: 0.105193, acc: 96.88%] [G loss: 5.462247]\n",
            "******* 1312 780 [D loss: 0.111033, acc: 95.31%] [G loss: 4.400216]\n",
            "******* 1313 780 [D loss: 0.073681, acc: 97.66%] [G loss: 3.997693]\n",
            "******* 1314 780 [D loss: 0.203101, acc: 93.75%] [G loss: 3.802480]\n",
            "******* 1315 780 [D loss: 0.036054, acc: 98.44%] [G loss: 4.479208]\n",
            "******* 1316 780 [D loss: 0.086874, acc: 97.66%] [G loss: 4.298841]\n",
            "******* 1317 780 [D loss: 0.132856, acc: 93.75%] [G loss: 4.203374]\n",
            "******* 1318 780 [D loss: 0.108209, acc: 95.31%] [G loss: 3.998931]\n",
            "******* 1319 780 [D loss: 0.092606, acc: 97.66%] [G loss: 4.646215]\n",
            "******* 1320 780 [D loss: 0.105540, acc: 95.31%] [G loss: 4.217722]\n",
            "******* 1321 780 [D loss: 0.038427, acc: 100.00%] [G loss: 4.553547]\n",
            "******* 1322 780 [D loss: 0.097598, acc: 96.88%] [G loss: 4.597085]\n",
            "******* 1323 780 [D loss: 0.033730, acc: 98.44%] [G loss: 4.813935]\n",
            "******* 1324 780 [D loss: 0.046972, acc: 99.22%] [G loss: 4.464235]\n",
            "******* 1325 780 [D loss: 0.030334, acc: 100.00%] [G loss: 4.807851]\n",
            "******* 1326 780 [D loss: 0.013664, acc: 100.00%] [G loss: 4.946839]\n",
            "******* 1327 780 [D loss: 0.034985, acc: 99.22%] [G loss: 4.706428]\n",
            "******* 1328 780 [D loss: 0.025078, acc: 99.22%] [G loss: 4.742988]\n",
            "******* 1329 780 [D loss: 0.028329, acc: 100.00%] [G loss: 4.587456]\n",
            "******* 1330 780 [D loss: 0.044092, acc: 98.44%] [G loss: 4.740860]\n",
            "******* 1331 780 [D loss: 0.076126, acc: 98.44%] [G loss: 4.987958]\n",
            "******* 1332 780 [D loss: 0.041272, acc: 100.00%] [G loss: 5.659264]\n",
            "******* 1333 780 [D loss: 0.058450, acc: 97.66%] [G loss: 5.375793]\n",
            "******* 1334 780 [D loss: 0.078629, acc: 97.66%] [G loss: 4.269187]\n",
            "******* 1335 780 [D loss: 0.046344, acc: 100.00%] [G loss: 4.434254]\n",
            "******* 1336 780 [D loss: 0.061294, acc: 97.66%] [G loss: 4.809485]\n",
            "******* 1337 780 [D loss: 0.113224, acc: 96.09%] [G loss: 4.287930]\n",
            "******* 1338 780 [D loss: 0.085837, acc: 96.88%] [G loss: 4.953068]\n",
            "******* 1339 780 [D loss: 0.103718, acc: 96.09%] [G loss: 5.228683]\n",
            "******* 1340 780 [D loss: 0.047112, acc: 97.66%] [G loss: 5.948407]\n",
            "******* 1341 780 [D loss: 0.098252, acc: 97.66%] [G loss: 4.919633]\n",
            "******* 1342 780 [D loss: 0.158762, acc: 93.75%] [G loss: 6.682740]\n",
            "******* 1343 780 [D loss: 0.082465, acc: 96.88%] [G loss: 7.306072]\n",
            "******* 1344 780 [D loss: 0.213866, acc: 93.75%] [G loss: 5.291837]\n",
            "******* 1345 780 [D loss: 0.149736, acc: 94.53%] [G loss: 7.635543]\n",
            "******* 1346 780 [D loss: 0.103755, acc: 95.31%] [G loss: 8.464612]\n",
            "******* 1347 780 [D loss: 0.588459, acc: 78.12%] [G loss: 7.727728]\n",
            "******* 1348 780 [D loss: 0.070717, acc: 96.88%] [G loss: 8.896401]\n",
            "******* 1349 780 [D loss: 0.280042, acc: 86.72%] [G loss: 3.454787]\n",
            "******* 1350 780 [D loss: 0.806094, acc: 74.22%] [G loss: 8.202616]\n",
            "******* 1351 780 [D loss: 0.123464, acc: 96.09%] [G loss: 12.817505]\n",
            "******* 1352 780 [D loss: 1.126031, acc: 68.75%] [G loss: 9.335492]\n",
            "******* 1353 780 [D loss: 0.263852, acc: 90.62%] [G loss: 3.973922]\n",
            "******* 1354 780 [D loss: 0.770650, acc: 79.69%] [G loss: 5.318644]\n",
            "******* 1355 780 [D loss: 0.076008, acc: 97.66%] [G loss: 8.897320]\n",
            "******* 1356 780 [D loss: 0.049644, acc: 99.22%] [G loss: 8.860877]\n",
            "******* 1357 780 [D loss: 0.237919, acc: 90.62%] [G loss: 7.090601]\n",
            "******* 1358 780 [D loss: 0.244301, acc: 89.84%] [G loss: 4.707413]\n",
            "******* 1359 780 [D loss: 0.290926, acc: 90.62%] [G loss: 4.725731]\n",
            "******* 1360 780 [D loss: 0.095474, acc: 96.09%] [G loss: 5.318047]\n",
            "******* 1361 780 [D loss: 0.228185, acc: 92.97%] [G loss: 6.130076]\n",
            "******* 1362 780 [D loss: 0.080319, acc: 97.66%] [G loss: 6.112952]\n",
            "******* 1363 780 [D loss: 0.079427, acc: 97.66%] [G loss: 5.474446]\n",
            "******* 1364 780 [D loss: 0.097293, acc: 95.31%] [G loss: 5.062686]\n",
            "******* 1365 780 [D loss: 0.136829, acc: 96.88%] [G loss: 4.779223]\n",
            "******* 1366 780 [D loss: 0.103056, acc: 95.31%] [G loss: 4.036620]\n",
            "******* 1367 780 [D loss: 0.149814, acc: 96.09%] [G loss: 4.197511]\n",
            "******* 1368 780 [D loss: 0.111033, acc: 97.66%] [G loss: 4.025216]\n",
            "******* 1369 780 [D loss: 0.168441, acc: 92.97%] [G loss: 4.351385]\n",
            "******* 1370 780 [D loss: 0.172171, acc: 92.97%] [G loss: 3.779646]\n",
            "******* 1371 780 [D loss: 0.118409, acc: 95.31%] [G loss: 3.267292]\n",
            "******* 1372 780 [D loss: 0.183187, acc: 93.75%] [G loss: 3.184224]\n",
            "******* 1373 780 [D loss: 0.160885, acc: 95.31%] [G loss: 3.403876]\n",
            "******* 1374 780 [D loss: 0.087739, acc: 98.44%] [G loss: 3.691467]\n",
            "******* 1375 780 [D loss: 0.128610, acc: 96.09%] [G loss: 3.923131]\n",
            "******* 1376 780 [D loss: 0.142859, acc: 95.31%] [G loss: 3.684924]\n",
            "******* 1377 780 [D loss: 0.114367, acc: 96.09%] [G loss: 3.715165]\n",
            "******* 1378 780 [D loss: 0.099925, acc: 96.09%] [G loss: 4.030017]\n",
            "******* 1379 780 [D loss: 0.104001, acc: 96.88%] [G loss: 3.468477]\n",
            "******* 1380 780 [D loss: 0.136968, acc: 96.09%] [G loss: 3.597510]\n",
            "******* 1381 780 [D loss: 0.084962, acc: 96.88%] [G loss: 4.082968]\n",
            "******* 1382 780 [D loss: 0.055670, acc: 100.00%] [G loss: 4.393655]\n",
            "******* 1383 780 [D loss: 0.037300, acc: 99.22%] [G loss: 4.734756]\n",
            "******* 1384 780 [D loss: 0.071813, acc: 97.66%] [G loss: 5.033460]\n",
            "******* 1385 780 [D loss: 0.070217, acc: 97.66%] [G loss: 4.408376]\n",
            "******* 1386 780 [D loss: 0.069586, acc: 98.44%] [G loss: 4.303444]\n",
            "******* 1387 780 [D loss: 0.129184, acc: 95.31%] [G loss: 4.088405]\n",
            "******* 1388 780 [D loss: 0.122531, acc: 96.09%] [G loss: 5.447209]\n",
            "******* 1389 780 [D loss: 0.056324, acc: 98.44%] [G loss: 5.203793]\n",
            "******* 1390 780 [D loss: 0.081745, acc: 96.88%] [G loss: 4.319722]\n",
            "******* 1391 780 [D loss: 0.087259, acc: 97.66%] [G loss: 3.914049]\n",
            "******* 1392 780 [D loss: 0.072684, acc: 98.44%] [G loss: 4.104445]\n",
            "******* 1393 780 [D loss: 0.044733, acc: 99.22%] [G loss: 4.574003]\n",
            "******* 1394 780 [D loss: 0.090681, acc: 96.88%] [G loss: 4.942399]\n",
            "******* 1395 780 [D loss: 0.103613, acc: 96.88%] [G loss: 4.557498]\n",
            "******* 1396 780 [D loss: 0.187942, acc: 95.31%] [G loss: 3.465157]\n",
            "******* 1397 780 [D loss: 0.111076, acc: 94.53%] [G loss: 3.951342]\n",
            "******* 1398 780 [D loss: 0.134839, acc: 96.09%] [G loss: 4.752257]\n",
            "******* 1399 780 [D loss: 0.075806, acc: 96.88%] [G loss: 4.824924]\n",
            "******* 1400 780 [D loss: 0.096093, acc: 97.66%] [G loss: 4.411925]\n",
            "******* 1401 780 [D loss: 0.089777, acc: 98.44%] [G loss: 4.176926]\n",
            "******* 1402 780 [D loss: 0.209733, acc: 94.53%] [G loss: 2.874218]\n",
            "******* 1403 780 [D loss: 0.147389, acc: 94.53%] [G loss: 3.484076]\n",
            "******* 1404 780 [D loss: 0.304125, acc: 89.84%] [G loss: 3.938231]\n",
            "******* 1405 780 [D loss: 0.116439, acc: 96.88%] [G loss: 4.729058]\n",
            "******* 1406 780 [D loss: 0.125397, acc: 96.88%] [G loss: 5.198796]\n",
            "******* 1407 780 [D loss: 0.134258, acc: 93.75%] [G loss: 4.257152]\n",
            "******* 1408 780 [D loss: 0.152576, acc: 95.31%] [G loss: 3.158059]\n",
            "******* 1409 780 [D loss: 0.200463, acc: 91.41%] [G loss: 4.062671]\n",
            "******* 1410 780 [D loss: 0.044504, acc: 97.66%] [G loss: 5.410790]\n",
            "******* 1411 780 [D loss: 0.127569, acc: 94.53%] [G loss: 5.401516]\n",
            "******* 1412 780 [D loss: 0.074739, acc: 96.88%] [G loss: 5.220092]\n",
            "******* 1413 780 [D loss: 0.044392, acc: 100.00%] [G loss: 4.430023]\n",
            "******* 1414 780 [D loss: 0.114533, acc: 97.66%] [G loss: 4.216008]\n",
            "******* 1415 780 [D loss: 0.052391, acc: 98.44%] [G loss: 4.471661]\n",
            "******* 1416 780 [D loss: 0.059043, acc: 98.44%] [G loss: 4.680689]\n",
            "******* 1417 780 [D loss: 0.061236, acc: 97.66%] [G loss: 5.239618]\n",
            "******* 1418 780 [D loss: 0.153159, acc: 95.31%] [G loss: 4.425674]\n",
            "******* 1419 780 [D loss: 0.057073, acc: 99.22%] [G loss: 3.778883]\n",
            "******* 1420 780 [D loss: 0.080859, acc: 97.66%] [G loss: 3.839790]\n",
            "******* 1421 780 [D loss: 0.068179, acc: 97.66%] [G loss: 4.214867]\n",
            "******* 1422 780 [D loss: 0.150119, acc: 94.53%] [G loss: 4.647973]\n",
            "******* 1423 780 [D loss: 0.188931, acc: 93.75%] [G loss: 4.224344]\n",
            "******* 1424 780 [D loss: 0.190114, acc: 94.53%] [G loss: 3.589367]\n",
            "******* 1425 780 [D loss: 0.135230, acc: 95.31%] [G loss: 3.890390]\n",
            "******* 1426 780 [D loss: 0.087271, acc: 98.44%] [G loss: 4.705317]\n",
            "******* 1427 780 [D loss: 0.135493, acc: 93.75%] [G loss: 4.578048]\n",
            "******* 1428 780 [D loss: 0.225558, acc: 91.41%] [G loss: 3.779032]\n",
            "******* 1429 780 [D loss: 0.160490, acc: 94.53%] [G loss: 4.787868]\n",
            "******* 1430 780 [D loss: 0.140598, acc: 96.09%] [G loss: 5.474013]\n",
            "******* 1431 780 [D loss: 0.300188, acc: 87.50%] [G loss: 5.048175]\n",
            "******* 1432 780 [D loss: 0.133455, acc: 96.09%] [G loss: 5.748789]\n",
            "******* 1433 780 [D loss: 0.130570, acc: 96.09%] [G loss: 4.359209]\n",
            "******* 1434 780 [D loss: 0.315198, acc: 88.28%] [G loss: 5.358749]\n",
            "******* 1435 780 [D loss: 0.126573, acc: 95.31%] [G loss: 5.179037]\n",
            "******* 1436 780 [D loss: 0.065313, acc: 96.09%] [G loss: 5.742044]\n",
            "******* 1437 780 [D loss: 0.064468, acc: 98.44%] [G loss: 5.268153]\n",
            "******* 1438 780 [D loss: 0.180855, acc: 93.75%] [G loss: 6.512266]\n",
            "******* 1439 780 [D loss: 0.090961, acc: 95.31%] [G loss: 6.052014]\n",
            "******* 1440 780 [D loss: 0.084501, acc: 96.88%] [G loss: 4.937651]\n",
            "******* 1441 780 [D loss: 0.084222, acc: 98.44%] [G loss: 4.793967]\n",
            "******* 1442 780 [D loss: 0.234837, acc: 91.41%] [G loss: 5.037597]\n",
            "******* 1443 780 [D loss: 0.057223, acc: 98.44%] [G loss: 7.049600]\n",
            "******* 1444 780 [D loss: 0.207334, acc: 93.75%] [G loss: 5.711792]\n",
            "******* 1445 780 [D loss: 0.139813, acc: 95.31%] [G loss: 4.882698]\n",
            "******* 1446 780 [D loss: 0.313837, acc: 89.06%] [G loss: 3.630769]\n",
            "******* 1447 780 [D loss: 0.345861, acc: 81.25%] [G loss: 3.704885]\n",
            "******* 1448 780 [D loss: 0.126512, acc: 95.31%] [G loss: 5.090725]\n",
            "******* 1449 780 [D loss: 0.247092, acc: 93.75%] [G loss: 4.660926]\n",
            "******* 1450 780 [D loss: 0.358312, acc: 87.50%] [G loss: 3.573188]\n",
            "******* 1451 780 [D loss: 0.318082, acc: 89.84%] [G loss: 3.191312]\n",
            "******* 1452 780 [D loss: 0.217395, acc: 90.62%] [G loss: 4.101923]\n",
            "******* 1453 780 [D loss: 0.321001, acc: 90.62%] [G loss: 3.487321]\n",
            "******* 1454 780 [D loss: 0.268860, acc: 90.62%] [G loss: 3.002059]\n",
            "******* 1455 780 [D loss: 0.161624, acc: 95.31%] [G loss: 3.224018]\n",
            "******* 1456 780 [D loss: 0.192912, acc: 91.41%] [G loss: 4.247231]\n",
            "******* 1457 780 [D loss: 0.114172, acc: 96.88%] [G loss: 4.379307]\n",
            "******* 1458 780 [D loss: 0.178193, acc: 93.75%] [G loss: 3.293477]\n",
            "******* 1459 780 [D loss: 0.151109, acc: 94.53%] [G loss: 3.302345]\n",
            "******* 1460 780 [D loss: 0.165200, acc: 92.19%] [G loss: 3.824443]\n",
            "******* 1461 780 [D loss: 0.072784, acc: 99.22%] [G loss: 4.197566]\n",
            "******* 1462 780 [D loss: 0.150964, acc: 92.97%] [G loss: 3.812419]\n",
            "******* 1463 780 [D loss: 0.232744, acc: 89.84%] [G loss: 4.248886]\n",
            "******* 1464 780 [D loss: 0.146912, acc: 92.97%] [G loss: 5.498990]\n",
            "******* 1465 780 [D loss: 0.198136, acc: 90.62%] [G loss: 5.519732]\n",
            "******* 1466 780 [D loss: 0.071912, acc: 96.88%] [G loss: 4.532098]\n",
            "******* 1467 780 [D loss: 0.182342, acc: 92.19%] [G loss: 3.560825]\n",
            "******* 1468 780 [D loss: 0.192383, acc: 90.62%] [G loss: 4.531332]\n",
            "******* 1469 780 [D loss: 0.062153, acc: 98.44%] [G loss: 5.937641]\n",
            "******* 1470 780 [D loss: 0.212286, acc: 92.19%] [G loss: 4.522865]\n",
            "******* 1471 780 [D loss: 0.354403, acc: 86.72%] [G loss: 4.201129]\n",
            "******* 1472 780 [D loss: 0.153365, acc: 93.75%] [G loss: 5.411503]\n",
            "******* 1473 780 [D loss: 0.187580, acc: 90.62%] [G loss: 4.643342]\n",
            "******* 1474 780 [D loss: 0.218794, acc: 92.19%] [G loss: 4.061477]\n",
            "******* 1475 780 [D loss: 0.328720, acc: 87.50%] [G loss: 5.685116]\n",
            "******* 1476 780 [D loss: 0.150516, acc: 96.09%] [G loss: 6.698575]\n",
            "******* 1477 780 [D loss: 0.171092, acc: 92.19%] [G loss: 5.519173]\n",
            "******* 1478 780 [D loss: 0.231221, acc: 89.84%] [G loss: 3.950840]\n",
            "******* 1479 780 [D loss: 0.128082, acc: 95.31%] [G loss: 3.961283]\n",
            "******* 1480 780 [D loss: 0.091461, acc: 97.66%] [G loss: 5.186307]\n",
            "******* 1481 780 [D loss: 0.083444, acc: 95.31%] [G loss: 6.188020]\n",
            "******* 1482 780 [D loss: 0.072363, acc: 96.09%] [G loss: 5.566972]\n",
            "******* 1483 780 [D loss: 0.051996, acc: 98.44%] [G loss: 5.368869]\n",
            "******* 1484 780 [D loss: 0.054210, acc: 96.88%] [G loss: 5.916492]\n",
            "******* 1485 780 [D loss: 0.091876, acc: 97.66%] [G loss: 6.420962]\n",
            "******* 1486 780 [D loss: 0.251979, acc: 92.97%] [G loss: 6.088247]\n",
            "******* 1487 780 [D loss: 0.147147, acc: 93.75%] [G loss: 5.817667]\n",
            "******* 1488 780 [D loss: 0.130333, acc: 93.75%] [G loss: 5.288402]\n",
            "******* 1489 780 [D loss: 0.190285, acc: 92.19%] [G loss: 5.913151]\n",
            "******* 1490 780 [D loss: 0.059826, acc: 96.88%] [G loss: 6.638388]\n",
            "******* 1491 780 [D loss: 0.161739, acc: 94.53%] [G loss: 5.914709]\n",
            "******* 1492 780 [D loss: 0.106100, acc: 96.88%] [G loss: 4.972956]\n",
            "******* 1493 780 [D loss: 0.088445, acc: 96.09%] [G loss: 4.784496]\n",
            "******* 1494 780 [D loss: 0.111724, acc: 95.31%] [G loss: 5.116014]\n",
            "******* 1495 780 [D loss: 0.207174, acc: 91.41%] [G loss: 5.132305]\n",
            "******* 1496 780 [D loss: 0.204152, acc: 89.84%] [G loss: 5.681154]\n",
            "******* 1497 780 [D loss: 0.074768, acc: 97.66%] [G loss: 5.406819]\n",
            "******* 1498 780 [D loss: 0.220480, acc: 88.28%] [G loss: 5.262842]\n",
            "******* 1499 780 [D loss: 0.119783, acc: 96.88%] [G loss: 4.293710]\n",
            "******* 1500 780 [D loss: 0.184508, acc: 92.97%] [G loss: 4.313154]\n",
            "******* 1501 780 [D loss: 0.157617, acc: 94.53%] [G loss: 5.443500]\n",
            "******* 1502 780 [D loss: 0.342647, acc: 92.19%] [G loss: 4.334663]\n",
            "******* 1503 780 [D loss: 0.213182, acc: 94.53%] [G loss: 4.402119]\n",
            "******* 1504 780 [D loss: 0.195215, acc: 91.41%] [G loss: 3.688228]\n",
            "******* 1505 780 [D loss: 0.279204, acc: 89.84%] [G loss: 3.669778]\n",
            "******* 1506 780 [D loss: 0.200964, acc: 92.97%] [G loss: 3.993911]\n",
            "******* 1507 780 [D loss: 0.261301, acc: 88.28%] [G loss: 4.164350]\n",
            "******* 1508 780 [D loss: 0.111852, acc: 96.09%] [G loss: 4.924461]\n",
            "******* 1509 780 [D loss: 0.187785, acc: 90.62%] [G loss: 4.625016]\n",
            "******* 1510 780 [D loss: 0.255206, acc: 90.62%] [G loss: 3.799811]\n",
            "******* 1511 780 [D loss: 0.107000, acc: 96.88%] [G loss: 4.598198]\n",
            "******* 1512 780 [D loss: 0.096043, acc: 96.88%] [G loss: 4.458152]\n",
            "******* 1513 780 [D loss: 0.106685, acc: 96.09%] [G loss: 4.627393]\n",
            "******* 1514 780 [D loss: 0.129170, acc: 96.09%] [G loss: 4.259485]\n",
            "******* 1515 780 [D loss: 0.177044, acc: 93.75%] [G loss: 4.698688]\n",
            "******* 1516 780 [D loss: 0.165735, acc: 92.97%] [G loss: 4.822577]\n",
            "******* 1517 780 [D loss: 0.128709, acc: 97.66%] [G loss: 5.477337]\n",
            "******* 1518 780 [D loss: 0.120042, acc: 94.53%] [G loss: 5.286494]\n",
            "******* 1519 780 [D loss: 0.141913, acc: 94.53%] [G loss: 4.786288]\n",
            "******* 1520 780 [D loss: 0.119782, acc: 93.75%] [G loss: 5.648917]\n",
            "******* 1521 780 [D loss: 0.070313, acc: 98.44%] [G loss: 5.665367]\n",
            "******* 1522 780 [D loss: 0.172546, acc: 93.75%] [G loss: 4.731471]\n",
            "******* 1523 780 [D loss: 0.042973, acc: 98.44%] [G loss: 5.020566]\n",
            "******* 1524 780 [D loss: 0.172179, acc: 92.19%] [G loss: 4.734805]\n",
            "******* 1525 780 [D loss: 0.130151, acc: 96.09%] [G loss: 4.209056]\n",
            "******* 1526 780 [D loss: 0.151903, acc: 93.75%] [G loss: 3.940217]\n",
            "******* 1527 780 [D loss: 0.148547, acc: 95.31%] [G loss: 4.597207]\n",
            "******* 1528 780 [D loss: 0.134624, acc: 95.31%] [G loss: 4.803796]\n",
            "******* 1529 780 [D loss: 0.247160, acc: 91.41%] [G loss: 3.797131]\n",
            "******* 1530 780 [D loss: 0.066546, acc: 98.44%] [G loss: 3.502167]\n",
            "******* 1531 780 [D loss: 0.106164, acc: 96.09%] [G loss: 3.379495]\n",
            "******* 1532 780 [D loss: 0.161075, acc: 92.97%] [G loss: 3.567239]\n",
            "******* 1533 780 [D loss: 0.102702, acc: 98.44%] [G loss: 4.203753]\n",
            "******* 1534 780 [D loss: 0.063782, acc: 96.88%] [G loss: 4.930977]\n",
            "******* 1535 780 [D loss: 0.083242, acc: 96.88%] [G loss: 5.425711]\n",
            "******* 1536 780 [D loss: 0.135229, acc: 95.31%] [G loss: 4.367586]\n",
            "******* 1537 780 [D loss: 0.143472, acc: 95.31%] [G loss: 3.714746]\n",
            "******* 1538 780 [D loss: 0.090856, acc: 98.44%] [G loss: 3.741921]\n",
            "******* 1539 780 [D loss: 0.114163, acc: 95.31%] [G loss: 4.647949]\n",
            "******* 1540 780 [D loss: 0.016647, acc: 100.00%] [G loss: 5.645380]\n",
            "******* 1541 780 [D loss: 0.062303, acc: 98.44%] [G loss: 5.922642]\n",
            "******* 1542 780 [D loss: 0.092178, acc: 95.31%] [G loss: 5.434620]\n",
            "******* 1543 780 [D loss: 0.066687, acc: 97.66%] [G loss: 4.561593]\n",
            "******* 1544 780 [D loss: 0.163309, acc: 93.75%] [G loss: 4.399821]\n",
            "******* 1545 780 [D loss: 0.029296, acc: 99.22%] [G loss: 5.254823]\n",
            "******* 1546 780 [D loss: 0.107846, acc: 95.31%] [G loss: 6.151391]\n",
            "******* 1547 780 [D loss: 0.125458, acc: 96.09%] [G loss: 4.662026]\n",
            "******* 1548 780 [D loss: 0.103125, acc: 97.66%] [G loss: 5.263735]\n",
            "******* 1549 780 [D loss: 0.141670, acc: 97.66%] [G loss: 4.905072]\n",
            "******* 1550 780 [D loss: 0.089435, acc: 96.88%] [G loss: 4.500113]\n",
            "******* 1551 780 [D loss: 0.121871, acc: 95.31%] [G loss: 4.996425]\n",
            "******* 1552 780 [D loss: 0.207507, acc: 92.97%] [G loss: 5.467828]\n",
            "******* 1553 780 [D loss: 0.122250, acc: 95.31%] [G loss: 6.634654]\n",
            "******* 1554 780 [D loss: 0.084435, acc: 96.09%] [G loss: 6.338301]\n",
            "******* 1555 780 [D loss: 0.216447, acc: 95.31%] [G loss: 5.689515]\n",
            "******* 1556 780 [D loss: 0.204967, acc: 92.19%] [G loss: 5.446828]\n",
            "******* 1557 780 [D loss: 0.098254, acc: 97.66%] [G loss: 6.597052]\n",
            "******* 1558 780 [D loss: 0.076852, acc: 96.88%] [G loss: 6.926769]\n",
            "******* 1559 780 [D loss: 0.170551, acc: 96.09%] [G loss: 5.875189]\n",
            "******* 1560 780 [D loss: 0.489541, acc: 86.72%] [G loss: 4.515431]\n",
            "******* 1561 780 [D loss: 0.095298, acc: 96.09%] [G loss: 5.284673]\n",
            "******* 1562 780 [D loss: 0.162925, acc: 96.88%] [G loss: 5.957106]\n",
            "******* 1563 780 [D loss: 0.021922, acc: 100.00%] [G loss: 6.455010]\n",
            "******* 1564 780 [D loss: 0.059264, acc: 97.66%] [G loss: 6.905015]\n",
            "******* 1565 780 [D loss: 0.066940, acc: 97.66%] [G loss: 6.579834]\n",
            "******* 1566 780 [D loss: 0.167973, acc: 94.53%] [G loss: 5.942915]\n",
            "******* 1567 780 [D loss: 0.124665, acc: 96.88%] [G loss: 7.300817]\n",
            "******* 1568 780 [D loss: 0.130213, acc: 96.88%] [G loss: 9.504919]\n",
            "******* 1569 780 [D loss: 0.171042, acc: 96.09%] [G loss: 6.792523]\n",
            "******* 1570 780 [D loss: 0.128417, acc: 94.53%] [G loss: 8.245005]\n",
            "******* 1571 780 [D loss: 0.034160, acc: 97.66%] [G loss: 9.312041]\n",
            "******* 1572 780 [D loss: 0.122151, acc: 96.88%] [G loss: 7.653041]\n",
            "******* 1573 780 [D loss: 0.150295, acc: 94.53%] [G loss: 7.216674]\n",
            "******* 1574 780 [D loss: 0.234829, acc: 93.75%] [G loss: 10.100861]\n",
            "******* 1575 780 [D loss: 0.231640, acc: 90.62%] [G loss: 9.042830]\n",
            "******* 1576 780 [D loss: 0.179427, acc: 92.19%] [G loss: 5.738914]\n",
            "******* 1577 780 [D loss: 0.554744, acc: 79.69%] [G loss: 8.253341]\n",
            "******* 1578 780 [D loss: 0.263023, acc: 92.97%] [G loss: 8.884099]\n",
            "******* 1579 780 [D loss: 0.380571, acc: 87.50%] [G loss: 4.014424]\n",
            "******* 1580 780 [D loss: 0.443555, acc: 78.91%] [G loss: 3.410370]\n",
            "******* 1581 780 [D loss: 0.070074, acc: 97.66%] [G loss: 5.541389]\n",
            "******* 1582 780 [D loss: 0.100778, acc: 96.09%] [G loss: 6.640106]\n",
            "******* 1583 780 [D loss: 0.414906, acc: 84.38%] [G loss: 3.286271]\n",
            "******* 1584 780 [D loss: 0.263180, acc: 89.84%] [G loss: 2.212492]\n",
            "******* 1585 780 [D loss: 0.220529, acc: 89.06%] [G loss: 3.084169]\n",
            "******* 1586 780 [D loss: 0.058344, acc: 99.22%] [G loss: 4.794426]\n",
            "******* 1587 780 [D loss: 0.093878, acc: 96.09%] [G loss: 5.316008]\n",
            "******* 1588 780 [D loss: 0.258976, acc: 89.84%] [G loss: 4.859565]\n",
            "******* 1589 780 [D loss: 0.168243, acc: 92.97%] [G loss: 3.531231]\n",
            "******* 1590 780 [D loss: 0.245755, acc: 88.28%] [G loss: 3.145115]\n",
            "******* 1591 780 [D loss: 0.125423, acc: 97.66%] [G loss: 3.627007]\n",
            "******* 1592 780 [D loss: 0.053042, acc: 99.22%] [G loss: 4.073165]\n",
            "******* 1593 780 [D loss: 0.055685, acc: 98.44%] [G loss: 4.273712]\n",
            "******* 1594 780 [D loss: 0.157653, acc: 92.19%] [G loss: 4.080714]\n",
            "******* 1595 780 [D loss: 0.054015, acc: 98.44%] [G loss: 4.193122]\n",
            "******* 1596 780 [D loss: 0.199245, acc: 92.19%] [G loss: 2.917683]\n",
            "******* 1597 780 [D loss: 0.145342, acc: 96.88%] [G loss: 2.978422]\n",
            "******* 1598 780 [D loss: 0.176095, acc: 92.97%] [G loss: 2.908149]\n",
            "******* 1599 780 [D loss: 0.174798, acc: 95.31%] [G loss: 3.533517]\n",
            "******* 1600 780 [D loss: 0.080026, acc: 97.66%] [G loss: 3.855866]\n",
            "******* 1601 780 [D loss: 0.106267, acc: 94.53%] [G loss: 4.420399]\n",
            "******* 1602 780 [D loss: 0.078413, acc: 95.31%] [G loss: 4.439845]\n",
            "******* 1603 780 [D loss: 0.061561, acc: 97.66%] [G loss: 4.384967]\n",
            "******* 1604 780 [D loss: 0.083929, acc: 97.66%] [G loss: 3.987604]\n",
            "******* 1605 780 [D loss: 0.095218, acc: 96.88%] [G loss: 3.784015]\n",
            "******* 1606 780 [D loss: 0.110985, acc: 93.75%] [G loss: 4.280760]\n",
            "******* 1607 780 [D loss: 0.054297, acc: 98.44%] [G loss: 4.084325]\n",
            "******* 1608 780 [D loss: 0.100743, acc: 98.44%] [G loss: 4.583462]\n",
            "******* 1609 780 [D loss: 0.060195, acc: 99.22%] [G loss: 4.644175]\n",
            "******* 1610 780 [D loss: 0.093955, acc: 97.66%] [G loss: 4.449119]\n",
            "******* 1611 780 [D loss: 0.157376, acc: 95.31%] [G loss: 3.725904]\n",
            "******* 1612 780 [D loss: 0.080876, acc: 98.44%] [G loss: 3.708322]\n",
            "******* 1613 780 [D loss: 0.077898, acc: 97.66%] [G loss: 4.270710]\n",
            "******* 1614 780 [D loss: 0.075074, acc: 96.09%] [G loss: 4.706285]\n",
            "******* 1615 780 [D loss: 0.037387, acc: 99.22%] [G loss: 5.376204]\n",
            "******* 1616 780 [D loss: 0.061596, acc: 99.22%] [G loss: 5.402748]\n",
            "******* 1617 780 [D loss: 0.011652, acc: 100.00%] [G loss: 5.390358]\n",
            "******* 1618 780 [D loss: 0.078327, acc: 97.66%] [G loss: 5.198638]\n",
            "******* 1619 780 [D loss: 0.066083, acc: 95.31%] [G loss: 4.886970]\n",
            "******* 1620 780 [D loss: 0.070906, acc: 98.44%] [G loss: 4.373740]\n",
            "******* 1621 780 [D loss: 0.076612, acc: 97.66%] [G loss: 4.035456]\n",
            "******* 1622 780 [D loss: 0.049710, acc: 98.44%] [G loss: 4.557752]\n",
            "******* 1623 780 [D loss: 0.070189, acc: 97.66%] [G loss: 4.520227]\n",
            "******* 1624 780 [D loss: 0.024348, acc: 99.22%] [G loss: 5.670629]\n",
            "******* 1625 780 [D loss: 0.074164, acc: 97.66%] [G loss: 5.415176]\n",
            "******* 1626 780 [D loss: 0.036285, acc: 99.22%] [G loss: 5.551097]\n",
            "******* 1627 780 [D loss: 0.121728, acc: 95.31%] [G loss: 4.051941]\n",
            "******* 1628 780 [D loss: 0.028227, acc: 100.00%] [G loss: 3.494729]\n",
            "******* 1629 780 [D loss: 0.087699, acc: 97.66%] [G loss: 4.122967]\n",
            "******* 1630 780 [D loss: 0.045309, acc: 98.44%] [G loss: 4.864617]\n",
            "******* 1631 780 [D loss: 0.126760, acc: 93.75%] [G loss: 4.720179]\n",
            "******* 1632 780 [D loss: 0.058488, acc: 97.66%] [G loss: 4.369513]\n",
            "******* 1633 780 [D loss: 0.027566, acc: 100.00%] [G loss: 4.424378]\n",
            "******* 1634 780 [D loss: 0.074331, acc: 98.44%] [G loss: 4.567232]\n",
            "******* 1635 780 [D loss: 0.087641, acc: 95.31%] [G loss: 4.409770]\n",
            "******* 1636 780 [D loss: 0.050795, acc: 99.22%] [G loss: 4.364997]\n",
            "******* 1637 780 [D loss: 0.191282, acc: 92.97%] [G loss: 4.205890]\n",
            "******* 1638 780 [D loss: 0.068336, acc: 96.88%] [G loss: 4.951430]\n",
            "******* 1639 780 [D loss: 0.034247, acc: 100.00%] [G loss: 5.767572]\n",
            "******* 1640 780 [D loss: 0.059099, acc: 98.44%] [G loss: 5.290051]\n",
            "******* 1641 780 [D loss: 0.194471, acc: 91.41%] [G loss: 4.335767]\n",
            "******* 1642 780 [D loss: 0.133061, acc: 95.31%] [G loss: 4.449562]\n",
            "******* 1643 780 [D loss: 0.088410, acc: 98.44%] [G loss: 4.969342]\n",
            "******* 1644 780 [D loss: 0.111252, acc: 93.75%] [G loss: 5.160913]\n",
            "******* 1645 780 [D loss: 0.070957, acc: 96.88%] [G loss: 4.908155]\n",
            "******* 1646 780 [D loss: 0.172094, acc: 93.75%] [G loss: 4.560602]\n",
            "******* 1647 780 [D loss: 0.071393, acc: 96.88%] [G loss: 4.402712]\n",
            "******* 1648 780 [D loss: 0.069066, acc: 96.88%] [G loss: 5.276548]\n",
            "******* 1649 780 [D loss: 0.104639, acc: 94.53%] [G loss: 4.820859]\n",
            "******* 1650 780 [D loss: 0.084659, acc: 96.88%] [G loss: 4.900642]\n",
            "******* 1651 780 [D loss: 0.108525, acc: 95.31%] [G loss: 5.355898]\n",
            "******* 1652 780 [D loss: 0.070049, acc: 98.44%] [G loss: 4.919503]\n",
            "******* 1653 780 [D loss: 0.045903, acc: 98.44%] [G loss: 5.212256]\n",
            "******* 1654 780 [D loss: 0.233164, acc: 90.62%] [G loss: 4.348270]\n",
            "******* 1655 780 [D loss: 0.098738, acc: 96.88%] [G loss: 5.204620]\n",
            "******* 1656 780 [D loss: 0.060116, acc: 96.88%] [G loss: 6.213059]\n",
            "******* 1657 780 [D loss: 0.075045, acc: 95.31%] [G loss: 6.038501]\n",
            "******* 1658 780 [D loss: 0.167832, acc: 92.19%] [G loss: 4.511707]\n",
            "******* 1659 780 [D loss: 0.140680, acc: 96.09%] [G loss: 3.788853]\n",
            "******* 1660 780 [D loss: 0.155211, acc: 95.31%] [G loss: 4.379198]\n",
            "******* 1661 780 [D loss: 0.074335, acc: 96.88%] [G loss: 4.858598]\n",
            "******* 1662 780 [D loss: 0.096785, acc: 96.09%] [G loss: 4.847578]\n",
            "******* 1663 780 [D loss: 0.190518, acc: 92.19%] [G loss: 4.622849]\n",
            "******* 1664 780 [D loss: 0.101809, acc: 96.09%] [G loss: 4.074438]\n",
            "******* 1665 780 [D loss: 0.220345, acc: 92.97%] [G loss: 4.746717]\n",
            "******* 1666 780 [D loss: 0.133720, acc: 93.75%] [G loss: 4.954586]\n",
            "******* 1667 780 [D loss: 0.318018, acc: 89.06%] [G loss: 4.115037]\n",
            "******* 1668 780 [D loss: 0.060382, acc: 98.44%] [G loss: 3.981643]\n",
            "******* 1669 780 [D loss: 0.240098, acc: 91.41%] [G loss: 3.611350]\n",
            "******* 1670 780 [D loss: 0.289529, acc: 90.62%] [G loss: 4.615100]\n",
            "******* 1671 780 [D loss: 0.041378, acc: 99.22%] [G loss: 6.043325]\n",
            "******* 1672 780 [D loss: 0.170451, acc: 92.97%] [G loss: 5.701881]\n",
            "******* 1673 780 [D loss: 0.316892, acc: 89.84%] [G loss: 3.970814]\n",
            "******* 1674 780 [D loss: 0.189253, acc: 90.62%] [G loss: 2.631376]\n",
            "******* 1675 780 [D loss: 0.160124, acc: 92.19%] [G loss: 3.433103]\n",
            "******* 1676 780 [D loss: 0.053567, acc: 99.22%] [G loss: 5.886098]\n",
            "******* 1677 780 [D loss: 0.124638, acc: 95.31%] [G loss: 7.164152]\n",
            "******* 1678 780 [D loss: 0.046870, acc: 98.44%] [G loss: 7.325070]\n",
            "******* 1679 780 [D loss: 0.275283, acc: 91.41%] [G loss: 5.340359]\n",
            "******* 1680 780 [D loss: 0.076483, acc: 95.31%] [G loss: 4.075398]\n",
            "******* 1681 780 [D loss: 0.257165, acc: 92.19%] [G loss: 5.745990]\n",
            "******* 1682 780 [D loss: 0.043448, acc: 98.44%] [G loss: 7.919683]\n",
            "******* 1683 780 [D loss: 0.160721, acc: 92.97%] [G loss: 8.353682]\n",
            "******* 1684 780 [D loss: 0.317746, acc: 89.84%] [G loss: 7.067350]\n",
            "******* 1685 780 [D loss: 0.222690, acc: 92.97%] [G loss: 7.260744]\n",
            "******* 1686 780 [D loss: 0.040974, acc: 97.66%] [G loss: 7.566416]\n",
            "******* 1687 780 [D loss: 0.104568, acc: 95.31%] [G loss: 6.986921]\n",
            "******* 1688 780 [D loss: 0.072309, acc: 97.66%] [G loss: 5.488728]\n",
            "******* 1689 780 [D loss: 0.050951, acc: 97.66%] [G loss: 5.502979]\n",
            "******* 1690 780 [D loss: 0.113439, acc: 96.09%] [G loss: 7.088990]\n",
            "******* 1691 780 [D loss: 0.001481, acc: 100.00%] [G loss: 8.427595]\n",
            "******* 1692 780 [D loss: 0.043250, acc: 97.66%] [G loss: 10.261293]\n",
            "******* 1693 780 [D loss: 0.160169, acc: 96.88%] [G loss: 9.238513]\n",
            "******* 1694 780 [D loss: 0.161590, acc: 93.75%] [G loss: 6.848893]\n",
            "******* 1695 780 [D loss: 0.111020, acc: 96.09%] [G loss: 6.019463]\n",
            "******* 1696 780 [D loss: 0.314665, acc: 91.41%] [G loss: 5.671530]\n",
            "******* 1697 780 [D loss: 0.067711, acc: 97.66%] [G loss: 8.337395]\n",
            "******* 1698 780 [D loss: 0.254294, acc: 89.84%] [G loss: 7.288594]\n",
            "******* 1699 780 [D loss: 0.290742, acc: 86.72%] [G loss: 3.881607]\n",
            "******* 1700 780 [D loss: 0.476068, acc: 82.81%] [G loss: 4.351894]\n",
            "******* 1701 780 [D loss: 0.078602, acc: 97.66%] [G loss: 7.169570]\n",
            "******* 1702 780 [D loss: 0.394644, acc: 88.28%] [G loss: 6.124075]\n",
            "******* 1703 780 [D loss: 0.220111, acc: 92.97%] [G loss: 3.429124]\n",
            "******* 1704 780 [D loss: 0.448696, acc: 81.25%] [G loss: 3.647932]\n",
            "******* 1705 780 [D loss: 0.119061, acc: 96.09%] [G loss: 5.292216]\n",
            "******* 1706 780 [D loss: 0.190395, acc: 91.41%] [G loss: 6.022171]\n",
            "******* 1707 780 [D loss: 0.164786, acc: 92.97%] [G loss: 4.565193]\n",
            "******* 1708 780 [D loss: 0.113862, acc: 96.88%] [G loss: 2.950041]\n",
            "******* 1709 780 [D loss: 0.126075, acc: 97.66%] [G loss: 3.462366]\n",
            "******* 1710 780 [D loss: 0.051112, acc: 99.22%] [G loss: 4.655165]\n",
            "******* 1711 780 [D loss: 0.073915, acc: 96.88%] [G loss: 5.105278]\n",
            "******* 1712 780 [D loss: 0.037256, acc: 99.22%] [G loss: 5.298316]\n",
            "******* 1713 780 [D loss: 0.036433, acc: 99.22%] [G loss: 5.277673]\n",
            "******* 1714 780 [D loss: 0.078316, acc: 96.09%] [G loss: 4.789577]\n",
            "******* 1715 780 [D loss: 0.066092, acc: 98.44%] [G loss: 4.444942]\n",
            "******* 1716 780 [D loss: 0.061003, acc: 98.44%] [G loss: 4.637618]\n",
            "******* 1717 780 [D loss: 0.053690, acc: 98.44%] [G loss: 4.349661]\n",
            "******* 1718 780 [D loss: 0.037973, acc: 99.22%] [G loss: 4.474679]\n",
            "******* 1719 780 [D loss: 0.053824, acc: 99.22%] [G loss: 4.326832]\n",
            "******* 1720 780 [D loss: 0.052825, acc: 99.22%] [G loss: 4.677979]\n",
            "******* 1721 780 [D loss: 0.145642, acc: 96.09%] [G loss: 4.212667]\n",
            "******* 1722 780 [D loss: 0.094846, acc: 97.66%] [G loss: 4.391120]\n",
            "******* 1723 780 [D loss: 0.056007, acc: 97.66%] [G loss: 4.551929]\n",
            "******* 1724 780 [D loss: 0.049443, acc: 98.44%] [G loss: 4.911583]\n",
            "******* 1725 780 [D loss: 0.183596, acc: 89.06%] [G loss: 4.458436]\n",
            "******* 1726 780 [D loss: 0.073202, acc: 97.66%] [G loss: 4.440684]\n",
            "******* 1727 780 [D loss: 0.054440, acc: 98.44%] [G loss: 5.110206]\n",
            "******* 1728 780 [D loss: 0.035531, acc: 99.22%] [G loss: 5.414964]\n",
            "******* 1729 780 [D loss: 0.048239, acc: 96.88%] [G loss: 5.380502]\n",
            "******* 1730 780 [D loss: 0.053476, acc: 98.44%] [G loss: 5.458734]\n",
            "******* 1731 780 [D loss: 0.039171, acc: 99.22%] [G loss: 4.782804]\n",
            "******* 1732 780 [D loss: 0.060109, acc: 97.66%] [G loss: 4.689212]\n",
            "******* 1733 780 [D loss: 0.108536, acc: 96.09%] [G loss: 5.553487]\n",
            "******* 1734 780 [D loss: 0.037018, acc: 99.22%] [G loss: 6.219541]\n",
            "******* 1735 780 [D loss: 0.183385, acc: 94.53%] [G loss: 5.463836]\n",
            "******* 1736 780 [D loss: 0.227492, acc: 90.62%] [G loss: 3.624114]\n",
            "******* 1737 780 [D loss: 0.211484, acc: 89.06%] [G loss: 4.937756]\n",
            "******* 1738 780 [D loss: 0.178698, acc: 92.97%] [G loss: 5.897965]\n",
            "******* 1739 780 [D loss: 0.095340, acc: 98.44%] [G loss: 5.409078]\n",
            "******* 1740 780 [D loss: 0.182549, acc: 92.97%] [G loss: 4.208048]\n",
            "******* 1741 780 [D loss: 0.122914, acc: 96.09%] [G loss: 4.911127]\n",
            "******* 1742 780 [D loss: 0.129145, acc: 94.53%] [G loss: 5.678185]\n",
            "******* 1743 780 [D loss: 0.114033, acc: 95.31%] [G loss: 5.125073]\n",
            "******* 1744 780 [D loss: 0.096860, acc: 95.31%] [G loss: 5.427738]\n",
            "******* 1745 780 [D loss: 0.182518, acc: 94.53%] [G loss: 3.731318]\n",
            "******* 1746 780 [D loss: 0.179277, acc: 92.19%] [G loss: 4.272935]\n",
            "******* 1747 780 [D loss: 0.077018, acc: 97.66%] [G loss: 5.532603]\n",
            "******* 1748 780 [D loss: 0.098751, acc: 96.88%] [G loss: 5.873234]\n",
            "******* 1749 780 [D loss: 0.095468, acc: 96.88%] [G loss: 5.123919]\n",
            "******* 1750 780 [D loss: 0.077824, acc: 96.88%] [G loss: 4.693087]\n",
            "******* 1751 780 [D loss: 0.061223, acc: 97.66%] [G loss: 5.500623]\n",
            "******* 1752 780 [D loss: 0.039686, acc: 97.66%] [G loss: 5.625408]\n",
            "******* 1753 780 [D loss: 0.071843, acc: 97.66%] [G loss: 5.134166]\n",
            "******* 1754 780 [D loss: 0.067632, acc: 97.66%] [G loss: 5.509774]\n",
            "******* 1755 780 [D loss: 0.102505, acc: 97.66%] [G loss: 5.199978]\n",
            "******* 1756 780 [D loss: 0.068317, acc: 98.44%] [G loss: 6.616100]\n",
            "******* 1757 780 [D loss: 0.137317, acc: 95.31%] [G loss: 7.794235]\n",
            "******* 1758 780 [D loss: 0.029680, acc: 98.44%] [G loss: 6.274818]\n",
            "******* 1759 780 [D loss: 0.036608, acc: 98.44%] [G loss: 7.076460]\n",
            "******* 1760 780 [D loss: 0.120003, acc: 92.19%] [G loss: 6.662331]\n",
            "******* 1761 780 [D loss: 0.073582, acc: 96.88%] [G loss: 6.831139]\n",
            "******* 1762 780 [D loss: 0.098407, acc: 96.88%] [G loss: 7.640156]\n",
            "******* 1763 780 [D loss: 0.283732, acc: 93.75%] [G loss: 9.233048]\n",
            "******* 1764 780 [D loss: 0.164393, acc: 94.53%] [G loss: 8.400590]\n",
            "******* 1765 780 [D loss: 0.101897, acc: 96.09%] [G loss: 6.458264]\n",
            "******* 1766 780 [D loss: 0.191015, acc: 93.75%] [G loss: 5.454631]\n",
            "******* 1767 780 [D loss: 0.188272, acc: 93.75%] [G loss: 5.403709]\n",
            "******* 1768 780 [D loss: 0.070508, acc: 95.31%] [G loss: 5.930925]\n",
            "******* 1769 780 [D loss: 0.173083, acc: 92.97%] [G loss: 5.214482]\n",
            "******* 1770 780 [D loss: 0.176866, acc: 94.53%] [G loss: 5.901730]\n",
            "******* 1771 780 [D loss: 0.173389, acc: 93.75%] [G loss: 5.990999]\n",
            "******* 1772 780 [D loss: 0.116496, acc: 94.53%] [G loss: 6.199781]\n",
            "******* 1773 780 [D loss: 0.077768, acc: 96.09%] [G loss: 4.812031]\n",
            "******* 1774 780 [D loss: 0.247209, acc: 90.62%] [G loss: 3.669639]\n",
            "******* 1775 780 [D loss: 0.231940, acc: 90.62%] [G loss: 4.166555]\n",
            "******* 1776 780 [D loss: 0.160391, acc: 92.97%] [G loss: 5.137242]\n",
            "******* 1777 780 [D loss: 0.282905, acc: 92.19%] [G loss: 5.689713]\n",
            "******* 1778 780 [D loss: 0.187448, acc: 92.97%] [G loss: 4.379305]\n",
            "******* 1779 780 [D loss: 0.344606, acc: 84.38%] [G loss: 3.365700]\n",
            "******* 1780 780 [D loss: 0.107518, acc: 96.88%] [G loss: 4.406684]\n",
            "******* 1781 780 [D loss: 0.082010, acc: 97.66%] [G loss: 4.558896]\n",
            "******* 1782 780 [D loss: 0.185655, acc: 91.41%] [G loss: 4.157527]\n",
            "******* 1783 780 [D loss: 0.289963, acc: 89.84%] [G loss: 3.905258]\n",
            "******* 1784 780 [D loss: 0.146564, acc: 93.75%] [G loss: 3.770522]\n",
            "******* 1785 780 [D loss: 0.226152, acc: 91.41%] [G loss: 4.201984]\n",
            "******* 1786 780 [D loss: 0.189442, acc: 90.62%] [G loss: 3.834687]\n",
            "******* 1787 780 [D loss: 0.064227, acc: 97.66%] [G loss: 4.593870]\n",
            "******* 1788 780 [D loss: 0.093224, acc: 97.66%] [G loss: 4.712445]\n",
            "******* 1789 780 [D loss: 0.095926, acc: 96.88%] [G loss: 4.204020]\n",
            "******* 1790 780 [D loss: 0.088594, acc: 96.88%] [G loss: 4.605648]\n",
            "******* 1791 780 [D loss: 0.114799, acc: 94.53%] [G loss: 4.868692]\n",
            "******* 1792 780 [D loss: 0.063208, acc: 97.66%] [G loss: 5.599430]\n",
            "******* 1793 780 [D loss: 0.119164, acc: 96.09%] [G loss: 5.003139]\n",
            "******* 1794 780 [D loss: 0.077997, acc: 97.66%] [G loss: 4.895494]\n",
            "******* 1795 780 [D loss: 0.165929, acc: 92.97%] [G loss: 4.914347]\n",
            "******* 1796 780 [D loss: 0.085576, acc: 95.31%] [G loss: 4.659940]\n",
            "******* 1797 780 [D loss: 0.067349, acc: 96.88%] [G loss: 5.294603]\n",
            "******* 1798 780 [D loss: 0.169166, acc: 89.84%] [G loss: 4.309934]\n",
            "******* 1799 780 [D loss: 0.136486, acc: 94.53%] [G loss: 4.959435]\n",
            "******* 1800 780 [D loss: 0.121049, acc: 93.75%] [G loss: 4.919196]\n",
            "******* 1801 780 [D loss: 0.186041, acc: 93.75%] [G loss: 4.037641]\n",
            "******* 1802 780 [D loss: 0.147854, acc: 95.31%] [G loss: 4.303250]\n",
            "******* 1803 780 [D loss: 0.322659, acc: 87.50%] [G loss: 4.417074]\n",
            "******* 1804 780 [D loss: 0.173998, acc: 96.09%] [G loss: 4.670387]\n",
            "******* 1805 780 [D loss: 0.328810, acc: 84.38%] [G loss: 4.658741]\n",
            "******* 1806 780 [D loss: 0.214437, acc: 91.41%] [G loss: 4.688351]\n",
            "******* 1807 780 [D loss: 0.253583, acc: 90.62%] [G loss: 3.995925]\n",
            "******* 1808 780 [D loss: 0.176076, acc: 92.19%] [G loss: 5.053004]\n",
            "******* 1809 780 [D loss: 0.129466, acc: 95.31%] [G loss: 4.903897]\n",
            "******* 1810 780 [D loss: 0.110785, acc: 96.88%] [G loss: 4.807423]\n",
            "******* 1811 780 [D loss: 0.212991, acc: 92.19%] [G loss: 5.067447]\n",
            "******* 1812 780 [D loss: 0.143153, acc: 93.75%] [G loss: 4.937778]\n",
            "******* 1813 780 [D loss: 0.079616, acc: 96.88%] [G loss: 5.422310]\n",
            "******* 1814 780 [D loss: 0.104981, acc: 94.53%] [G loss: 5.982471]\n",
            "******* 1815 780 [D loss: 0.183538, acc: 92.97%] [G loss: 5.689981]\n",
            "******* 1816 780 [D loss: 0.100408, acc: 96.09%] [G loss: 5.113458]\n",
            "******* 1817 780 [D loss: 0.207165, acc: 92.97%] [G loss: 6.004093]\n",
            "******* 1818 780 [D loss: 0.120327, acc: 96.88%] [G loss: 5.962774]\n",
            "******* 1819 780 [D loss: 0.128326, acc: 97.66%] [G loss: 6.715981]\n",
            "******* 1820 780 [D loss: 0.263227, acc: 89.84%] [G loss: 5.361115]\n",
            "******* 1821 780 [D loss: 0.218673, acc: 89.84%] [G loss: 5.477864]\n",
            "******* 1822 780 [D loss: 0.191643, acc: 95.31%] [G loss: 7.367545]\n",
            "******* 1823 780 [D loss: 0.226462, acc: 92.97%] [G loss: 5.306976]\n",
            "******* 1824 780 [D loss: 0.172311, acc: 94.53%] [G loss: 4.229881]\n",
            "******* 1825 780 [D loss: 0.116685, acc: 95.31%] [G loss: 4.971742]\n",
            "******* 1826 780 [D loss: 0.096481, acc: 98.44%] [G loss: 4.942614]\n",
            "******* 1827 780 [D loss: 0.075977, acc: 96.88%] [G loss: 4.922700]\n",
            "******* 1828 780 [D loss: 0.112897, acc: 97.66%] [G loss: 5.391607]\n",
            "******* 1829 780 [D loss: 0.129954, acc: 95.31%] [G loss: 3.875541]\n",
            "******* 1830 780 [D loss: 0.098175, acc: 96.88%] [G loss: 3.806271]\n",
            "******* 1831 780 [D loss: 0.199858, acc: 89.06%] [G loss: 3.984594]\n",
            "******* 1832 780 [D loss: 0.055408, acc: 96.88%] [G loss: 4.116550]\n",
            "******* 1833 780 [D loss: 0.107379, acc: 96.09%] [G loss: 3.874638]\n",
            "******* 1834 780 [D loss: 0.173314, acc: 94.53%] [G loss: 3.516335]\n",
            "******* 1835 780 [D loss: 0.113549, acc: 96.88%] [G loss: 4.092532]\n",
            "******* 1836 780 [D loss: 0.155731, acc: 94.53%] [G loss: 4.290549]\n",
            "******* 1837 780 [D loss: 0.124301, acc: 97.66%] [G loss: 4.099522]\n",
            "******* 1838 780 [D loss: 0.112303, acc: 92.97%] [G loss: 4.247023]\n",
            "******* 1839 780 [D loss: 0.143941, acc: 96.88%] [G loss: 3.920708]\n",
            "******* 1840 780 [D loss: 0.127604, acc: 95.31%] [G loss: 3.877403]\n",
            "******* 1841 780 [D loss: 0.144249, acc: 95.31%] [G loss: 3.083516]\n",
            "******* 1842 780 [D loss: 0.155319, acc: 93.75%] [G loss: 3.715107]\n",
            "******* 1843 780 [D loss: 0.072624, acc: 98.44%] [G loss: 4.058821]\n",
            "******* 1844 780 [D loss: 0.167314, acc: 95.31%] [G loss: 4.667518]\n",
            "******* 1845 780 [D loss: 0.095534, acc: 97.66%] [G loss: 4.565876]\n",
            "******* 1846 780 [D loss: 0.165936, acc: 92.97%] [G loss: 3.571787]\n",
            "******* 1847 780 [D loss: 0.072821, acc: 99.22%] [G loss: 3.415133]\n",
            "******* 1848 780 [D loss: 0.131632, acc: 96.88%] [G loss: 3.188171]\n",
            "******* 1849 780 [D loss: 0.163017, acc: 95.31%] [G loss: 3.554507]\n",
            "******* 1850 780 [D loss: 0.258006, acc: 93.75%] [G loss: 3.437173]\n",
            "******* 1851 780 [D loss: 0.149154, acc: 96.88%] [G loss: 3.341557]\n",
            "******* 1852 780 [D loss: 0.069119, acc: 99.22%] [G loss: 3.503896]\n",
            "******* 1853 780 [D loss: 0.263594, acc: 91.41%] [G loss: 3.436887]\n",
            "******* 1854 780 [D loss: 0.140901, acc: 96.09%] [G loss: 2.958905]\n",
            "******* 1855 780 [D loss: 0.137407, acc: 94.53%] [G loss: 4.301864]\n",
            "******* 1856 780 [D loss: 0.147045, acc: 94.53%] [G loss: 4.915936]\n",
            "******* 1857 780 [D loss: 0.226142, acc: 92.97%] [G loss: 4.222916]\n",
            "******* 1858 780 [D loss: 0.115965, acc: 97.66%] [G loss: 3.641317]\n",
            "******* 1859 780 [D loss: 0.196366, acc: 92.97%] [G loss: 3.321789]\n",
            "******* 1860 780 [D loss: 0.107330, acc: 96.88%] [G loss: 3.781022]\n",
            "******* 1861 780 [D loss: 0.111195, acc: 94.53%] [G loss: 4.020344]\n",
            "******* 1862 780 [D loss: 0.067476, acc: 98.44%] [G loss: 4.644556]\n",
            "******* 1863 780 [D loss: 0.104287, acc: 94.53%] [G loss: 4.542370]\n",
            "******* 1864 780 [D loss: 0.063939, acc: 98.44%] [G loss: 4.617365]\n",
            "******* 1865 780 [D loss: 0.144793, acc: 94.53%] [G loss: 3.954852]\n",
            "******* 1866 780 [D loss: 0.082456, acc: 96.88%] [G loss: 4.319558]\n",
            "******* 1867 780 [D loss: 0.086011, acc: 96.88%] [G loss: 4.750716]\n",
            "******* 1868 780 [D loss: 0.085574, acc: 97.66%] [G loss: 4.385143]\n",
            "******* 1869 780 [D loss: 0.108976, acc: 95.31%] [G loss: 4.104457]\n",
            "******* 1870 780 [D loss: 0.068648, acc: 96.88%] [G loss: 4.370310]\n",
            "******* 1871 780 [D loss: 0.097498, acc: 96.88%] [G loss: 5.021561]\n",
            "******* 1872 780 [D loss: 0.180759, acc: 96.09%] [G loss: 5.181845]\n",
            "******* 1873 780 [D loss: 0.215989, acc: 91.41%] [G loss: 4.194860]\n",
            "******* 1874 780 [D loss: 0.156511, acc: 94.53%] [G loss: 5.177189]\n",
            "******* 1875 780 [D loss: 0.160664, acc: 96.09%] [G loss: 6.100507]\n",
            "******* 1876 780 [D loss: 0.191121, acc: 90.62%] [G loss: 6.237821]\n",
            "******* 1877 780 [D loss: 0.250123, acc: 91.41%] [G loss: 4.881356]\n",
            "******* 1878 780 [D loss: 0.168761, acc: 92.19%] [G loss: 5.413428]\n",
            "******* 1879 780 [D loss: 0.082593, acc: 96.09%] [G loss: 6.327671]\n",
            "******* 1880 780 [D loss: 0.073049, acc: 96.09%] [G loss: 7.318756]\n",
            "******* 1881 780 [D loss: 0.058340, acc: 97.66%] [G loss: 6.808220]\n",
            "******* 1882 780 [D loss: 0.125907, acc: 95.31%] [G loss: 5.166897]\n",
            "******* 1883 780 [D loss: 0.064732, acc: 98.44%] [G loss: 5.694256]\n",
            "******* 1884 780 [D loss: 0.026395, acc: 100.00%] [G loss: 6.991639]\n",
            "******* 1885 780 [D loss: 0.019774, acc: 99.22%] [G loss: 7.992120]\n",
            "******* 1886 780 [D loss: 0.041331, acc: 98.44%] [G loss: 8.759993]\n",
            "******* 1887 780 [D loss: 0.115192, acc: 96.09%] [G loss: 6.155270]\n",
            "******* 1888 780 [D loss: 0.090934, acc: 95.31%] [G loss: 5.469110]\n",
            "******* 1889 780 [D loss: 0.056898, acc: 98.44%] [G loss: 5.507077]\n",
            "******* 1890 780 [D loss: 0.093321, acc: 96.88%] [G loss: 6.057246]\n",
            "******* 1891 780 [D loss: 0.040831, acc: 99.22%] [G loss: 6.207026]\n",
            "******* 1892 780 [D loss: 0.170322, acc: 92.97%] [G loss: 5.976547]\n",
            "******* 1893 780 [D loss: 0.211312, acc: 96.09%] [G loss: 5.353359]\n",
            "******* 1894 780 [D loss: 0.077048, acc: 98.44%] [G loss: 6.130639]\n",
            "******* 1895 780 [D loss: 0.207110, acc: 92.97%] [G loss: 4.044617]\n",
            "******* 1896 780 [D loss: 0.531028, acc: 76.56%] [G loss: 6.055694]\n",
            "******* 1897 780 [D loss: 0.112760, acc: 92.97%] [G loss: 7.974927]\n",
            "******* 1898 780 [D loss: 0.421342, acc: 85.94%] [G loss: 5.029678]\n",
            "******* 1899 780 [D loss: 0.076500, acc: 97.66%] [G loss: 2.790305]\n",
            "******* 1900 780 [D loss: 0.145525, acc: 92.97%] [G loss: 3.824798]\n",
            "******* 1901 780 [D loss: 0.027727, acc: 99.22%] [G loss: 6.072733]\n",
            "******* 1902 780 [D loss: 0.066714, acc: 97.66%] [G loss: 7.385135]\n",
            "******* 1903 780 [D loss: 0.025283, acc: 99.22%] [G loss: 7.728127]\n",
            "******* 1904 780 [D loss: 0.045176, acc: 96.88%] [G loss: 6.587308]\n",
            "******* 1905 780 [D loss: 0.040037, acc: 98.44%] [G loss: 5.612225]\n",
            "******* 1906 780 [D loss: 0.060544, acc: 98.44%] [G loss: 4.915870]\n",
            "******* 1907 780 [D loss: 0.014284, acc: 100.00%] [G loss: 5.004709]\n",
            "******* 1908 780 [D loss: 0.036519, acc: 99.22%] [G loss: 5.584446]\n",
            "******* 1909 780 [D loss: 0.037726, acc: 99.22%] [G loss: 5.691532]\n",
            "******* 1910 780 [D loss: 0.235483, acc: 93.75%] [G loss: 4.383910]\n",
            "******* 1911 780 [D loss: 0.054877, acc: 97.66%] [G loss: 4.647727]\n",
            "******* 1912 780 [D loss: 0.034172, acc: 99.22%] [G loss: 5.791262]\n",
            "******* 1913 780 [D loss: 0.013721, acc: 100.00%] [G loss: 6.042212]\n",
            "******* 1914 780 [D loss: 0.009391, acc: 100.00%] [G loss: 6.849689]\n",
            "******* 1915 780 [D loss: 0.171065, acc: 94.53%] [G loss: 5.338988]\n",
            "******* 1916 780 [D loss: 0.101064, acc: 95.31%] [G loss: 5.171430]\n",
            "******* 1917 780 [D loss: 0.067873, acc: 97.66%] [G loss: 5.445379]\n",
            "******* 1918 780 [D loss: 0.072060, acc: 96.88%] [G loss: 6.336423]\n",
            "******* 1919 780 [D loss: 0.169840, acc: 96.09%] [G loss: 6.499487]\n",
            "******* 1920 780 [D loss: 0.139024, acc: 95.31%] [G loss: 6.233892]\n",
            "******* 1921 780 [D loss: 0.203165, acc: 94.53%] [G loss: 4.871374]\n",
            "******* 1922 780 [D loss: 0.224013, acc: 92.97%] [G loss: 6.964246]\n",
            "******* 1923 780 [D loss: 0.231323, acc: 90.62%] [G loss: 8.225504]\n",
            "******* 1924 780 [D loss: 0.397897, acc: 88.28%] [G loss: 7.080833]\n",
            "******* 1925 780 [D loss: 0.380575, acc: 84.38%] [G loss: 6.510818]\n",
            "******* 1926 780 [D loss: 0.504490, acc: 83.59%] [G loss: 8.900447]\n",
            "******* 1927 780 [D loss: 0.263460, acc: 92.19%] [G loss: 10.188240]\n",
            "******* 1928 780 [D loss: 0.670791, acc: 79.69%] [G loss: 5.894660]\n",
            "******* 1929 780 [D loss: 0.818893, acc: 75.78%] [G loss: 4.249277]\n",
            "******* 1930 780 [D loss: 0.282379, acc: 91.41%] [G loss: 5.469453]\n",
            "******* 1931 780 [D loss: 0.170991, acc: 92.97%] [G loss: 6.796891]\n",
            "******* 1932 780 [D loss: 0.331641, acc: 88.28%] [G loss: 6.109460]\n",
            "******* 1933 780 [D loss: 0.253062, acc: 89.06%] [G loss: 4.619041]\n",
            "******* 1934 780 [D loss: 0.196309, acc: 90.62%] [G loss: 4.457687]\n",
            "******* 1935 780 [D loss: 0.146739, acc: 92.97%] [G loss: 5.092356]\n",
            "******* 1936 780 [D loss: 0.057359, acc: 98.44%] [G loss: 4.726810]\n",
            "******* 1937 780 [D loss: 0.051495, acc: 99.22%] [G loss: 5.621696]\n",
            "******* 1938 780 [D loss: 0.044813, acc: 97.66%] [G loss: 5.412932]\n",
            "******* 1939 780 [D loss: 0.066316, acc: 98.44%] [G loss: 5.985747]\n",
            "******* 1940 780 [D loss: 0.051488, acc: 97.66%] [G loss: 5.579744]\n",
            "******* 1941 780 [D loss: 0.048698, acc: 98.44%] [G loss: 5.494050]\n",
            "******* 1942 780 [D loss: 0.033059, acc: 99.22%] [G loss: 4.878386]\n",
            "******* 1943 780 [D loss: 0.054686, acc: 98.44%] [G loss: 4.969672]\n",
            "******* 1944 780 [D loss: 0.044652, acc: 98.44%] [G loss: 5.685059]\n",
            "******* 1945 780 [D loss: 0.089753, acc: 96.88%] [G loss: 5.648422]\n",
            "******* 1946 780 [D loss: 0.084955, acc: 97.66%] [G loss: 5.289942]\n",
            "******* 1947 780 [D loss: 0.054573, acc: 98.44%] [G loss: 5.468628]\n",
            "******* 1948 780 [D loss: 0.069710, acc: 97.66%] [G loss: 4.993352]\n",
            "******* 1949 780 [D loss: 0.047629, acc: 98.44%] [G loss: 4.780264]\n",
            "******* 1950 780 [D loss: 0.044351, acc: 97.66%] [G loss: 5.513264]\n",
            "******* 1951 780 [D loss: 0.093152, acc: 96.09%] [G loss: 5.330820]\n",
            "******* 1952 780 [D loss: 0.055785, acc: 99.22%] [G loss: 4.874390]\n",
            "******* 1953 780 [D loss: 0.138369, acc: 99.22%] [G loss: 5.155490]\n",
            "******* 1954 780 [D loss: 0.055559, acc: 97.66%] [G loss: 5.661749]\n",
            "******* 1955 780 [D loss: 0.040188, acc: 99.22%] [G loss: 4.836810]\n",
            "******* 1956 780 [D loss: 0.065295, acc: 96.88%] [G loss: 5.231124]\n",
            "******* 1957 780 [D loss: 0.097171, acc: 96.09%] [G loss: 4.858388]\n",
            "******* 1958 780 [D loss: 0.053979, acc: 96.88%] [G loss: 4.711581]\n",
            "******* 1959 780 [D loss: 0.066477, acc: 98.44%] [G loss: 5.620202]\n",
            "******* 1960 780 [D loss: 0.041086, acc: 98.44%] [G loss: 6.181125]\n",
            "******* 1961 780 [D loss: 0.028977, acc: 99.22%] [G loss: 6.574018]\n",
            "******* 1962 780 [D loss: 0.025551, acc: 99.22%] [G loss: 6.630033]\n",
            "******* 1963 780 [D loss: 0.079376, acc: 97.66%] [G loss: 5.763031]\n",
            "******* 1964 780 [D loss: 0.018332, acc: 100.00%] [G loss: 5.611367]\n",
            "******* 1965 780 [D loss: 0.107068, acc: 95.31%] [G loss: 4.741623]\n",
            "******* 1966 780 [D loss: 0.085414, acc: 97.66%] [G loss: 4.603736]\n",
            "******* 1967 780 [D loss: 0.030031, acc: 99.22%] [G loss: 6.009168]\n",
            "******* 1968 780 [D loss: 0.019216, acc: 100.00%] [G loss: 6.296051]\n",
            "******* 1969 780 [D loss: 0.055511, acc: 97.66%] [G loss: 5.651059]\n",
            "******* 1970 780 [D loss: 0.076997, acc: 96.09%] [G loss: 4.892234]\n",
            "******* 1971 780 [D loss: 0.106786, acc: 96.09%] [G loss: 5.456529]\n",
            "******* 1972 780 [D loss: 0.097240, acc: 97.66%] [G loss: 5.029462]\n",
            "******* 1973 780 [D loss: 0.139810, acc: 96.88%] [G loss: 4.980268]\n",
            "******* 1974 780 [D loss: 0.056505, acc: 98.44%] [G loss: 4.526459]\n",
            "******* 1975 780 [D loss: 0.150626, acc: 95.31%] [G loss: 3.804353]\n",
            "******* 1976 780 [D loss: 0.032750, acc: 99.22%] [G loss: 4.487096]\n",
            "******* 1977 780 [D loss: 0.119357, acc: 96.09%] [G loss: 3.828334]\n",
            "******* 1978 780 [D loss: 0.084440, acc: 97.66%] [G loss: 4.584264]\n",
            "******* 1979 780 [D loss: 0.033624, acc: 99.22%] [G loss: 5.813047]\n",
            "******* 1980 780 [D loss: 0.086495, acc: 95.31%] [G loss: 4.919306]\n",
            "******* 1981 780 [D loss: 0.071406, acc: 98.44%] [G loss: 4.014243]\n",
            "******* 1982 780 [D loss: 0.087030, acc: 97.66%] [G loss: 4.599278]\n",
            "******* 1983 780 [D loss: 0.056780, acc: 96.88%] [G loss: 5.765988]\n",
            "******* 1984 780 [D loss: 0.134216, acc: 96.09%] [G loss: 6.243701]\n",
            "******* 1985 780 [D loss: 0.075753, acc: 97.66%] [G loss: 5.567068]\n",
            "******* 1986 780 [D loss: 0.114468, acc: 94.53%] [G loss: 5.026040]\n",
            "******* 1987 780 [D loss: 0.140546, acc: 93.75%] [G loss: 6.333663]\n",
            "******* 1988 780 [D loss: 0.307483, acc: 91.41%] [G loss: 7.327895]\n",
            "******* 1989 780 [D loss: 0.155919, acc: 92.97%] [G loss: 6.173920]\n",
            "******* 1990 780 [D loss: 0.475992, acc: 88.28%] [G loss: 5.926959]\n",
            "******* 1991 780 [D loss: 0.130087, acc: 96.09%] [G loss: 6.656331]\n",
            "******* 1992 780 [D loss: 0.424353, acc: 84.38%] [G loss: 5.470230]\n",
            "******* 1993 780 [D loss: 0.173483, acc: 94.53%] [G loss: 5.590389]\n",
            "******* 1994 780 [D loss: 0.058248, acc: 97.66%] [G loss: 5.407879]\n",
            "******* 1995 780 [D loss: 0.077551, acc: 97.66%] [G loss: 6.400499]\n",
            "******* 1996 780 [D loss: 0.225090, acc: 93.75%] [G loss: 6.784827]\n",
            "******* 1997 780 [D loss: 0.123711, acc: 95.31%] [G loss: 6.657458]\n",
            "******* 1998 780 [D loss: 0.168887, acc: 92.97%] [G loss: 7.157624]\n",
            "******* 1999 780 [D loss: 0.057165, acc: 99.22%] [G loss: 6.181509]\n",
            "******* 2000 780 [D loss: 0.173565, acc: 92.97%] [G loss: 5.938796]\n",
            "******* 2001 780 [D loss: 0.093749, acc: 96.88%] [G loss: 5.296427]\n",
            "******* 2002 780 [D loss: 0.124779, acc: 94.53%] [G loss: 5.357307]\n",
            "******* 2003 780 [D loss: 0.035969, acc: 98.44%] [G loss: 6.015958]\n",
            "******* 2004 780 [D loss: 0.040410, acc: 99.22%] [G loss: 6.295373]\n",
            "******* 2005 780 [D loss: 0.076270, acc: 96.88%] [G loss: 6.239281]\n",
            "******* 2006 780 [D loss: 0.058585, acc: 97.66%] [G loss: 5.844604]\n",
            "******* 2007 780 [D loss: 0.121098, acc: 94.53%] [G loss: 4.780454]\n",
            "******* 2008 780 [D loss: 0.088367, acc: 98.44%] [G loss: 4.383095]\n",
            "******* 2009 780 [D loss: 0.110665, acc: 97.66%] [G loss: 4.755488]\n",
            "******* 2010 780 [D loss: 0.098075, acc: 97.66%] [G loss: 5.212967]\n",
            "******* 2011 780 [D loss: 0.071662, acc: 98.44%] [G loss: 6.162629]\n",
            "******* 2012 780 [D loss: 0.113079, acc: 97.66%] [G loss: 6.123032]\n",
            "******* 2013 780 [D loss: 0.071381, acc: 96.88%] [G loss: 6.228870]\n",
            "******* 2014 780 [D loss: 0.121667, acc: 96.09%] [G loss: 6.003898]\n",
            "******* 2015 780 [D loss: 0.127940, acc: 96.88%] [G loss: 5.583703]\n",
            "******* 2016 780 [D loss: 0.131721, acc: 94.53%] [G loss: 6.533072]\n",
            "******* 2017 780 [D loss: 0.120298, acc: 96.88%] [G loss: 5.978794]\n",
            "******* 2018 780 [D loss: 0.157440, acc: 93.75%] [G loss: 4.286981]\n",
            "******* 2019 780 [D loss: 0.201798, acc: 92.19%] [G loss: 3.742291]\n",
            "******* 2020 780 [D loss: 0.152777, acc: 93.75%] [G loss: 5.262495]\n",
            "******* 2021 780 [D loss: 0.209700, acc: 91.41%] [G loss: 4.607608]\n",
            "******* 2022 780 [D loss: 0.192259, acc: 93.75%] [G loss: 3.811147]\n",
            "******* 2023 780 [D loss: 0.323585, acc: 90.62%] [G loss: 3.993974]\n",
            "******* 2024 780 [D loss: 0.143246, acc: 95.31%] [G loss: 4.437647]\n",
            "******* 2025 780 [D loss: 0.141606, acc: 94.53%] [G loss: 4.153382]\n",
            "******* 2026 780 [D loss: 0.183694, acc: 94.53%] [G loss: 3.906606]\n",
            "******* 2027 780 [D loss: 0.403560, acc: 85.94%] [G loss: 4.159937]\n",
            "******* 2028 780 [D loss: 0.141423, acc: 96.09%] [G loss: 5.334169]\n",
            "******* 2029 780 [D loss: 0.123852, acc: 94.53%] [G loss: 4.555261]\n",
            "******* 2030 780 [D loss: 0.359411, acc: 89.06%] [G loss: 3.850013]\n",
            "******* 2031 780 [D loss: 0.575876, acc: 77.34%] [G loss: 3.172536]\n",
            "******* 2032 780 [D loss: 0.253072, acc: 88.28%] [G loss: 3.841038]\n",
            "******* 2033 780 [D loss: 0.221816, acc: 90.62%] [G loss: 3.482158]\n",
            "******* 2034 780 [D loss: 0.302558, acc: 85.94%] [G loss: 3.825672]\n",
            "******* 2035 780 [D loss: 0.117060, acc: 95.31%] [G loss: 4.097018]\n",
            "******* 2036 780 [D loss: 0.303682, acc: 88.28%] [G loss: 3.222095]\n",
            "******* 2037 780 [D loss: 0.368646, acc: 81.25%] [G loss: 2.919620]\n",
            "******* 2038 780 [D loss: 0.172053, acc: 93.75%] [G loss: 3.818254]\n",
            "******* 2039 780 [D loss: 0.106205, acc: 97.66%] [G loss: 4.361385]\n",
            "******* 2040 780 [D loss: 0.165153, acc: 94.53%] [G loss: 4.234387]\n",
            "******* 2041 780 [D loss: 0.249803, acc: 91.41%] [G loss: 3.671407]\n",
            "******* 2042 780 [D loss: 0.250571, acc: 87.50%] [G loss: 3.195344]\n",
            "******* 2043 780 [D loss: 0.185871, acc: 91.41%] [G loss: 3.658396]\n",
            "******* 2044 780 [D loss: 0.211793, acc: 89.84%] [G loss: 3.656421]\n",
            "******* 2045 780 [D loss: 0.103066, acc: 96.88%] [G loss: 4.458262]\n",
            "******* 2046 780 [D loss: 0.060173, acc: 97.66%] [G loss: 4.893972]\n",
            "******* 2047 780 [D loss: 0.144039, acc: 92.19%] [G loss: 4.354025]\n",
            "******* 2048 780 [D loss: 0.165146, acc: 92.19%] [G loss: 4.321455]\n",
            "******* 2049 780 [D loss: 0.113149, acc: 96.09%] [G loss: 4.710562]\n",
            "******* 2050 780 [D loss: 0.068317, acc: 99.22%] [G loss: 5.446740]\n",
            "******* 2051 780 [D loss: 0.117752, acc: 94.53%] [G loss: 5.203027]\n",
            "******* 2052 780 [D loss: 0.138089, acc: 92.97%] [G loss: 4.444853]\n",
            "******* 2053 780 [D loss: 0.131792, acc: 94.53%] [G loss: 4.282331]\n",
            "******* 2054 780 [D loss: 0.182323, acc: 92.19%] [G loss: 3.477887]\n",
            "******* 2055 780 [D loss: 0.229951, acc: 90.62%] [G loss: 3.715342]\n",
            "******* 2056 780 [D loss: 0.153036, acc: 94.53%] [G loss: 4.619781]\n",
            "******* 2057 780 [D loss: 0.164319, acc: 92.97%] [G loss: 4.592607]\n",
            "******* 2058 780 [D loss: 0.134230, acc: 93.75%] [G loss: 3.947505]\n",
            "******* 2059 780 [D loss: 0.148416, acc: 92.19%] [G loss: 3.676230]\n",
            "******* 2060 780 [D loss: 0.108078, acc: 94.53%] [G loss: 4.383633]\n",
            "******* 2061 780 [D loss: 0.193282, acc: 93.75%] [G loss: 4.786868]\n",
            "******* 2062 780 [D loss: 0.124781, acc: 95.31%] [G loss: 5.243433]\n",
            "******* 2063 780 [D loss: 0.157578, acc: 93.75%] [G loss: 4.603640]\n",
            "******* 2064 780 [D loss: 0.108512, acc: 96.09%] [G loss: 3.902290]\n",
            "******* 2065 780 [D loss: 0.135220, acc: 95.31%] [G loss: 3.652363]\n",
            "******* 2066 780 [D loss: 0.239325, acc: 90.62%] [G loss: 4.836289]\n",
            "******* 2067 780 [D loss: 0.120630, acc: 95.31%] [G loss: 4.910775]\n",
            "******* 2068 780 [D loss: 0.128677, acc: 95.31%] [G loss: 5.538084]\n",
            "******* 2069 780 [D loss: 0.127933, acc: 94.53%] [G loss: 4.808346]\n",
            "******* 2070 780 [D loss: 0.109979, acc: 96.09%] [G loss: 3.967856]\n",
            "******* 2071 780 [D loss: 0.150440, acc: 95.31%] [G loss: 3.977781]\n",
            "******* 2072 780 [D loss: 0.097785, acc: 96.09%] [G loss: 4.796674]\n",
            "******* 2073 780 [D loss: 0.094817, acc: 96.88%] [G loss: 6.092696]\n",
            "******* 2074 780 [D loss: 0.062775, acc: 96.88%] [G loss: 5.950537]\n",
            "******* 2075 780 [D loss: 0.109049, acc: 94.53%] [G loss: 5.202435]\n",
            "******* 2076 780 [D loss: 0.066159, acc: 96.88%] [G loss: 4.620306]\n",
            "******* 2077 780 [D loss: 0.150591, acc: 92.97%] [G loss: 4.925673]\n",
            "******* 2078 780 [D loss: 0.094907, acc: 94.53%] [G loss: 5.988382]\n",
            "******* 2079 780 [D loss: 0.061844, acc: 96.88%] [G loss: 6.419265]\n",
            "******* 2080 780 [D loss: 0.041765, acc: 97.66%] [G loss: 5.201052]\n",
            "******* 2081 780 [D loss: 0.092391, acc: 96.09%] [G loss: 5.162725]\n",
            "******* 2082 780 [D loss: 0.026807, acc: 99.22%] [G loss: 5.786404]\n",
            "******* 2083 780 [D loss: 0.116059, acc: 94.53%] [G loss: 4.683002]\n",
            "******* 2084 780 [D loss: 0.068785, acc: 97.66%] [G loss: 4.912798]\n",
            "******* 2085 780 [D loss: 0.057895, acc: 98.44%] [G loss: 4.748741]\n",
            "******* 2086 780 [D loss: 0.127546, acc: 94.53%] [G loss: 5.729025]\n",
            "******* 2087 780 [D loss: 0.030875, acc: 100.00%] [G loss: 6.129868]\n",
            "******* 2088 780 [D loss: 0.097627, acc: 97.66%] [G loss: 5.606774]\n",
            "******* 2089 780 [D loss: 0.126268, acc: 94.53%] [G loss: 3.747234]\n",
            "******* 2090 780 [D loss: 0.175889, acc: 92.19%] [G loss: 3.920729]\n",
            "******* 2091 780 [D loss: 0.065373, acc: 99.22%] [G loss: 5.396840]\n",
            "******* 2092 780 [D loss: 0.174688, acc: 92.97%] [G loss: 4.322895]\n",
            "******* 2093 780 [D loss: 0.124884, acc: 93.75%] [G loss: 5.020526]\n",
            "******* 2094 780 [D loss: 0.089635, acc: 96.88%] [G loss: 5.010715]\n",
            "******* 2095 780 [D loss: 0.172382, acc: 95.31%] [G loss: 4.521808]\n",
            "******* 2096 780 [D loss: 0.114530, acc: 95.31%] [G loss: 3.935643]\n",
            "******* 2097 780 [D loss: 0.108924, acc: 96.09%] [G loss: 4.352230]\n",
            "******* 2098 780 [D loss: 0.095250, acc: 97.66%] [G loss: 4.974190]\n",
            "******* 2099 780 [D loss: 0.252649, acc: 93.75%] [G loss: 3.812279]\n",
            "******* 2100 780 [D loss: 0.219310, acc: 92.97%] [G loss: 4.499653]\n",
            "******* 2101 780 [D loss: 0.063396, acc: 97.66%] [G loss: 5.615706]\n",
            "******* 2102 780 [D loss: 0.182312, acc: 92.97%] [G loss: 4.791154]\n",
            "******* 2103 780 [D loss: 0.184822, acc: 94.53%] [G loss: 3.322198]\n",
            "******* 2104 780 [D loss: 0.115717, acc: 96.88%] [G loss: 3.403697]\n",
            "******* 2105 780 [D loss: 0.114827, acc: 96.09%] [G loss: 4.006736]\n",
            "******* 2106 780 [D loss: 0.088287, acc: 96.88%] [G loss: 4.514279]\n",
            "******* 2107 780 [D loss: 0.075837, acc: 96.88%] [G loss: 4.446681]\n",
            "******* 2108 780 [D loss: 0.079117, acc: 97.66%] [G loss: 4.555288]\n",
            "******* 2109 780 [D loss: 0.076506, acc: 96.09%] [G loss: 4.596906]\n",
            "******* 2110 780 [D loss: 0.113324, acc: 95.31%] [G loss: 4.050615]\n",
            "******* 2111 780 [D loss: 0.137822, acc: 95.31%] [G loss: 4.387699]\n",
            "******* 2112 780 [D loss: 0.092850, acc: 97.66%] [G loss: 4.467928]\n",
            "******* 2113 780 [D loss: 0.078244, acc: 97.66%] [G loss: 4.252387]\n",
            "******* 2114 780 [D loss: 0.182047, acc: 92.97%] [G loss: 4.419581]\n",
            "******* 2115 780 [D loss: 0.199636, acc: 92.97%] [G loss: 4.168819]\n",
            "******* 2116 780 [D loss: 0.174493, acc: 93.75%] [G loss: 4.204762]\n",
            "******* 2117 780 [D loss: 0.095037, acc: 96.09%] [G loss: 4.548232]\n",
            "******* 2118 780 [D loss: 0.186513, acc: 92.97%] [G loss: 3.969587]\n",
            "******* 2119 780 [D loss: 0.169436, acc: 92.97%] [G loss: 3.035483]\n",
            "******* 2120 780 [D loss: 0.232458, acc: 91.41%] [G loss: 3.750822]\n",
            "******* 2121 780 [D loss: 0.195104, acc: 92.97%] [G loss: 4.062403]\n",
            "******* 2122 780 [D loss: 0.086310, acc: 96.09%] [G loss: 3.804010]\n",
            "******* 2123 780 [D loss: 0.165214, acc: 93.75%] [G loss: 3.294271]\n",
            "******* 2124 780 [D loss: 0.229671, acc: 90.62%] [G loss: 3.010630]\n",
            "******* 2125 780 [D loss: 0.095541, acc: 97.66%] [G loss: 3.800444]\n",
            "******* 2126 780 [D loss: 0.218936, acc: 92.97%] [G loss: 4.181396]\n",
            "******* 2127 780 [D loss: 0.205114, acc: 92.97%] [G loss: 3.528336]\n",
            "******* 2128 780 [D loss: 0.176978, acc: 92.19%] [G loss: 3.013897]\n",
            "******* 2129 780 [D loss: 0.148835, acc: 94.53%] [G loss: 2.901252]\n",
            "******* 2130 780 [D loss: 0.151115, acc: 96.09%] [G loss: 3.503819]\n",
            "******* 2131 780 [D loss: 0.114903, acc: 96.09%] [G loss: 4.082816]\n",
            "******* 2132 780 [D loss: 0.187506, acc: 95.31%] [G loss: 4.341721]\n",
            "******* 2133 780 [D loss: 0.220888, acc: 90.62%] [G loss: 3.731052]\n",
            "******* 2134 780 [D loss: 0.105862, acc: 97.66%] [G loss: 3.541846]\n",
            "******* 2135 780 [D loss: 0.136040, acc: 95.31%] [G loss: 3.176171]\n",
            "******* 2136 780 [D loss: 0.166416, acc: 96.09%] [G loss: 3.370419]\n",
            "******* 2137 780 [D loss: 0.184962, acc: 91.41%] [G loss: 3.656231]\n",
            "******* 2138 780 [D loss: 0.069331, acc: 99.22%] [G loss: 4.291828]\n",
            "******* 2139 780 [D loss: 0.071172, acc: 97.66%] [G loss: 4.634293]\n",
            "******* 2140 780 [D loss: 0.124877, acc: 95.31%] [G loss: 4.268694]\n",
            "******* 2141 780 [D loss: 0.091085, acc: 98.44%] [G loss: 4.297363]\n",
            "******* 2142 780 [D loss: 0.069539, acc: 98.44%] [G loss: 4.717432]\n",
            "******* 2143 780 [D loss: 0.097681, acc: 96.09%] [G loss: 5.558013]\n",
            "******* 2144 780 [D loss: 0.060457, acc: 98.44%] [G loss: 5.338705]\n",
            "******* 2145 780 [D loss: 0.128003, acc: 94.53%] [G loss: 5.075793]\n",
            "******* 2146 780 [D loss: 0.063181, acc: 97.66%] [G loss: 5.169480]\n",
            "******* 2147 780 [D loss: 0.080251, acc: 98.44%] [G loss: 4.990454]\n",
            "******* 2148 780 [D loss: 0.046079, acc: 100.00%] [G loss: 5.210198]\n",
            "******* 2149 780 [D loss: 0.147100, acc: 93.75%] [G loss: 4.917315]\n",
            "******* 2150 780 [D loss: 0.089049, acc: 95.31%] [G loss: 6.202785]\n",
            "******* 2151 780 [D loss: 0.280951, acc: 91.41%] [G loss: 4.307261]\n",
            "******* 2152 780 [D loss: 0.270819, acc: 89.84%] [G loss: 5.629200]\n",
            "******* 2153 780 [D loss: 0.056590, acc: 97.66%] [G loss: 6.454056]\n",
            "******* 2154 780 [D loss: 0.307601, acc: 89.06%] [G loss: 4.504787]\n",
            "******* 2155 780 [D loss: 0.220240, acc: 92.19%] [G loss: 4.907267]\n",
            "******* 2156 780 [D loss: 0.112912, acc: 97.66%] [G loss: 6.975041]\n",
            "******* 2157 780 [D loss: 0.330533, acc: 86.72%] [G loss: 4.092770]\n",
            "******* 2158 780 [D loss: 0.219004, acc: 91.41%] [G loss: 3.256215]\n",
            "******* 2159 780 [D loss: 0.193430, acc: 89.84%] [G loss: 5.124307]\n",
            "******* 2160 780 [D loss: 0.119905, acc: 94.53%] [G loss: 6.053879]\n",
            "******* 2161 780 [D loss: 0.240052, acc: 92.19%] [G loss: 3.821839]\n",
            "******* 2162 780 [D loss: 0.242809, acc: 89.84%] [G loss: 3.650954]\n",
            "******* 2163 780 [D loss: 0.105783, acc: 96.09%] [G loss: 4.854692]\n",
            "******* 2164 780 [D loss: 0.147924, acc: 92.19%] [G loss: 5.162928]\n",
            "******* 2165 780 [D loss: 0.192519, acc: 92.97%] [G loss: 4.098148]\n",
            "******* 2166 780 [D loss: 0.082082, acc: 96.88%] [G loss: 4.242963]\n",
            "******* 2167 780 [D loss: 0.159108, acc: 94.53%] [G loss: 4.709768]\n",
            "******* 2168 780 [D loss: 0.041241, acc: 99.22%] [G loss: 5.468546]\n",
            "******* 2169 780 [D loss: 0.035542, acc: 99.22%] [G loss: 6.465468]\n",
            "******* 2170 780 [D loss: 0.095868, acc: 94.53%] [G loss: 6.521973]\n",
            "******* 2171 780 [D loss: 0.079799, acc: 96.88%] [G loss: 5.587712]\n",
            "******* 2172 780 [D loss: 0.173280, acc: 92.19%] [G loss: 4.290385]\n",
            "******* 2173 780 [D loss: 0.032544, acc: 100.00%] [G loss: 4.755740]\n",
            "******* 2174 780 [D loss: 0.074561, acc: 96.88%] [G loss: 4.718725]\n",
            "******* 2175 780 [D loss: 0.098792, acc: 96.88%] [G loss: 5.781032]\n",
            "******* 2176 780 [D loss: 0.084826, acc: 96.88%] [G loss: 5.443164]\n",
            "******* 2177 780 [D loss: 0.163389, acc: 94.53%] [G loss: 5.427460]\n",
            "******* 2178 780 [D loss: 0.052613, acc: 97.66%] [G loss: 5.326830]\n",
            "******* 2179 780 [D loss: 0.044729, acc: 98.44%] [G loss: 5.529305]\n",
            "******* 2180 780 [D loss: 0.128712, acc: 93.75%] [G loss: 4.239257]\n",
            "******* 2181 780 [D loss: 0.096832, acc: 94.53%] [G loss: 4.459750]\n",
            "******* 2182 780 [D loss: 0.073235, acc: 96.88%] [G loss: 5.451203]\n",
            "******* 2183 780 [D loss: 0.119902, acc: 96.88%] [G loss: 5.044640]\n",
            "******* 2184 780 [D loss: 0.194932, acc: 90.62%] [G loss: 4.991129]\n",
            "******* 2185 780 [D loss: 0.258869, acc: 89.06%] [G loss: 3.593394]\n",
            "******* 2186 780 [D loss: 0.213370, acc: 91.41%] [G loss: 5.276980]\n",
            "******* 2187 780 [D loss: 0.102435, acc: 94.53%] [G loss: 6.013443]\n",
            "******* 2188 780 [D loss: 0.166449, acc: 92.19%] [G loss: 5.739153]\n",
            "******* 2189 780 [D loss: 0.073021, acc: 96.88%] [G loss: 4.789579]\n",
            "******* 2190 780 [D loss: 0.241703, acc: 91.41%] [G loss: 3.813096]\n",
            "******* 2191 780 [D loss: 0.145944, acc: 94.53%] [G loss: 4.385404]\n",
            "******* 2192 780 [D loss: 0.135101, acc: 95.31%] [G loss: 5.285541]\n",
            "******* 2193 780 [D loss: 0.043960, acc: 97.66%] [G loss: 6.214610]\n",
            "******* 2194 780 [D loss: 0.131434, acc: 95.31%] [G loss: 4.179239]\n",
            "******* 2195 780 [D loss: 0.145571, acc: 93.75%] [G loss: 3.873580]\n",
            "******* 2196 780 [D loss: 0.108586, acc: 96.09%] [G loss: 5.195430]\n",
            "******* 2197 780 [D loss: 0.133690, acc: 96.88%] [G loss: 5.753196]\n",
            "******* 2198 780 [D loss: 0.075660, acc: 98.44%] [G loss: 5.225628]\n",
            "******* 2199 780 [D loss: 0.113095, acc: 95.31%] [G loss: 3.831604]\n",
            "******* 2200 780 [D loss: 0.063929, acc: 97.66%] [G loss: 4.456469]\n",
            "******* 2201 780 [D loss: 0.047426, acc: 98.44%] [G loss: 5.400559]\n",
            "******* 2202 780 [D loss: 0.127165, acc: 96.09%] [G loss: 4.915624]\n",
            "******* 2203 780 [D loss: 0.056188, acc: 98.44%] [G loss: 4.843094]\n",
            "******* 2204 780 [D loss: 0.057802, acc: 98.44%] [G loss: 5.814183]\n",
            "******* 2205 780 [D loss: 0.197818, acc: 92.97%] [G loss: 5.440411]\n",
            "******* 2206 780 [D loss: 0.068989, acc: 99.22%] [G loss: 5.571836]\n",
            "******* 2207 780 [D loss: 0.088829, acc: 96.88%] [G loss: 4.768010]\n",
            "******* 2208 780 [D loss: 0.055225, acc: 98.44%] [G loss: 5.405912]\n",
            "******* 2209 780 [D loss: 0.061358, acc: 98.44%] [G loss: 5.613054]\n",
            "******* 2210 780 [D loss: 0.049937, acc: 98.44%] [G loss: 5.273483]\n",
            "******* 2211 780 [D loss: 0.032503, acc: 98.44%] [G loss: 6.917466]\n",
            "******* 2212 780 [D loss: 0.173634, acc: 93.75%] [G loss: 5.192159]\n",
            "******* 2213 780 [D loss: 0.193568, acc: 92.97%] [G loss: 7.549323]\n",
            "******* 2214 780 [D loss: 0.227105, acc: 92.19%] [G loss: 6.767191]\n",
            "******* 2215 780 [D loss: 0.392078, acc: 90.62%] [G loss: 5.471375]\n",
            "******* 2216 780 [D loss: 0.212999, acc: 92.19%] [G loss: 5.057467]\n",
            "******* 2217 780 [D loss: 0.189253, acc: 94.53%] [G loss: 6.118790]\n",
            "******* 2218 780 [D loss: 0.200411, acc: 93.75%] [G loss: 6.545232]\n",
            "******* 2219 780 [D loss: 0.168939, acc: 95.31%] [G loss: 5.074240]\n",
            "******* 2220 780 [D loss: 0.253150, acc: 88.28%] [G loss: 4.253284]\n",
            "******* 2221 780 [D loss: 0.223403, acc: 92.19%] [G loss: 4.865970]\n",
            "******* 2222 780 [D loss: 0.147697, acc: 95.31%] [G loss: 6.012420]\n",
            "******* 2223 780 [D loss: 0.158539, acc: 93.75%] [G loss: 4.576605]\n",
            "******* 2224 780 [D loss: 0.172427, acc: 96.09%] [G loss: 3.461680]\n",
            "******* 2225 780 [D loss: 0.120091, acc: 95.31%] [G loss: 3.619145]\n",
            "******* 2226 780 [D loss: 0.163468, acc: 94.53%] [G loss: 4.379982]\n",
            "******* 2227 780 [D loss: 0.068138, acc: 97.66%] [G loss: 5.272815]\n",
            "******* 2228 780 [D loss: 0.137561, acc: 95.31%] [G loss: 4.567421]\n",
            "******* 2229 780 [D loss: 0.109859, acc: 95.31%] [G loss: 4.135964]\n",
            "******* 2230 780 [D loss: 0.140753, acc: 96.09%] [G loss: 3.346947]\n",
            "******* 2231 780 [D loss: 0.174222, acc: 94.53%] [G loss: 3.669182]\n",
            "******* 2232 780 [D loss: 0.122531, acc: 94.53%] [G loss: 5.444079]\n",
            "******* 2233 780 [D loss: 0.060448, acc: 97.66%] [G loss: 5.937528]\n",
            "******* 2234 780 [D loss: 0.198613, acc: 92.97%] [G loss: 5.733274]\n",
            "******* 2235 780 [D loss: 0.098898, acc: 96.09%] [G loss: 5.178066]\n",
            "******* 2236 780 [D loss: 0.080844, acc: 97.66%] [G loss: 3.554041]\n",
            "******* 2237 780 [D loss: 0.084751, acc: 96.88%] [G loss: 3.437188]\n",
            "******* 2238 780 [D loss: 0.150261, acc: 94.53%] [G loss: 4.569783]\n",
            "******* 2239 780 [D loss: 0.059505, acc: 97.66%] [G loss: 5.160285]\n",
            "******* 2240 780 [D loss: 0.071316, acc: 97.66%] [G loss: 6.004376]\n",
            "******* 2241 780 [D loss: 0.148505, acc: 93.75%] [G loss: 5.094352]\n",
            "******* 2242 780 [D loss: 0.197539, acc: 92.97%] [G loss: 3.247378]\n",
            "******* 2243 780 [D loss: 0.226457, acc: 88.28%] [G loss: 3.431279]\n",
            "******* 2244 780 [D loss: 0.093185, acc: 96.09%] [G loss: 4.538361]\n",
            "******* 2245 780 [D loss: 0.102447, acc: 96.09%] [G loss: 5.675309]\n",
            "******* 2246 780 [D loss: 0.160271, acc: 94.53%] [G loss: 5.160110]\n",
            "******* 2247 780 [D loss: 0.173985, acc: 94.53%] [G loss: 3.832404]\n",
            "******* 2248 780 [D loss: 0.146302, acc: 95.31%] [G loss: 3.510847]\n",
            "******* 2249 780 [D loss: 0.153468, acc: 94.53%] [G loss: 4.016352]\n",
            "******* 2250 780 [D loss: 0.072924, acc: 99.22%] [G loss: 4.768163]\n",
            "******* 2251 780 [D loss: 0.067049, acc: 97.66%] [G loss: 4.460278]\n",
            "******* 2252 780 [D loss: 0.152758, acc: 92.97%] [G loss: 3.788872]\n",
            "******* 2253 780 [D loss: 0.221030, acc: 88.28%] [G loss: 3.331615]\n",
            "******* 2254 780 [D loss: 0.147120, acc: 94.53%] [G loss: 3.097035]\n",
            "******* 2255 780 [D loss: 0.137821, acc: 96.09%] [G loss: 3.684215]\n",
            "******* 2256 780 [D loss: 0.088098, acc: 98.44%] [G loss: 4.461021]\n",
            "******* 2257 780 [D loss: 0.145088, acc: 96.09%] [G loss: 4.064119]\n",
            "******* 2258 780 [D loss: 0.146525, acc: 94.53%] [G loss: 3.802411]\n",
            "******* 2259 780 [D loss: 0.137540, acc: 95.31%] [G loss: 4.107384]\n",
            "******* 2260 780 [D loss: 0.138344, acc: 94.53%] [G loss: 4.141346]\n",
            "******* 2261 780 [D loss: 0.096244, acc: 96.88%] [G loss: 4.191242]\n",
            "******* 2262 780 [D loss: 0.081358, acc: 97.66%] [G loss: 4.287650]\n",
            "******* 2263 780 [D loss: 0.067365, acc: 98.44%] [G loss: 4.800140]\n",
            "******* 2264 780 [D loss: 0.104200, acc: 95.31%] [G loss: 4.414328]\n",
            "******* 2265 780 [D loss: 0.120398, acc: 94.53%] [G loss: 4.232959]\n",
            "******* 2266 780 [D loss: 0.127665, acc: 94.53%] [G loss: 4.229459]\n",
            "******* 2267 780 [D loss: 0.117489, acc: 96.09%] [G loss: 4.936355]\n",
            "******* 2268 780 [D loss: 0.234271, acc: 90.62%] [G loss: 4.132319]\n",
            "******* 2269 780 [D loss: 0.081491, acc: 98.44%] [G loss: 3.876377]\n",
            "******* 2270 780 [D loss: 0.200974, acc: 92.19%] [G loss: 4.156857]\n",
            "******* 2271 780 [D loss: 0.238289, acc: 89.06%] [G loss: 4.341298]\n",
            "******* 2272 780 [D loss: 0.143135, acc: 96.09%] [G loss: 4.769559]\n",
            "******* 2273 780 [D loss: 0.153691, acc: 94.53%] [G loss: 4.164316]\n",
            "******* 2274 780 [D loss: 0.152665, acc: 93.75%] [G loss: 4.599926]\n",
            "******* 2275 780 [D loss: 0.104729, acc: 96.09%] [G loss: 4.442724]\n",
            "******* 2276 780 [D loss: 0.056855, acc: 98.44%] [G loss: 5.022532]\n",
            "******* 2277 780 [D loss: 0.057432, acc: 98.44%] [G loss: 5.106686]\n",
            "******* 2278 780 [D loss: 0.154425, acc: 92.97%] [G loss: 4.222830]\n",
            "******* 2279 780 [D loss: 0.083446, acc: 97.66%] [G loss: 3.408170]\n",
            "******* 2280 780 [D loss: 0.115304, acc: 96.09%] [G loss: 3.458738]\n",
            "******* 2281 780 [D loss: 0.038850, acc: 100.00%] [G loss: 4.488094]\n",
            "******* 2282 780 [D loss: 0.051770, acc: 98.44%] [G loss: 5.560052]\n",
            "******* 2283 780 [D loss: 0.202332, acc: 89.84%] [G loss: 4.082772]\n",
            "******* 2284 780 [D loss: 0.183068, acc: 89.84%] [G loss: 4.313663]\n",
            "******* 2285 780 [D loss: 0.056454, acc: 97.66%] [G loss: 4.741730]\n",
            "******* 2286 780 [D loss: 0.085485, acc: 96.88%] [G loss: 5.043601]\n",
            "******* 2287 780 [D loss: 0.057611, acc: 96.88%] [G loss: 4.842097]\n",
            "******* 2288 780 [D loss: 0.126657, acc: 95.31%] [G loss: 4.240981]\n",
            "******* 2289 780 [D loss: 0.114558, acc: 95.31%] [G loss: 4.520554]\n",
            "******* 2290 780 [D loss: 0.126786, acc: 94.53%] [G loss: 5.602576]\n",
            "******* 2291 780 [D loss: 0.139689, acc: 95.31%] [G loss: 5.162407]\n",
            "******* 2292 780 [D loss: 0.136235, acc: 96.09%] [G loss: 4.356672]\n",
            "******* 2293 780 [D loss: 0.214284, acc: 92.19%] [G loss: 4.094021]\n",
            "******* 2294 780 [D loss: 0.091529, acc: 96.09%] [G loss: 4.386062]\n",
            "******* 2295 780 [D loss: 0.183828, acc: 92.97%] [G loss: 4.673893]\n",
            "******* 2296 780 [D loss: 0.078688, acc: 98.44%] [G loss: 4.255463]\n",
            "******* 2297 780 [D loss: 0.119953, acc: 95.31%] [G loss: 3.867711]\n",
            "******* 2298 780 [D loss: 0.136740, acc: 94.53%] [G loss: 3.421974]\n",
            "******* 2299 780 [D loss: 0.116012, acc: 96.09%] [G loss: 3.929231]\n",
            "******* 2300 780 [D loss: 0.037435, acc: 99.22%] [G loss: 5.169546]\n",
            "******* 2301 780 [D loss: 0.137462, acc: 94.53%] [G loss: 4.111922]\n",
            "******* 2302 780 [D loss: 0.075817, acc: 96.09%] [G loss: 4.263651]\n",
            "******* 2303 780 [D loss: 0.020448, acc: 100.00%] [G loss: 5.803802]\n",
            "******* 2304 780 [D loss: 0.032686, acc: 98.44%] [G loss: 6.875349]\n",
            "******* 2305 780 [D loss: 0.058127, acc: 97.66%] [G loss: 5.753807]\n",
            "******* 2306 780 [D loss: 0.070832, acc: 96.88%] [G loss: 5.175960]\n",
            "******* 2307 780 [D loss: 0.101137, acc: 96.09%] [G loss: 4.532583]\n",
            "******* 2308 780 [D loss: 0.037520, acc: 98.44%] [G loss: 6.000898]\n",
            "******* 2309 780 [D loss: 0.050069, acc: 97.66%] [G loss: 6.737868]\n",
            "******* 2310 780 [D loss: 0.057348, acc: 97.66%] [G loss: 5.901070]\n",
            "******* 2311 780 [D loss: 0.097850, acc: 96.88%] [G loss: 5.538982]\n",
            "******* 2312 780 [D loss: 0.081517, acc: 96.88%] [G loss: 5.101712]\n",
            "******* 2313 780 [D loss: 0.154500, acc: 95.31%] [G loss: 6.402753]\n",
            "******* 2314 780 [D loss: 0.087681, acc: 96.09%] [G loss: 6.332617]\n",
            "******* 2315 780 [D loss: 0.102493, acc: 96.09%] [G loss: 5.773379]\n",
            "******* 2316 780 [D loss: 0.603480, acc: 81.25%] [G loss: 7.002612]\n",
            "******* 2317 780 [D loss: 0.239205, acc: 89.84%] [G loss: 6.285814]\n",
            "******* 2318 780 [D loss: 0.680907, acc: 75.78%] [G loss: 4.642608]\n",
            "******* 2319 780 [D loss: 0.315978, acc: 89.84%] [G loss: 4.254146]\n",
            "******* 2320 780 [D loss: 0.393370, acc: 81.25%] [G loss: 3.061681]\n",
            "******* 2321 780 [D loss: 0.202314, acc: 93.75%] [G loss: 3.833699]\n",
            "******* 2322 780 [D loss: 0.241247, acc: 90.62%] [G loss: 3.978679]\n",
            "******* 2323 780 [D loss: 0.344156, acc: 85.94%] [G loss: 3.721354]\n",
            "******* 2324 780 [D loss: 0.156355, acc: 93.75%] [G loss: 3.386955]\n",
            "******* 2325 780 [D loss: 0.198194, acc: 90.62%] [G loss: 3.781921]\n",
            "******* 2326 780 [D loss: 0.099231, acc: 96.09%] [G loss: 4.272041]\n",
            "******* 2327 780 [D loss: 0.076123, acc: 97.66%] [G loss: 4.778358]\n",
            "******* 2328 780 [D loss: 0.054946, acc: 98.44%] [G loss: 5.070741]\n",
            "******* 2329 780 [D loss: 0.160563, acc: 93.75%] [G loss: 4.772909]\n",
            "******* 2330 780 [D loss: 0.183606, acc: 93.75%] [G loss: 4.470577]\n",
            "******* 2331 780 [D loss: 0.079434, acc: 97.66%] [G loss: 5.574142]\n",
            "******* 2332 780 [D loss: 0.071507, acc: 96.88%] [G loss: 5.766726]\n",
            "******* 2333 780 [D loss: 0.068926, acc: 97.66%] [G loss: 5.563628]\n",
            "******* 2334 780 [D loss: 0.103626, acc: 93.75%] [G loss: 4.504165]\n",
            "******* 2335 780 [D loss: 0.106354, acc: 96.09%] [G loss: 4.250385]\n",
            "******* 2336 780 [D loss: 0.122084, acc: 93.75%] [G loss: 4.569701]\n",
            "******* 2337 780 [D loss: 0.155911, acc: 93.75%] [G loss: 4.608273]\n",
            "******* 2338 780 [D loss: 0.093694, acc: 96.88%] [G loss: 4.420509]\n",
            "******* 2339 780 [D loss: 0.074251, acc: 97.66%] [G loss: 3.657333]\n",
            "******* 2340 780 [D loss: 0.084882, acc: 96.88%] [G loss: 4.317931]\n",
            "******* 2341 780 [D loss: 0.058393, acc: 99.22%] [G loss: 5.093532]\n",
            "******* 2342 780 [D loss: 0.093721, acc: 96.09%] [G loss: 5.243917]\n",
            "******* 2343 780 [D loss: 0.062841, acc: 97.66%] [G loss: 5.265235]\n",
            "******* 2344 780 [D loss: 0.117810, acc: 96.88%] [G loss: 4.665182]\n",
            "******* 2345 780 [D loss: 0.093359, acc: 95.31%] [G loss: 4.369478]\n",
            "******* 2346 780 [D loss: 0.081808, acc: 97.66%] [G loss: 4.453506]\n",
            "******* 2347 780 [D loss: 0.159055, acc: 92.97%] [G loss: 5.407851]\n",
            "******* 2348 780 [D loss: 0.192768, acc: 94.53%] [G loss: 4.623016]\n",
            "******* 2349 780 [D loss: 0.101799, acc: 94.53%] [G loss: 4.365462]\n",
            "******* 2350 780 [D loss: 0.092631, acc: 96.09%] [G loss: 4.452549]\n",
            "******* 2351 780 [D loss: 0.102461, acc: 96.88%] [G loss: 4.736576]\n",
            "******* 2352 780 [D loss: 0.049201, acc: 99.22%] [G loss: 5.048443]\n",
            "******* 2353 780 [D loss: 0.143625, acc: 94.53%] [G loss: 4.532456]\n",
            "******* 2354 780 [D loss: 0.110749, acc: 96.88%] [G loss: 4.205733]\n",
            "******* 2355 780 [D loss: 0.103896, acc: 95.31%] [G loss: 4.851161]\n",
            "******* 2356 780 [D loss: 0.168012, acc: 93.75%] [G loss: 4.768446]\n",
            "******* 2357 780 [D loss: 0.182924, acc: 91.41%] [G loss: 5.029287]\n",
            "******* 2358 780 [D loss: 0.230258, acc: 93.75%] [G loss: 5.480455]\n",
            "******* 2359 780 [D loss: 0.188138, acc: 93.75%] [G loss: 5.728953]\n",
            "******* 2360 780 [D loss: 0.147543, acc: 95.31%] [G loss: 5.074510]\n",
            "******* 2361 780 [D loss: 0.089157, acc: 96.09%] [G loss: 4.781471]\n",
            "******* 2362 780 [D loss: 0.134333, acc: 94.53%] [G loss: 5.067222]\n",
            "******* 2363 780 [D loss: 0.039197, acc: 98.44%] [G loss: 5.815749]\n",
            "******* 2364 780 [D loss: 0.178042, acc: 94.53%] [G loss: 6.076444]\n",
            "******* 2365 780 [D loss: 0.085180, acc: 97.66%] [G loss: 6.100200]\n",
            "******* 2366 780 [D loss: 0.127662, acc: 93.75%] [G loss: 5.338495]\n",
            "******* 2367 780 [D loss: 0.158018, acc: 90.62%] [G loss: 4.253538]\n",
            "******* 2368 780 [D loss: 0.133395, acc: 92.97%] [G loss: 5.947361]\n",
            "******* 2369 780 [D loss: 0.115469, acc: 95.31%] [G loss: 7.065568]\n",
            "******* 2370 780 [D loss: 0.343905, acc: 87.50%] [G loss: 5.014219]\n",
            "******* 2371 780 [D loss: 0.148345, acc: 94.53%] [G loss: 3.635464]\n",
            "******* 2372 780 [D loss: 0.097318, acc: 95.31%] [G loss: 4.141422]\n",
            "******* 2373 780 [D loss: 0.099975, acc: 95.31%] [G loss: 4.632714]\n",
            "******* 2374 780 [D loss: 0.103674, acc: 97.66%] [G loss: 4.633246]\n",
            "******* 2375 780 [D loss: 0.114226, acc: 95.31%] [G loss: 3.953202]\n",
            "******* 2376 780 [D loss: 0.208545, acc: 95.31%] [G loss: 3.895976]\n",
            "******* 2377 780 [D loss: 0.101399, acc: 97.66%] [G loss: 3.531535]\n",
            "******* 2378 780 [D loss: 0.098654, acc: 96.88%] [G loss: 4.121037]\n",
            "******* 2379 780 [D loss: 0.166710, acc: 92.97%] [G loss: 3.916182]\n",
            "******* 2380 780 [D loss: 0.115037, acc: 97.66%] [G loss: 4.593872]\n",
            "******* 2381 780 [D loss: 0.167866, acc: 92.97%] [G loss: 3.922713]\n",
            "******* 2382 780 [D loss: 0.157388, acc: 94.53%] [G loss: 3.240695]\n",
            "******* 2383 780 [D loss: 0.242498, acc: 85.94%] [G loss: 3.705435]\n",
            "******* 2384 780 [D loss: 0.129804, acc: 93.75%] [G loss: 5.171526]\n",
            "******* 2385 780 [D loss: 0.178204, acc: 91.41%] [G loss: 5.081973]\n",
            "******* 2386 780 [D loss: 0.109540, acc: 94.53%] [G loss: 4.060016]\n",
            "******* 2387 780 [D loss: 0.204313, acc: 92.19%] [G loss: 3.322879]\n",
            "******* 2388 780 [D loss: 0.095193, acc: 96.09%] [G loss: 4.065131]\n",
            "******* 2389 780 [D loss: 0.203272, acc: 92.97%] [G loss: 4.285999]\n",
            "******* 2390 780 [D loss: 0.124389, acc: 95.31%] [G loss: 4.781627]\n",
            "******* 2391 780 [D loss: 0.032911, acc: 99.22%] [G loss: 5.176486]\n",
            "******* 2392 780 [D loss: 0.123331, acc: 92.19%] [G loss: 4.612419]\n",
            "******* 2393 780 [D loss: 0.188554, acc: 95.31%] [G loss: 3.494186]\n",
            "******* 2394 780 [D loss: 0.117590, acc: 94.53%] [G loss: 4.221982]\n",
            "******* 2395 780 [D loss: 0.097248, acc: 96.88%] [G loss: 5.229715]\n",
            "******* 2396 780 [D loss: 0.129577, acc: 94.53%] [G loss: 5.039813]\n",
            "******* 2397 780 [D loss: 0.112483, acc: 96.09%] [G loss: 4.918840]\n",
            "******* 2398 780 [D loss: 0.091053, acc: 92.97%] [G loss: 5.102920]\n",
            "******* 2399 780 [D loss: 0.118327, acc: 93.75%] [G loss: 6.204678]\n",
            "******* 2400 780 [D loss: 0.069765, acc: 98.44%] [G loss: 6.132644]\n",
            "******* 2401 780 [D loss: 0.109292, acc: 96.09%] [G loss: 6.147952]\n",
            "******* 2402 780 [D loss: 0.185530, acc: 95.31%] [G loss: 5.946434]\n",
            "******* 2403 780 [D loss: 0.265060, acc: 89.06%] [G loss: 5.077703]\n",
            "******* 2404 780 [D loss: 0.149674, acc: 93.75%] [G loss: 5.132022]\n",
            "******* 2405 780 [D loss: 0.202856, acc: 92.19%] [G loss: 4.072505]\n",
            "******* 2406 780 [D loss: 0.122662, acc: 96.88%] [G loss: 3.795698]\n",
            "******* 2407 780 [D loss: 0.152711, acc: 94.53%] [G loss: 4.432031]\n",
            "******* 2408 780 [D loss: 0.168417, acc: 94.53%] [G loss: 4.515443]\n",
            "******* 2409 780 [D loss: 0.155433, acc: 94.53%] [G loss: 4.375784]\n",
            "******* 2410 780 [D loss: 0.099582, acc: 96.09%] [G loss: 4.606439]\n",
            "******* 2411 780 [D loss: 0.197466, acc: 92.19%] [G loss: 4.031909]\n",
            "******* 2412 780 [D loss: 0.202846, acc: 92.19%] [G loss: 4.665513]\n",
            "******* 2413 780 [D loss: 0.081483, acc: 96.88%] [G loss: 5.682183]\n",
            "******* 2414 780 [D loss: 0.279594, acc: 89.06%] [G loss: 4.622064]\n",
            "******* 2415 780 [D loss: 0.081968, acc: 96.88%] [G loss: 3.967355]\n",
            "******* 2416 780 [D loss: 0.175716, acc: 92.97%] [G loss: 4.152036]\n",
            "******* 2417 780 [D loss: 0.094123, acc: 96.88%] [G loss: 5.006526]\n",
            "******* 2418 780 [D loss: 0.095283, acc: 97.66%] [G loss: 4.867949]\n",
            "******* 2419 780 [D loss: 0.083617, acc: 96.09%] [G loss: 4.768731]\n",
            "******* 2420 780 [D loss: 0.160707, acc: 93.75%] [G loss: 4.400179]\n",
            "******* 2421 780 [D loss: 0.071233, acc: 97.66%] [G loss: 4.727521]\n",
            "******* 2422 780 [D loss: 0.100677, acc: 96.09%] [G loss: 4.882219]\n",
            "******* 2423 780 [D loss: 0.096003, acc: 96.88%] [G loss: 4.378640]\n",
            "******* 2424 780 [D loss: 0.099313, acc: 96.09%] [G loss: 4.280949]\n",
            "******* 2425 780 [D loss: 0.196075, acc: 91.41%] [G loss: 3.654195]\n",
            "******* 2426 780 [D loss: 0.125111, acc: 94.53%] [G loss: 4.202136]\n",
            "******* 2427 780 [D loss: 0.037263, acc: 100.00%] [G loss: 4.538213]\n",
            "******* 2428 780 [D loss: 0.062394, acc: 97.66%] [G loss: 4.248129]\n",
            "******* 2429 780 [D loss: 0.136486, acc: 94.53%] [G loss: 4.834294]\n",
            "******* 2430 780 [D loss: 0.108582, acc: 96.09%] [G loss: 4.306471]\n",
            "******* 2431 780 [D loss: 0.106364, acc: 95.31%] [G loss: 3.777382]\n",
            "******* 2432 780 [D loss: 0.071086, acc: 98.44%] [G loss: 3.508094]\n",
            "******* 2433 780 [D loss: 0.175046, acc: 92.97%] [G loss: 3.539135]\n",
            "******* 2434 780 [D loss: 0.052785, acc: 99.22%] [G loss: 4.031537]\n",
            "******* 2435 780 [D loss: 0.058462, acc: 98.44%] [G loss: 4.870256]\n",
            "******* 2436 780 [D loss: 0.080542, acc: 97.66%] [G loss: 4.958990]\n",
            "******* 2437 780 [D loss: 0.146452, acc: 93.75%] [G loss: 4.696441]\n",
            "******* 2438 780 [D loss: 0.082797, acc: 96.09%] [G loss: 3.860912]\n",
            "******* 2439 780 [D loss: 0.085489, acc: 99.22%] [G loss: 4.545558]\n",
            "******* 2440 780 [D loss: 0.092304, acc: 94.53%] [G loss: 4.765631]\n",
            "******* 2441 780 [D loss: 0.126481, acc: 96.09%] [G loss: 4.963938]\n",
            "******* 2442 780 [D loss: 0.056610, acc: 99.22%] [G loss: 5.444677]\n",
            "******* 2443 780 [D loss: 0.068194, acc: 97.66%] [G loss: 5.081400]\n",
            "******* 2444 780 [D loss: 0.109020, acc: 96.09%] [G loss: 4.237983]\n",
            "******* 2445 780 [D loss: 0.041486, acc: 100.00%] [G loss: 4.128912]\n",
            "******* 2446 780 [D loss: 0.155149, acc: 95.31%] [G loss: 4.409812]\n",
            "******* 2447 780 [D loss: 0.065663, acc: 96.88%] [G loss: 5.606234]\n",
            "******* 2448 780 [D loss: 0.090909, acc: 96.88%] [G loss: 5.827937]\n",
            "******* 2449 780 [D loss: 0.142559, acc: 94.53%] [G loss: 5.227587]\n",
            "******* 2450 780 [D loss: 0.152462, acc: 95.31%] [G loss: 3.823523]\n",
            "******* 2451 780 [D loss: 0.251067, acc: 92.97%] [G loss: 4.873827]\n",
            "******* 2452 780 [D loss: 0.113109, acc: 96.09%] [G loss: 5.117192]\n",
            "******* 2453 780 [D loss: 0.137000, acc: 93.75%] [G loss: 5.298132]\n",
            "******* 2454 780 [D loss: 0.132433, acc: 95.31%] [G loss: 5.612248]\n",
            "******* 2455 780 [D loss: 0.149764, acc: 95.31%] [G loss: 4.300149]\n",
            "******* 2456 780 [D loss: 0.122691, acc: 92.97%] [G loss: 5.248960]\n",
            "******* 2457 780 [D loss: 0.064302, acc: 98.44%] [G loss: 6.154058]\n",
            "******* 2458 780 [D loss: 0.208678, acc: 92.19%] [G loss: 4.844803]\n",
            "******* 2459 780 [D loss: 0.164653, acc: 93.75%] [G loss: 4.721383]\n",
            "******* 2460 780 [D loss: 0.082247, acc: 97.66%] [G loss: 5.755060]\n",
            "******* 2461 780 [D loss: 0.062269, acc: 98.44%] [G loss: 5.906546]\n",
            "******* 2462 780 [D loss: 0.120638, acc: 96.09%] [G loss: 6.288542]\n",
            "******* 2463 780 [D loss: 0.152779, acc: 95.31%] [G loss: 5.854270]\n",
            "******* 2464 780 [D loss: 0.191988, acc: 91.41%] [G loss: 4.955665]\n",
            "******* 2465 780 [D loss: 0.080586, acc: 96.09%] [G loss: 5.312935]\n",
            "******* 2466 780 [D loss: 0.097823, acc: 97.66%] [G loss: 4.979864]\n",
            "******* 2467 780 [D loss: 0.189677, acc: 91.41%] [G loss: 4.239356]\n",
            "******* 2468 780 [D loss: 0.123233, acc: 96.09%] [G loss: 5.711534]\n",
            "******* 2469 780 [D loss: 0.069197, acc: 96.88%] [G loss: 6.702124]\n",
            "******* 2470 780 [D loss: 0.160458, acc: 93.75%] [G loss: 5.293293]\n",
            "******* 2471 780 [D loss: 0.258791, acc: 91.41%] [G loss: 5.262313]\n",
            "******* 2472 780 [D loss: 0.205943, acc: 95.31%] [G loss: 5.816030]\n",
            "******* 2473 780 [D loss: 0.205781, acc: 90.62%] [G loss: 4.823133]\n",
            "******* 2474 780 [D loss: 0.228768, acc: 92.19%] [G loss: 4.691460]\n",
            "******* 2475 780 [D loss: 0.178175, acc: 92.19%] [G loss: 4.440076]\n",
            "******* 2476 780 [D loss: 0.150368, acc: 93.75%] [G loss: 3.852422]\n",
            "******* 2477 780 [D loss: 0.193936, acc: 92.97%] [G loss: 4.745876]\n",
            "******* 2478 780 [D loss: 0.137676, acc: 96.09%] [G loss: 5.372524]\n",
            "******* 2479 780 [D loss: 0.224418, acc: 89.06%] [G loss: 4.998690]\n",
            "******* 2480 780 [D loss: 0.186375, acc: 91.41%] [G loss: 4.244464]\n",
            "******* 2481 780 [D loss: 0.176357, acc: 93.75%] [G loss: 4.767744]\n",
            "******* 2482 780 [D loss: 0.101705, acc: 96.88%] [G loss: 4.775059]\n",
            "******* 2483 780 [D loss: 0.116736, acc: 94.53%] [G loss: 4.483033]\n",
            "******* 2484 780 [D loss: 0.088905, acc: 98.44%] [G loss: 4.015180]\n",
            "******* 2485 780 [D loss: 0.111516, acc: 93.75%] [G loss: 3.914073]\n",
            "******* 2486 780 [D loss: 0.148668, acc: 93.75%] [G loss: 4.769313]\n",
            "******* 2487 780 [D loss: 0.067329, acc: 98.44%] [G loss: 4.991730]\n",
            "******* 2488 780 [D loss: 0.037328, acc: 98.44%] [G loss: 6.204607]\n",
            "******* 2489 780 [D loss: 0.088197, acc: 95.31%] [G loss: 5.895336]\n",
            "******* 2490 780 [D loss: 0.108475, acc: 96.88%] [G loss: 4.090365]\n",
            "******* 2491 780 [D loss: 0.213004, acc: 91.41%] [G loss: 3.773772]\n",
            "******* 2492 780 [D loss: 0.088318, acc: 96.88%] [G loss: 4.890267]\n",
            "******* 2493 780 [D loss: 0.135146, acc: 96.09%] [G loss: 5.323286]\n",
            "******* 2494 780 [D loss: 0.147559, acc: 94.53%] [G loss: 4.342919]\n",
            "******* 2495 780 [D loss: 0.173956, acc: 92.97%] [G loss: 5.659012]\n",
            "******* 2496 780 [D loss: 0.081501, acc: 95.31%] [G loss: 7.283212]\n",
            "******* 2497 780 [D loss: 0.114414, acc: 94.53%] [G loss: 5.451569]\n",
            "******* 2498 780 [D loss: 0.147274, acc: 93.75%] [G loss: 4.779327]\n",
            "******* 2499 780 [D loss: 0.145613, acc: 92.97%] [G loss: 6.193396]\n",
            "******* 2500 780 [D loss: 0.142949, acc: 93.75%] [G loss: 7.128119]\n",
            "******* 2501 780 [D loss: 0.314103, acc: 89.84%] [G loss: 4.892198]\n",
            "******* 2502 780 [D loss: 0.277500, acc: 90.62%] [G loss: 4.904401]\n",
            "******* 2503 780 [D loss: 0.058987, acc: 98.44%] [G loss: 5.646908]\n",
            "******* 2504 780 [D loss: 0.126484, acc: 93.75%] [G loss: 6.409874]\n",
            "******* 2505 780 [D loss: 0.082184, acc: 96.09%] [G loss: 6.846225]\n",
            "******* 2506 780 [D loss: 0.072119, acc: 96.88%] [G loss: 5.203640]\n",
            "******* 2507 780 [D loss: 0.299918, acc: 86.72%] [G loss: 5.808949]\n",
            "******* 2508 780 [D loss: 0.160161, acc: 93.75%] [G loss: 6.526540]\n",
            "******* 2509 780 [D loss: 0.282472, acc: 90.62%] [G loss: 5.395627]\n",
            "******* 2510 780 [D loss: 0.314959, acc: 89.84%] [G loss: 3.970017]\n",
            "******* 2511 780 [D loss: 0.182122, acc: 94.53%] [G loss: 4.157485]\n",
            "******* 2512 780 [D loss: 0.430288, acc: 86.72%] [G loss: 4.892993]\n",
            "******* 2513 780 [D loss: 0.323790, acc: 87.50%] [G loss: 4.152433]\n",
            "******* 2514 780 [D loss: 0.238423, acc: 88.28%] [G loss: 4.449984]\n",
            "******* 2515 780 [D loss: 0.258867, acc: 92.19%] [G loss: 4.462701]\n",
            "******* 2516 780 [D loss: 0.142656, acc: 94.53%] [G loss: 4.137376]\n",
            "******* 2517 780 [D loss: 0.085851, acc: 98.44%] [G loss: 4.206646]\n",
            "******* 2518 780 [D loss: 0.289375, acc: 91.41%] [G loss: 4.375703]\n",
            "******* 2519 780 [D loss: 0.185192, acc: 93.75%] [G loss: 4.926785]\n",
            "******* 2520 780 [D loss: 0.194993, acc: 92.97%] [G loss: 4.500585]\n",
            "******* 2521 780 [D loss: 0.142604, acc: 94.53%] [G loss: 2.906838]\n",
            "******* 2522 780 [D loss: 0.110199, acc: 96.09%] [G loss: 3.846350]\n",
            "******* 2523 780 [D loss: 0.110048, acc: 96.88%] [G loss: 3.809647]\n",
            "******* 2524 780 [D loss: 0.116503, acc: 95.31%] [G loss: 4.361307]\n",
            "******* 2525 780 [D loss: 0.047452, acc: 98.44%] [G loss: 5.763638]\n",
            "******* 2526 780 [D loss: 0.090631, acc: 99.22%] [G loss: 5.398241]\n",
            "******* 2527 780 [D loss: 0.154169, acc: 94.53%] [G loss: 4.798706]\n",
            "******* 2528 780 [D loss: 0.101695, acc: 97.66%] [G loss: 3.857049]\n",
            "******* 2529 780 [D loss: 0.120737, acc: 95.31%] [G loss: 4.164288]\n",
            "******* 2530 780 [D loss: 0.066859, acc: 98.44%] [G loss: 4.601105]\n",
            "******* 2531 780 [D loss: 0.036927, acc: 98.44%] [G loss: 5.460318]\n",
            "******* 2532 780 [D loss: 0.077039, acc: 96.09%] [G loss: 5.613913]\n",
            "******* 2533 780 [D loss: 0.134001, acc: 94.53%] [G loss: 4.393478]\n",
            "******* 2534 780 [D loss: 0.093805, acc: 96.09%] [G loss: 3.666963]\n",
            "******* 2535 780 [D loss: 0.125355, acc: 95.31%] [G loss: 4.003318]\n",
            "******* 2536 780 [D loss: 0.065525, acc: 97.66%] [G loss: 4.974870]\n",
            "******* 2537 780 [D loss: 0.053056, acc: 97.66%] [G loss: 5.721790]\n",
            "******* 2538 780 [D loss: 0.128157, acc: 92.97%] [G loss: 5.487539]\n",
            "******* 2539 780 [D loss: 0.137700, acc: 92.97%] [G loss: 4.794936]\n",
            "******* 2540 780 [D loss: 0.072179, acc: 97.66%] [G loss: 4.009957]\n",
            "******* 2541 780 [D loss: 0.064959, acc: 97.66%] [G loss: 3.668389]\n",
            "******* 2542 780 [D loss: 0.091680, acc: 96.88%] [G loss: 4.169952]\n",
            "******* 2543 780 [D loss: 0.063627, acc: 98.44%] [G loss: 5.009570]\n",
            "******* 2544 780 [D loss: 0.092193, acc: 96.09%] [G loss: 4.746742]\n",
            "******* 2545 780 [D loss: 0.082282, acc: 96.09%] [G loss: 4.384793]\n",
            "******* 2546 780 [D loss: 0.109673, acc: 96.88%] [G loss: 4.718427]\n",
            "******* 2547 780 [D loss: 0.066114, acc: 97.66%] [G loss: 4.670579]\n",
            "******* 2548 780 [D loss: 0.113670, acc: 97.66%] [G loss: 5.171445]\n",
            "******* 2549 780 [D loss: 0.212274, acc: 90.62%] [G loss: 4.181808]\n",
            "******* 2550 780 [D loss: 0.068384, acc: 99.22%] [G loss: 5.208162]\n",
            "******* 2551 780 [D loss: 0.080479, acc: 95.31%] [G loss: 5.188436]\n",
            "******* 2552 780 [D loss: 0.125190, acc: 97.66%] [G loss: 4.898012]\n",
            "******* 2553 780 [D loss: 0.074838, acc: 96.88%] [G loss: 3.928002]\n",
            "******* 2554 780 [D loss: 0.145149, acc: 92.97%] [G loss: 4.922493]\n",
            "******* 2555 780 [D loss: 0.173748, acc: 92.19%] [G loss: 5.430941]\n",
            "******* 2556 780 [D loss: 0.121620, acc: 94.53%] [G loss: 5.149008]\n",
            "******* 2557 780 [D loss: 0.136310, acc: 92.97%] [G loss: 5.205265]\n",
            "******* 2558 780 [D loss: 0.144362, acc: 95.31%] [G loss: 6.431849]\n",
            "******* 2559 780 [D loss: 0.374969, acc: 82.81%] [G loss: 3.655870]\n",
            "******* 2560 780 [D loss: 0.368597, acc: 83.59%] [G loss: 7.193850]\n",
            "******* 2561 780 [D loss: 0.118859, acc: 96.09%] [G loss: 9.506098]\n",
            "******* 2562 780 [D loss: 0.288331, acc: 89.84%] [G loss: 8.856745]\n",
            "******* 2563 780 [D loss: 0.865359, acc: 75.00%] [G loss: 5.304862]\n",
            "******* 2564 780 [D loss: 0.131044, acc: 93.75%] [G loss: 5.389860]\n",
            "******* 2565 780 [D loss: 0.050351, acc: 98.44%] [G loss: 6.342690]\n",
            "******* 2566 780 [D loss: 0.087440, acc: 95.31%] [G loss: 6.561119]\n",
            "******* 2567 780 [D loss: 0.122806, acc: 93.75%] [G loss: 6.299644]\n",
            "******* 2568 780 [D loss: 0.119292, acc: 95.31%] [G loss: 5.403361]\n",
            "******* 2569 780 [D loss: 0.106904, acc: 96.88%] [G loss: 4.594580]\n",
            "******* 2570 780 [D loss: 0.064397, acc: 98.44%] [G loss: 5.625093]\n",
            "******* 2571 780 [D loss: 0.205332, acc: 92.19%] [G loss: 5.275733]\n",
            "******* 2572 780 [D loss: 0.036305, acc: 99.22%] [G loss: 4.921679]\n",
            "******* 2573 780 [D loss: 0.209990, acc: 90.62%] [G loss: 4.620163]\n",
            "******* 2574 780 [D loss: 0.205435, acc: 91.41%] [G loss: 4.746367]\n",
            "******* 2575 780 [D loss: 0.127645, acc: 94.53%] [G loss: 5.294414]\n",
            "******* 2576 780 [D loss: 0.162290, acc: 92.97%] [G loss: 4.442376]\n",
            "******* 2577 780 [D loss: 0.135178, acc: 93.75%] [G loss: 3.166348]\n",
            "******* 2578 780 [D loss: 0.208567, acc: 90.62%] [G loss: 4.056050]\n",
            "******* 2579 780 [D loss: 0.096002, acc: 95.31%] [G loss: 5.441616]\n",
            "******* 2580 780 [D loss: 0.170134, acc: 92.97%] [G loss: 5.111215]\n",
            "******* 2581 780 [D loss: 0.252903, acc: 89.84%] [G loss: 3.838480]\n",
            "******* 2582 780 [D loss: 0.197952, acc: 91.41%] [G loss: 3.872614]\n",
            "******* 2583 780 [D loss: 0.122636, acc: 95.31%] [G loss: 5.293641]\n",
            "******* 2584 780 [D loss: 0.103327, acc: 95.31%] [G loss: 4.988118]\n",
            "******* 2585 780 [D loss: 0.143571, acc: 94.53%] [G loss: 3.970564]\n",
            "******* 2586 780 [D loss: 0.167361, acc: 94.53%] [G loss: 4.317303]\n",
            "******* 2587 780 [D loss: 0.156310, acc: 93.75%] [G loss: 4.741098]\n",
            "******* 2588 780 [D loss: 0.147696, acc: 92.19%] [G loss: 4.711394]\n",
            "******* 2589 780 [D loss: 0.090550, acc: 97.66%] [G loss: 4.500845]\n",
            "******* 2590 780 [D loss: 0.195550, acc: 92.97%] [G loss: 4.032154]\n",
            "******* 2591 780 [D loss: 0.060505, acc: 98.44%] [G loss: 4.522495]\n",
            "******* 2592 780 [D loss: 0.121449, acc: 95.31%] [G loss: 4.101838]\n",
            "******* 2593 780 [D loss: 0.087685, acc: 96.09%] [G loss: 4.990438]\n",
            "******* 2594 780 [D loss: 0.096634, acc: 96.88%] [G loss: 5.094252]\n",
            "******* 2595 780 [D loss: 0.063397, acc: 98.44%] [G loss: 5.177658]\n",
            "******* 2596 780 [D loss: 0.091436, acc: 96.09%] [G loss: 3.994284]\n",
            "******* 2597 780 [D loss: 0.092930, acc: 96.88%] [G loss: 4.677886]\n",
            "******* 2598 780 [D loss: 0.059680, acc: 98.44%] [G loss: 5.239790]\n",
            "******* 2599 780 [D loss: 0.083940, acc: 96.88%] [G loss: 5.160081]\n",
            "******* 2600 780 [D loss: 0.095880, acc: 95.31%] [G loss: 4.246460]\n",
            "******* 2601 780 [D loss: 0.054730, acc: 98.44%] [G loss: 4.292719]\n",
            "******* 2602 780 [D loss: 0.067152, acc: 97.66%] [G loss: 4.492981]\n",
            "******* 2603 780 [D loss: 0.013244, acc: 100.00%] [G loss: 5.183806]\n",
            "******* 2604 780 [D loss: 0.115512, acc: 96.09%] [G loss: 4.600928]\n",
            "******* 2605 780 [D loss: 0.080761, acc: 98.44%] [G loss: 4.657008]\n",
            "******* 2606 780 [D loss: 0.196824, acc: 92.97%] [G loss: 4.634239]\n",
            "******* 2607 780 [D loss: 0.081463, acc: 96.88%] [G loss: 4.928415]\n",
            "******* 2608 780 [D loss: 0.103265, acc: 96.09%] [G loss: 4.518936]\n",
            "******* 2609 780 [D loss: 0.160496, acc: 95.31%] [G loss: 4.505760]\n",
            "******* 2610 780 [D loss: 0.189959, acc: 91.41%] [G loss: 4.414714]\n",
            "******* 2611 780 [D loss: 0.185755, acc: 92.19%] [G loss: 4.717797]\n",
            "******* 2612 780 [D loss: 0.125789, acc: 96.09%] [G loss: 4.878603]\n",
            "******* 2613 780 [D loss: 0.162629, acc: 93.75%] [G loss: 5.399647]\n",
            "******* 2614 780 [D loss: 0.137090, acc: 96.09%] [G loss: 5.133916]\n",
            "******* 2615 780 [D loss: 0.155570, acc: 93.75%] [G loss: 4.720988]\n",
            "******* 2616 780 [D loss: 0.164791, acc: 92.19%] [G loss: 4.665448]\n",
            "******* 2617 780 [D loss: 0.270380, acc: 85.16%] [G loss: 4.286750]\n",
            "******* 2618 780 [D loss: 0.083985, acc: 95.31%] [G loss: 4.592844]\n",
            "******* 2619 780 [D loss: 0.079104, acc: 96.88%] [G loss: 5.024610]\n",
            "******* 2620 780 [D loss: 0.119491, acc: 95.31%] [G loss: 4.506044]\n",
            "******* 2621 780 [D loss: 0.058055, acc: 97.66%] [G loss: 4.291171]\n",
            "******* 2622 780 [D loss: 0.036072, acc: 100.00%] [G loss: 4.937835]\n",
            "******* 2623 780 [D loss: 0.147270, acc: 94.53%] [G loss: 4.567632]\n",
            "******* 2624 780 [D loss: 0.035558, acc: 99.22%] [G loss: 4.864411]\n",
            "******* 2625 780 [D loss: 0.076023, acc: 97.66%] [G loss: 5.318800]\n",
            "******* 2626 780 [D loss: 0.152573, acc: 94.53%] [G loss: 5.319432]\n",
            "******* 2627 780 [D loss: 0.064012, acc: 96.88%] [G loss: 4.684815]\n",
            "******* 2628 780 [D loss: 0.066169, acc: 98.44%] [G loss: 4.301238]\n",
            "******* 2629 780 [D loss: 0.102856, acc: 96.09%] [G loss: 4.773405]\n",
            "******* 2630 780 [D loss: 0.035034, acc: 98.44%] [G loss: 6.353818]\n",
            "******* 2631 780 [D loss: 0.095728, acc: 96.88%] [G loss: 5.517736]\n",
            "******* 2632 780 [D loss: 0.177005, acc: 93.75%] [G loss: 4.756211]\n",
            "******* 2633 780 [D loss: 0.109955, acc: 96.09%] [G loss: 4.292303]\n",
            "******* 2634 780 [D loss: 0.088662, acc: 97.66%] [G loss: 4.140465]\n",
            "******* 2635 780 [D loss: 0.109917, acc: 96.09%] [G loss: 4.734131]\n",
            "******* 2636 780 [D loss: 0.112382, acc: 96.09%] [G loss: 4.967039]\n",
            "******* 2637 780 [D loss: 0.188437, acc: 89.84%] [G loss: 4.081405]\n",
            "******* 2638 780 [D loss: 0.268219, acc: 92.19%] [G loss: 4.490659]\n",
            "******* 2639 780 [D loss: 0.067205, acc: 96.09%] [G loss: 5.850824]\n",
            "******* 2640 780 [D loss: 0.213952, acc: 92.19%] [G loss: 4.860653]\n",
            "******* 2641 780 [D loss: 0.113248, acc: 94.53%] [G loss: 4.062013]\n",
            "******* 2642 780 [D loss: 0.103698, acc: 96.09%] [G loss: 4.595726]\n",
            "******* 2643 780 [D loss: 0.122440, acc: 93.75%] [G loss: 6.371916]\n",
            "******* 2644 780 [D loss: 0.086353, acc: 96.88%] [G loss: 7.541948]\n",
            "******* 2645 780 [D loss: 0.189681, acc: 92.19%] [G loss: 6.033572]\n",
            "******* 2646 780 [D loss: 0.232990, acc: 92.19%] [G loss: 4.087483]\n",
            "******* 2647 780 [D loss: 0.191211, acc: 91.41%] [G loss: 5.587941]\n",
            "******* 2648 780 [D loss: 0.084200, acc: 96.09%] [G loss: 6.119497]\n",
            "******* 2649 780 [D loss: 0.255580, acc: 89.06%] [G loss: 5.046877]\n",
            "******* 2650 780 [D loss: 0.118616, acc: 91.41%] [G loss: 4.825561]\n",
            "******* 2651 780 [D loss: 0.112839, acc: 94.53%] [G loss: 5.866910]\n",
            "******* 2652 780 [D loss: 0.096701, acc: 95.31%] [G loss: 5.084595]\n",
            "******* 2653 780 [D loss: 0.085615, acc: 98.44%] [G loss: 4.576926]\n",
            "******* 2654 780 [D loss: 0.027125, acc: 99.22%] [G loss: 6.120115]\n",
            "******* 2655 780 [D loss: 0.027055, acc: 98.44%] [G loss: 6.695487]\n",
            "******* 2656 780 [D loss: 0.082835, acc: 96.09%] [G loss: 5.085591]\n",
            "******* 2657 780 [D loss: 0.069704, acc: 97.66%] [G loss: 4.509846]\n",
            "******* 2658 780 [D loss: 0.101775, acc: 95.31%] [G loss: 4.493183]\n",
            "******* 2659 780 [D loss: 0.019967, acc: 100.00%] [G loss: 6.435341]\n",
            "******* 2660 780 [D loss: 0.068427, acc: 97.66%] [G loss: 6.822268]\n",
            "******* 2661 780 [D loss: 0.089741, acc: 96.09%] [G loss: 5.519016]\n",
            "******* 2662 780 [D loss: 0.181329, acc: 94.53%] [G loss: 4.690661]\n",
            "******* 2663 780 [D loss: 0.157814, acc: 93.75%] [G loss: 4.612058]\n",
            "******* 2664 780 [D loss: 0.045618, acc: 97.66%] [G loss: 7.452195]\n",
            "******* 2665 780 [D loss: 0.186835, acc: 92.97%] [G loss: 6.251160]\n",
            "******* 2666 780 [D loss: 0.081258, acc: 96.88%] [G loss: 5.745292]\n",
            "******* 2667 780 [D loss: 0.223642, acc: 90.62%] [G loss: 4.774725]\n",
            "******* 2668 780 [D loss: 0.226031, acc: 90.62%] [G loss: 4.285776]\n",
            "******* 2669 780 [D loss: 0.046604, acc: 98.44%] [G loss: 4.761709]\n",
            "******* 2670 780 [D loss: 0.180418, acc: 91.41%] [G loss: 4.416000]\n",
            "******* 2671 780 [D loss: 0.268557, acc: 90.62%] [G loss: 4.305962]\n",
            "******* 2672 780 [D loss: 0.285099, acc: 87.50%] [G loss: 4.543909]\n",
            "******* 2673 780 [D loss: 0.138859, acc: 93.75%] [G loss: 4.976197]\n",
            "******* 2674 780 [D loss: 0.166729, acc: 93.75%] [G loss: 5.136515]\n",
            "******* 2675 780 [D loss: 0.287040, acc: 89.84%] [G loss: 3.759988]\n",
            "******* 2676 780 [D loss: 0.195712, acc: 88.28%] [G loss: 4.046760]\n",
            "******* 2677 780 [D loss: 0.116042, acc: 96.88%] [G loss: 4.002115]\n",
            "******* 2678 780 [D loss: 0.106427, acc: 96.09%] [G loss: 4.768535]\n",
            "******* 2679 780 [D loss: 0.140081, acc: 93.75%] [G loss: 4.984963]\n",
            "******* 2680 780 [D loss: 0.141231, acc: 94.53%] [G loss: 4.771238]\n",
            "******* 2681 780 [D loss: 0.305955, acc: 86.72%] [G loss: 4.174329]\n",
            "******* 2682 780 [D loss: 0.245520, acc: 91.41%] [G loss: 3.744370]\n",
            "******* 2683 780 [D loss: 0.100359, acc: 96.09%] [G loss: 4.099601]\n",
            "******* 2684 780 [D loss: 0.220772, acc: 88.28%] [G loss: 4.115775]\n",
            "******* 2685 780 [D loss: 0.131122, acc: 94.53%] [G loss: 4.252037]\n",
            "******* 2686 780 [D loss: 0.178318, acc: 96.88%] [G loss: 4.098132]\n",
            "******* 2687 780 [D loss: 0.204126, acc: 92.19%] [G loss: 3.430851]\n",
            "******* 2688 780 [D loss: 0.175644, acc: 91.41%] [G loss: 3.281870]\n",
            "******* 2689 780 [D loss: 0.196200, acc: 92.19%] [G loss: 3.945027]\n",
            "******* 2690 780 [D loss: 0.142738, acc: 96.88%] [G loss: 4.622232]\n",
            "******* 2691 780 [D loss: 0.220400, acc: 93.75%] [G loss: 4.077268]\n",
            "******* 2692 780 [D loss: 0.154136, acc: 92.97%] [G loss: 3.569768]\n",
            "******* 2693 780 [D loss: 0.144748, acc: 95.31%] [G loss: 3.708008]\n",
            "******* 2694 780 [D loss: 0.117472, acc: 95.31%] [G loss: 4.191367]\n",
            "******* 2695 780 [D loss: 0.295549, acc: 87.50%] [G loss: 3.920951]\n",
            "******* 2696 780 [D loss: 0.119402, acc: 95.31%] [G loss: 4.070690]\n",
            "******* 2697 780 [D loss: 0.114245, acc: 96.09%] [G loss: 4.101097]\n",
            "******* 2698 780 [D loss: 0.111943, acc: 96.88%] [G loss: 4.080476]\n",
            "******* 2699 780 [D loss: 0.112416, acc: 96.09%] [G loss: 4.213882]\n",
            "******* 2700 780 [D loss: 0.104686, acc: 96.09%] [G loss: 4.052597]\n",
            "******* 2701 780 [D loss: 0.053741, acc: 98.44%] [G loss: 4.450434]\n",
            "******* 2702 780 [D loss: 0.119426, acc: 96.09%] [G loss: 5.559256]\n",
            "******* 2703 780 [D loss: 0.122777, acc: 96.88%] [G loss: 5.824471]\n",
            "******* 2704 780 [D loss: 0.078503, acc: 96.88%] [G loss: 5.818963]\n",
            "******* 2705 780 [D loss: 0.036124, acc: 98.44%] [G loss: 6.153933]\n",
            "******* 2706 780 [D loss: 0.068746, acc: 96.88%] [G loss: 5.733116]\n",
            "******* 2707 780 [D loss: 0.140596, acc: 95.31%] [G loss: 5.333211]\n",
            "******* 2708 780 [D loss: 0.075198, acc: 96.88%] [G loss: 4.927135]\n",
            "******* 2709 780 [D loss: 0.159692, acc: 94.53%] [G loss: 4.944603]\n",
            "******* 2710 780 [D loss: 0.060901, acc: 96.88%] [G loss: 5.309115]\n",
            "******* 2711 780 [D loss: 0.114915, acc: 95.31%] [G loss: 5.501292]\n",
            "******* 2712 780 [D loss: 0.121712, acc: 96.88%] [G loss: 5.099164]\n",
            "******* 2713 780 [D loss: 0.106638, acc: 97.66%] [G loss: 4.717087]\n",
            "******* 2714 780 [D loss: 0.073428, acc: 97.66%] [G loss: 5.526507]\n",
            "******* 2715 780 [D loss: 0.146513, acc: 94.53%] [G loss: 6.942320]\n",
            "******* 2716 780 [D loss: 0.159520, acc: 92.19%] [G loss: 5.982214]\n",
            "******* 2717 780 [D loss: 0.209044, acc: 92.97%] [G loss: 3.914354]\n",
            "******* 2718 780 [D loss: 0.259049, acc: 92.19%] [G loss: 4.746199]\n",
            "******* 2719 780 [D loss: 0.069677, acc: 97.66%] [G loss: 7.216707]\n",
            "******* 2720 780 [D loss: 0.349827, acc: 92.19%] [G loss: 5.904641]\n",
            "******* 2721 780 [D loss: 0.251483, acc: 87.50%] [G loss: 4.232659]\n",
            "******* 2722 780 [D loss: 0.319754, acc: 89.06%] [G loss: 4.057606]\n",
            "******* 2723 780 [D loss: 0.064280, acc: 97.66%] [G loss: 5.322575]\n",
            "******* 2724 780 [D loss: 0.259981, acc: 90.62%] [G loss: 4.140284]\n",
            "******* 2725 780 [D loss: 0.344452, acc: 85.94%] [G loss: 4.211109]\n",
            "******* 2726 780 [D loss: 0.235999, acc: 95.31%] [G loss: 4.778213]\n",
            "******* 2727 780 [D loss: 0.197192, acc: 94.53%] [G loss: 4.605791]\n",
            "******* 2728 780 [D loss: 0.300250, acc: 89.84%] [G loss: 3.796885]\n",
            "******* 2729 780 [D loss: 0.228488, acc: 92.19%] [G loss: 3.330421]\n",
            "******* 2730 780 [D loss: 0.193399, acc: 92.97%] [G loss: 4.159569]\n",
            "******* 2731 780 [D loss: 0.232403, acc: 89.84%] [G loss: 4.125383]\n",
            "******* 2732 780 [D loss: 0.131757, acc: 93.75%] [G loss: 3.766031]\n",
            "******* 2733 780 [D loss: 0.176357, acc: 92.97%] [G loss: 3.682452]\n",
            "******* 2734 780 [D loss: 0.130389, acc: 95.31%] [G loss: 3.168788]\n",
            "******* 2735 780 [D loss: 0.110031, acc: 97.66%] [G loss: 3.489274]\n",
            "******* 2736 780 [D loss: 0.151879, acc: 94.53%] [G loss: 3.426564]\n",
            "******* 2737 780 [D loss: 0.122847, acc: 96.09%] [G loss: 3.735156]\n",
            "******* 2738 780 [D loss: 0.131774, acc: 94.53%] [G loss: 3.803253]\n",
            "******* 2739 780 [D loss: 0.070794, acc: 100.00%] [G loss: 3.561584]\n",
            "******* 2740 780 [D loss: 0.161061, acc: 95.31%] [G loss: 4.073516]\n",
            "******* 2741 780 [D loss: 0.092970, acc: 96.88%] [G loss: 3.663817]\n",
            "******* 2742 780 [D loss: 0.136881, acc: 94.53%] [G loss: 3.944415]\n",
            "******* 2743 780 [D loss: 0.085567, acc: 96.88%] [G loss: 3.893309]\n",
            "******* 2744 780 [D loss: 0.161288, acc: 93.75%] [G loss: 3.693262]\n",
            "******* 2745 780 [D loss: 0.159988, acc: 93.75%] [G loss: 4.152069]\n",
            "******* 2746 780 [D loss: 0.087487, acc: 97.66%] [G loss: 4.780910]\n",
            "******* 2747 780 [D loss: 0.154805, acc: 94.53%] [G loss: 4.384383]\n",
            "******* 2748 780 [D loss: 0.060012, acc: 98.44%] [G loss: 4.062719]\n",
            "******* 2749 780 [D loss: 0.210189, acc: 93.75%] [G loss: 3.858082]\n",
            "******* 2750 780 [D loss: 0.192854, acc: 92.19%] [G loss: 4.006808]\n",
            "******* 2751 780 [D loss: 0.113829, acc: 95.31%] [G loss: 3.367301]\n",
            "******* 2752 780 [D loss: 0.107197, acc: 95.31%] [G loss: 4.102582]\n",
            "******* 2753 780 [D loss: 0.329875, acc: 88.28%] [G loss: 3.307997]\n",
            "******* 2754 780 [D loss: 0.086815, acc: 97.66%] [G loss: 4.241851]\n",
            "******* 2755 780 [D loss: 0.147393, acc: 92.97%] [G loss: 4.258907]\n",
            "******* 2756 780 [D loss: 0.167704, acc: 94.53%] [G loss: 3.726824]\n",
            "******* 2757 780 [D loss: 0.117636, acc: 96.09%] [G loss: 3.733906]\n",
            "******* 2758 780 [D loss: 0.120671, acc: 95.31%] [G loss: 3.920513]\n",
            "******* 2759 780 [D loss: 0.059698, acc: 98.44%] [G loss: 4.584331]\n",
            "******* 2760 780 [D loss: 0.141365, acc: 95.31%] [G loss: 5.085320]\n",
            "******* 2761 780 [D loss: 0.065944, acc: 97.66%] [G loss: 4.989481]\n",
            "******* 2762 780 [D loss: 0.102107, acc: 96.09%] [G loss: 5.329385]\n",
            "******* 2763 780 [D loss: 0.197630, acc: 94.53%] [G loss: 4.611476]\n",
            "******* 2764 780 [D loss: 0.062450, acc: 96.88%] [G loss: 4.348168]\n",
            "******* 2765 780 [D loss: 0.069484, acc: 97.66%] [G loss: 4.124157]\n",
            "******* 2766 780 [D loss: 0.084023, acc: 96.88%] [G loss: 3.925087]\n",
            "******* 2767 780 [D loss: 0.060819, acc: 96.88%] [G loss: 3.679796]\n",
            "******* 2768 780 [D loss: 0.067958, acc: 97.66%] [G loss: 4.472104]\n",
            "******* 2769 780 [D loss: 0.082765, acc: 95.31%] [G loss: 4.520737]\n",
            "******* 2770 780 [D loss: 0.056681, acc: 98.44%] [G loss: 5.217131]\n",
            "******* 2771 780 [D loss: 0.080965, acc: 96.88%] [G loss: 4.514084]\n",
            "******* 2772 780 [D loss: 0.054196, acc: 98.44%] [G loss: 5.082767]\n",
            "******* 2773 780 [D loss: 0.052015, acc: 99.22%] [G loss: 5.661241]\n",
            "******* 2774 780 [D loss: 0.040392, acc: 99.22%] [G loss: 6.174028]\n",
            "******* 2775 780 [D loss: 0.076347, acc: 95.31%] [G loss: 5.531003]\n",
            "******* 2776 780 [D loss: 0.041069, acc: 98.44%] [G loss: 5.048822]\n",
            "******* 2777 780 [D loss: 0.050947, acc: 97.66%] [G loss: 4.591286]\n",
            "******* 2778 780 [D loss: 0.074498, acc: 96.88%] [G loss: 5.562839]\n",
            "******* 2779 780 [D loss: 0.030818, acc: 98.44%] [G loss: 6.700639]\n",
            "******* 2780 780 [D loss: 0.158072, acc: 92.97%] [G loss: 5.409105]\n",
            "******* 2781 780 [D loss: 0.094049, acc: 96.88%] [G loss: 4.221738]\n",
            "******* 2782 780 [D loss: 0.130035, acc: 98.44%] [G loss: 4.356359]\n",
            "******* 2783 780 [D loss: 0.203763, acc: 92.97%] [G loss: 6.282838]\n",
            "******* 2784 780 [D loss: 0.152959, acc: 96.09%] [G loss: 6.490990]\n",
            "******* 2785 780 [D loss: 0.181055, acc: 94.53%] [G loss: 5.755072]\n",
            "******* 2786 780 [D loss: 0.124406, acc: 96.09%] [G loss: 4.207519]\n",
            "******* 2787 780 [D loss: 0.168042, acc: 93.75%] [G loss: 3.932884]\n",
            "******* 2788 780 [D loss: 0.070292, acc: 97.66%] [G loss: 5.616717]\n",
            "******* 2789 780 [D loss: 0.086652, acc: 97.66%] [G loss: 5.853881]\n",
            "******* 2790 780 [D loss: 0.247715, acc: 89.84%] [G loss: 5.397743]\n",
            "******* 2791 780 [D loss: 0.218243, acc: 92.97%] [G loss: 4.544595]\n",
            "******* 2792 780 [D loss: 0.063600, acc: 98.44%] [G loss: 4.546638]\n",
            "******* 2793 780 [D loss: 0.106072, acc: 96.09%] [G loss: 4.883269]\n",
            "******* 2794 780 [D loss: 0.080536, acc: 97.66%] [G loss: 4.616850]\n",
            "******* 2795 780 [D loss: 0.091294, acc: 96.88%] [G loss: 4.887106]\n",
            "******* 2796 780 [D loss: 0.149779, acc: 94.53%] [G loss: 4.202356]\n",
            "******* 2797 780 [D loss: 0.100326, acc: 94.53%] [G loss: 4.253160]\n",
            "******* 2798 780 [D loss: 0.083213, acc: 96.88%] [G loss: 4.815411]\n",
            "******* 2799 780 [D loss: 0.059867, acc: 98.44%] [G loss: 5.251472]\n",
            "******* 2800 780 [D loss: 0.140918, acc: 94.53%] [G loss: 4.588486]\n",
            "******* 2801 780 [D loss: 0.201175, acc: 93.75%] [G loss: 3.943326]\n",
            "******* 2802 780 [D loss: 0.094340, acc: 96.09%] [G loss: 4.587584]\n",
            "******* 2803 780 [D loss: 0.095964, acc: 96.88%] [G loss: 5.194910]\n",
            "******* 2804 780 [D loss: 0.169243, acc: 89.84%] [G loss: 4.331421]\n",
            "******* 2805 780 [D loss: 0.163621, acc: 94.53%] [G loss: 5.779839]\n",
            "******* 2806 780 [D loss: 0.079356, acc: 96.88%] [G loss: 7.290994]\n",
            "******* 2807 780 [D loss: 0.181104, acc: 93.75%] [G loss: 5.341414]\n",
            "******* 2808 780 [D loss: 0.324212, acc: 84.38%] [G loss: 6.639408]\n",
            "******* 2809 780 [D loss: 0.183683, acc: 93.75%] [G loss: 6.631837]\n",
            "******* 2810 780 [D loss: 0.303284, acc: 89.84%] [G loss: 6.037899]\n",
            "******* 2811 780 [D loss: 0.114103, acc: 96.09%] [G loss: 5.303906]\n",
            "******* 2812 780 [D loss: 0.127439, acc: 96.09%] [G loss: 4.764170]\n",
            "******* 2813 780 [D loss: 0.096021, acc: 96.88%] [G loss: 4.158243]\n",
            "******* 2814 780 [D loss: 0.072278, acc: 97.66%] [G loss: 5.205188]\n",
            "******* 2815 780 [D loss: 0.078939, acc: 96.88%] [G loss: 5.433732]\n",
            "******* 2816 780 [D loss: 0.121079, acc: 97.66%] [G loss: 4.126210]\n",
            "******* 2817 780 [D loss: 0.133855, acc: 95.31%] [G loss: 4.293151]\n",
            "******* 2818 780 [D loss: 0.075000, acc: 97.66%] [G loss: 4.499371]\n",
            "******* 2819 780 [D loss: 0.107934, acc: 97.66%] [G loss: 4.570108]\n",
            "******* 2820 780 [D loss: 0.032439, acc: 98.44%] [G loss: 5.566374]\n",
            "******* 2821 780 [D loss: 0.150151, acc: 94.53%] [G loss: 5.077694]\n",
            "******* 2822 780 [D loss: 0.098372, acc: 96.09%] [G loss: 4.940416]\n",
            "******* 2823 780 [D loss: 0.127505, acc: 94.53%] [G loss: 4.715611]\n",
            "******* 2824 780 [D loss: 0.029637, acc: 99.22%] [G loss: 5.753525]\n",
            "******* 2825 780 [D loss: 0.070529, acc: 97.66%] [G loss: 5.987071]\n",
            "******* 2826 780 [D loss: 0.091794, acc: 96.88%] [G loss: 5.104789]\n",
            "******* 2827 780 [D loss: 0.074123, acc: 97.66%] [G loss: 3.913675]\n",
            "******* 2828 780 [D loss: 0.140369, acc: 95.31%] [G loss: 4.045547]\n",
            "******* 2829 780 [D loss: 0.099714, acc: 96.09%] [G loss: 5.000554]\n",
            "******* 2830 780 [D loss: 0.028302, acc: 98.44%] [G loss: 5.823214]\n",
            "******* 2831 780 [D loss: 0.094778, acc: 96.88%] [G loss: 5.764742]\n",
            "******* 2832 780 [D loss: 0.140081, acc: 94.53%] [G loss: 4.469115]\n",
            "******* 2833 780 [D loss: 0.140661, acc: 94.53%] [G loss: 3.769816]\n",
            "******* 2834 780 [D loss: 0.049858, acc: 96.88%] [G loss: 5.520529]\n",
            "******* 2835 780 [D loss: 0.105986, acc: 96.09%] [G loss: 4.921341]\n",
            "******* 2836 780 [D loss: 0.191644, acc: 90.62%] [G loss: 5.064266]\n",
            "******* 2837 780 [D loss: 0.038368, acc: 99.22%] [G loss: 6.219065]\n",
            "******* 2838 780 [D loss: 0.049715, acc: 97.66%] [G loss: 6.159434]\n",
            "******* 2839 780 [D loss: 0.128207, acc: 96.09%] [G loss: 5.634728]\n",
            "******* 2840 780 [D loss: 0.117236, acc: 95.31%] [G loss: 5.798985]\n",
            "******* 2841 780 [D loss: 0.038746, acc: 98.44%] [G loss: 5.162018]\n",
            "******* 2842 780 [D loss: 0.072009, acc: 97.66%] [G loss: 5.352649]\n",
            "******* 2843 780 [D loss: 0.164788, acc: 95.31%] [G loss: 4.747939]\n",
            "******* 2844 780 [D loss: 0.036056, acc: 99.22%] [G loss: 5.176357]\n",
            "******* 2845 780 [D loss: 0.108339, acc: 96.09%] [G loss: 4.605419]\n",
            "******* 2846 780 [D loss: 0.108130, acc: 95.31%] [G loss: 4.774753]\n",
            "******* 2847 780 [D loss: 0.096673, acc: 95.31%] [G loss: 4.802442]\n",
            "******* 2848 780 [D loss: 0.090976, acc: 96.88%] [G loss: 5.385174]\n",
            "******* 2849 780 [D loss: 0.265030, acc: 89.84%] [G loss: 3.786157]\n",
            "******* 2850 780 [D loss: 0.078825, acc: 96.88%] [G loss: 4.969093]\n",
            "******* 2851 780 [D loss: 0.052244, acc: 97.66%] [G loss: 6.205110]\n",
            "******* 2852 780 [D loss: 0.241925, acc: 93.75%] [G loss: 5.335490]\n",
            "******* 2853 780 [D loss: 0.087870, acc: 97.66%] [G loss: 4.877923]\n",
            "******* 2854 780 [D loss: 0.093298, acc: 96.09%] [G loss: 5.526971]\n",
            "******* 2855 780 [D loss: 0.218133, acc: 94.53%] [G loss: 6.348803]\n",
            "******* 2856 780 [D loss: 0.216348, acc: 92.97%] [G loss: 4.451114]\n",
            "******* 2857 780 [D loss: 0.279736, acc: 89.06%] [G loss: 6.242922]\n",
            "******* 2858 780 [D loss: 0.266219, acc: 92.97%] [G loss: 6.949509]\n",
            "******* 2859 780 [D loss: 0.244590, acc: 91.41%] [G loss: 4.848660]\n",
            "******* 2860 780 [D loss: 0.365285, acc: 88.28%] [G loss: 4.180106]\n",
            "******* 2861 780 [D loss: 0.204834, acc: 92.19%] [G loss: 3.752962]\n",
            "******* 2862 780 [D loss: 0.346414, acc: 85.94%] [G loss: 3.451087]\n",
            "******* 2863 780 [D loss: 0.168007, acc: 92.19%] [G loss: 3.693009]\n",
            "******* 2864 780 [D loss: 0.120215, acc: 98.44%] [G loss: 4.132880]\n",
            "******* 2865 780 [D loss: 0.190074, acc: 93.75%] [G loss: 3.789981]\n",
            "******* 2866 780 [D loss: 0.146509, acc: 93.75%] [G loss: 3.919549]\n",
            "******* 2867 780 [D loss: 0.083151, acc: 96.09%] [G loss: 4.480599]\n",
            "******* 2868 780 [D loss: 0.099339, acc: 94.53%] [G loss: 3.840755]\n",
            "******* 2869 780 [D loss: 0.140244, acc: 95.31%] [G loss: 3.988030]\n",
            "******* 2870 780 [D loss: 0.113514, acc: 96.88%] [G loss: 4.440644]\n",
            "******* 2871 780 [D loss: 0.119636, acc: 92.97%] [G loss: 4.282528]\n",
            "******* 2872 780 [D loss: 0.171505, acc: 95.31%] [G loss: 4.710516]\n",
            "******* 2873 780 [D loss: 0.100217, acc: 96.88%] [G loss: 4.763384]\n",
            "******* 2874 780 [D loss: 0.042872, acc: 97.66%] [G loss: 4.625233]\n",
            "******* 2875 780 [D loss: 0.043094, acc: 98.44%] [G loss: 4.430799]\n",
            "******* 2876 780 [D loss: 0.132000, acc: 94.53%] [G loss: 4.734322]\n",
            "******* 2877 780 [D loss: 0.120021, acc: 96.09%] [G loss: 4.325418]\n",
            "******* 2878 780 [D loss: 0.097973, acc: 96.88%] [G loss: 4.124449]\n",
            "******* 2879 780 [D loss: 0.097508, acc: 96.88%] [G loss: 4.332378]\n",
            "******* 2880 780 [D loss: 0.097581, acc: 96.88%] [G loss: 5.280367]\n",
            "******* 2881 780 [D loss: 0.051674, acc: 98.44%] [G loss: 5.456039]\n",
            "******* 2882 780 [D loss: 0.131751, acc: 94.53%] [G loss: 5.912508]\n",
            "******* 2883 780 [D loss: 0.030159, acc: 99.22%] [G loss: 5.573988]\n",
            "******* 2884 780 [D loss: 0.062043, acc: 97.66%] [G loss: 5.401577]\n",
            "******* 2885 780 [D loss: 0.086772, acc: 96.88%] [G loss: 4.363260]\n",
            "******* 2886 780 [D loss: 0.077777, acc: 97.66%] [G loss: 4.473730]\n",
            "******* 2887 780 [D loss: 0.059638, acc: 98.44%] [G loss: 5.828647]\n",
            "******* 2888 780 [D loss: 0.023947, acc: 99.22%] [G loss: 6.922011]\n",
            "******* 2889 780 [D loss: 0.193644, acc: 92.97%] [G loss: 5.230231]\n",
            "******* 2890 780 [D loss: 0.142410, acc: 95.31%] [G loss: 4.495566]\n",
            "******* 2891 780 [D loss: 0.115653, acc: 97.66%] [G loss: 5.412238]\n",
            "******* 2892 780 [D loss: 0.025168, acc: 99.22%] [G loss: 6.825577]\n",
            "******* 2893 780 [D loss: 0.102531, acc: 95.31%] [G loss: 5.780971]\n",
            "******* 2894 780 [D loss: 0.204108, acc: 92.97%] [G loss: 4.496031]\n",
            "******* 2895 780 [D loss: 0.109069, acc: 94.53%] [G loss: 4.458692]\n",
            "******* 2896 780 [D loss: 0.050098, acc: 97.66%] [G loss: 6.143161]\n",
            "******* 2897 780 [D loss: 0.087579, acc: 96.88%] [G loss: 5.942229]\n",
            "******* 2898 780 [D loss: 0.166470, acc: 93.75%] [G loss: 4.431625]\n",
            "******* 2899 780 [D loss: 0.153385, acc: 93.75%] [G loss: 4.612003]\n",
            "******* 2900 780 [D loss: 0.079693, acc: 97.66%] [G loss: 5.505589]\n",
            "******* 2901 780 [D loss: 0.184730, acc: 94.53%] [G loss: 4.872492]\n",
            "******* 2902 780 [D loss: 0.189291, acc: 90.62%] [G loss: 4.200400]\n",
            "******* 2903 780 [D loss: 0.172000, acc: 94.53%] [G loss: 4.218872]\n",
            "******* 2904 780 [D loss: 0.142828, acc: 94.53%] [G loss: 4.086441]\n",
            "******* 2905 780 [D loss: 0.156248, acc: 94.53%] [G loss: 4.500509]\n",
            "******* 2906 780 [D loss: 0.071601, acc: 96.88%] [G loss: 4.742325]\n",
            "******* 2907 780 [D loss: 0.180006, acc: 92.19%] [G loss: 4.903838]\n",
            "******* 2908 780 [D loss: 0.125763, acc: 95.31%] [G loss: 5.117930]\n",
            "******* 2909 780 [D loss: 0.093555, acc: 96.09%] [G loss: 4.393801]\n",
            "******* 2910 780 [D loss: 0.154023, acc: 92.97%] [G loss: 4.392247]\n",
            "******* 2911 780 [D loss: 0.144161, acc: 94.53%] [G loss: 4.595848]\n",
            "******* 2912 780 [D loss: 0.064199, acc: 99.22%] [G loss: 5.545731]\n",
            "******* 2913 780 [D loss: 0.136982, acc: 93.75%] [G loss: 5.177324]\n",
            "******* 2914 780 [D loss: 0.110631, acc: 96.09%] [G loss: 4.626658]\n",
            "******* 2915 780 [D loss: 0.153794, acc: 95.31%] [G loss: 4.871007]\n",
            "******* 2916 780 [D loss: 0.163166, acc: 92.97%] [G loss: 4.352363]\n",
            "******* 2917 780 [D loss: 0.119736, acc: 95.31%] [G loss: 5.384106]\n",
            "******* 2918 780 [D loss: 0.105915, acc: 96.88%] [G loss: 4.426373]\n",
            "******* 2919 780 [D loss: 0.107090, acc: 95.31%] [G loss: 4.368716]\n",
            "******* 2920 780 [D loss: 0.110680, acc: 96.09%] [G loss: 5.218966]\n",
            "******* 2921 780 [D loss: 0.133085, acc: 96.88%] [G loss: 5.470829]\n",
            "******* 2922 780 [D loss: 0.139998, acc: 95.31%] [G loss: 4.942112]\n",
            "******* 2923 780 [D loss: 0.118811, acc: 96.09%] [G loss: 4.695668]\n",
            "******* 2924 780 [D loss: 0.099714, acc: 95.31%] [G loss: 4.832680]\n",
            "******* 2925 780 [D loss: 0.158907, acc: 93.75%] [G loss: 5.475739]\n",
            "******* 2926 780 [D loss: 0.082806, acc: 96.88%] [G loss: 7.385701]\n",
            "******* 2927 780 [D loss: 0.326089, acc: 88.28%] [G loss: 5.221934]\n",
            "******* 2928 780 [D loss: 0.143054, acc: 96.88%] [G loss: 4.418695]\n",
            "******* 2929 780 [D loss: 0.181993, acc: 92.97%] [G loss: 5.408505]\n",
            "******* 2930 780 [D loss: 0.140601, acc: 94.53%] [G loss: 5.443689]\n",
            "******* 2931 780 [D loss: 0.181938, acc: 94.53%] [G loss: 5.923892]\n",
            "******* 2932 780 [D loss: 0.233744, acc: 90.62%] [G loss: 5.398211]\n",
            "******* 2933 780 [D loss: 0.245504, acc: 92.19%] [G loss: 4.867007]\n",
            "******* 2934 780 [D loss: 0.071487, acc: 97.66%] [G loss: 5.444052]\n",
            "******* 2935 780 [D loss: 0.119460, acc: 96.88%] [G loss: 6.580906]\n",
            "******* 2936 780 [D loss: 0.265203, acc: 88.28%] [G loss: 4.427321]\n",
            "******* 2937 780 [D loss: 0.114622, acc: 95.31%] [G loss: 4.350050]\n",
            "******* 2938 780 [D loss: 0.132349, acc: 95.31%] [G loss: 5.375199]\n",
            "******* 2939 780 [D loss: 0.147672, acc: 96.88%] [G loss: 5.172712]\n",
            "******* 2940 780 [D loss: 0.110963, acc: 95.31%] [G loss: 5.758862]\n",
            "******* 2941 780 [D loss: 0.018228, acc: 100.00%] [G loss: 6.695130]\n",
            "******* 2942 780 [D loss: 0.051568, acc: 98.44%] [G loss: 7.015049]\n",
            "******* 2943 780 [D loss: 0.136406, acc: 94.53%] [G loss: 6.807082]\n",
            "******* 2944 780 [D loss: 0.022803, acc: 100.00%] [G loss: 5.787930]\n",
            "******* 2945 780 [D loss: 0.243376, acc: 92.19%] [G loss: 5.355454]\n",
            "******* 2946 780 [D loss: 0.143660, acc: 92.97%] [G loss: 5.633421]\n",
            "******* 2947 780 [D loss: 0.106315, acc: 96.09%] [G loss: 5.793519]\n",
            "******* 2948 780 [D loss: 0.201476, acc: 93.75%] [G loss: 4.601375]\n",
            "******* 2949 780 [D loss: 0.196690, acc: 92.19%] [G loss: 4.493962]\n",
            "******* 2950 780 [D loss: 0.203042, acc: 90.62%] [G loss: 4.474854]\n",
            "******* 2951 780 [D loss: 0.248152, acc: 89.06%] [G loss: 4.760947]\n",
            "******* 2952 780 [D loss: 0.263155, acc: 92.97%] [G loss: 3.975977]\n",
            "******* 2953 780 [D loss: 0.287759, acc: 87.50%] [G loss: 4.604347]\n",
            "******* 2954 780 [D loss: 0.323598, acc: 87.50%] [G loss: 5.045650]\n",
            "******* 2955 780 [D loss: 0.198825, acc: 91.41%] [G loss: 4.880934]\n",
            "******* 2956 780 [D loss: 0.283634, acc: 90.62%] [G loss: 4.447961]\n",
            "******* 2957 780 [D loss: 0.078138, acc: 96.88%] [G loss: 4.422195]\n",
            "******* 2958 780 [D loss: 0.111056, acc: 96.09%] [G loss: 4.933880]\n",
            "******* 2959 780 [D loss: 0.035211, acc: 99.22%] [G loss: 5.838238]\n",
            "******* 2960 780 [D loss: 0.094414, acc: 97.66%] [G loss: 6.263079]\n",
            "******* 2961 780 [D loss: 0.070031, acc: 97.66%] [G loss: 6.111156]\n",
            "******* 2962 780 [D loss: 0.089042, acc: 96.88%] [G loss: 4.822025]\n",
            "******* 2963 780 [D loss: 0.055107, acc: 97.66%] [G loss: 5.504457]\n",
            "******* 2964 780 [D loss: 0.049410, acc: 96.88%] [G loss: 5.582880]\n",
            "******* 2965 780 [D loss: 0.028487, acc: 98.44%] [G loss: 6.322509]\n",
            "******* 2966 780 [D loss: 0.086632, acc: 96.88%] [G loss: 5.551519]\n",
            "******* 2967 780 [D loss: 0.016256, acc: 100.00%] [G loss: 6.380460]\n",
            "******* 2968 780 [D loss: 0.062728, acc: 96.88%] [G loss: 5.868373]\n",
            "******* 2969 780 [D loss: 0.075725, acc: 96.88%] [G loss: 5.280193]\n",
            "******* 2970 780 [D loss: 0.041047, acc: 98.44%] [G loss: 6.100577]\n",
            "******* 2971 780 [D loss: 0.073347, acc: 99.22%] [G loss: 5.563827]\n",
            "******* 2972 780 [D loss: 0.023558, acc: 99.22%] [G loss: 6.260093]\n",
            "******* 2973 780 [D loss: 0.022669, acc: 100.00%] [G loss: 5.915689]\n",
            "******* 2974 780 [D loss: 0.042949, acc: 97.66%] [G loss: 5.292860]\n",
            "******* 2975 780 [D loss: 0.146762, acc: 95.31%] [G loss: 5.305954]\n",
            "******* 2976 780 [D loss: 0.111253, acc: 96.09%] [G loss: 5.700791]\n",
            "******* 2977 780 [D loss: 0.120261, acc: 94.53%] [G loss: 5.207445]\n",
            "******* 2978 780 [D loss: 0.049521, acc: 98.44%] [G loss: 5.188947]\n",
            "******* 2979 780 [D loss: 0.048752, acc: 98.44%] [G loss: 5.279287]\n",
            "******* 2980 780 [D loss: 0.102652, acc: 92.97%] [G loss: 5.478497]\n",
            "******* 2981 780 [D loss: 0.085744, acc: 98.44%] [G loss: 5.726149]\n",
            "******* 2982 780 [D loss: 0.063179, acc: 99.22%] [G loss: 5.184708]\n",
            "******* 2983 780 [D loss: 0.113815, acc: 96.88%] [G loss: 5.781921]\n",
            "******* 2984 780 [D loss: 0.026720, acc: 99.22%] [G loss: 7.203267]\n",
            "******* 2985 780 [D loss: 0.081912, acc: 96.88%] [G loss: 6.950145]\n",
            "******* 2986 780 [D loss: 0.042129, acc: 97.66%] [G loss: 5.916964]\n",
            "******* 2987 780 [D loss: 0.106124, acc: 96.09%] [G loss: 5.934931]\n",
            "******* 2988 780 [D loss: 0.027650, acc: 99.22%] [G loss: 7.235138]\n",
            "******* 2989 780 [D loss: 0.039576, acc: 97.66%] [G loss: 7.333001]\n",
            "******* 2990 780 [D loss: 0.100181, acc: 94.53%] [G loss: 6.307592]\n",
            "******* 2991 780 [D loss: 0.056840, acc: 96.88%] [G loss: 6.456736]\n",
            "******* 2992 780 [D loss: 0.068623, acc: 98.44%] [G loss: 7.434711]\n",
            "******* 2993 780 [D loss: 0.096879, acc: 98.44%] [G loss: 7.320238]\n",
            "******* 2994 780 [D loss: 0.045478, acc: 97.66%] [G loss: 8.279172]\n",
            "******* 2995 780 [D loss: 0.059716, acc: 98.44%] [G loss: 7.873845]\n",
            "******* 2996 780 [D loss: 0.027955, acc: 99.22%] [G loss: 7.203959]\n",
            "******* 2997 780 [D loss: 0.038258, acc: 98.44%] [G loss: 5.191799]\n",
            "******* 2998 780 [D loss: 0.077497, acc: 96.88%] [G loss: 6.436439]\n",
            "******* 2999 780 [D loss: 0.053363, acc: 97.66%] [G loss: 8.508334]\n",
            "******* 3000 780 [D loss: 0.021940, acc: 98.44%] [G loss: 10.254532]\n",
            "******* 3001 780 [D loss: 0.342380, acc: 92.97%] [G loss: 5.515953]\n",
            "******* 3002 780 [D loss: 0.284588, acc: 85.94%] [G loss: 10.074273]\n",
            "******* 3003 780 [D loss: 0.245224, acc: 92.19%] [G loss: 11.813460]\n",
            "******* 3004 780 [D loss: 0.684000, acc: 81.25%] [G loss: 2.743509]\n",
            "******* 3005 780 [D loss: 2.403722, acc: 64.84%] [G loss: 8.615387]\n",
            "******* 3006 780 [D loss: 0.188857, acc: 94.53%] [G loss: 12.131940]\n",
            "******* 3007 780 [D loss: 1.663853, acc: 64.06%] [G loss: 5.336283]\n",
            "******* 3008 780 [D loss: 1.764759, acc: 53.12%] [G loss: 5.142958]\n",
            "******* 3009 780 [D loss: 0.441673, acc: 82.81%] [G loss: 6.704680]\n",
            "******* 3010 780 [D loss: 0.387002, acc: 82.03%] [G loss: 1.999662]\n",
            "******* 3011 780 [D loss: 1.356435, acc: 61.72%] [G loss: 5.981754]\n",
            "******* 3012 780 [D loss: 0.426961, acc: 85.94%] [G loss: 8.816057]\n",
            "******* 3013 780 [D loss: 1.054182, acc: 72.66%] [G loss: 5.964940]\n",
            "******* 3014 780 [D loss: 0.530225, acc: 78.91%] [G loss: 2.476819]\n",
            "******* 3015 780 [D loss: 0.540939, acc: 85.94%] [G loss: 3.794155]\n",
            "******* 3016 780 [D loss: 0.094636, acc: 95.31%] [G loss: 6.431308]\n",
            "******* 3017 780 [D loss: 0.160980, acc: 95.31%] [G loss: 8.141481]\n",
            "******* 3018 780 [D loss: 0.134018, acc: 95.31%] [G loss: 7.458971]\n",
            "******* 3019 780 [D loss: 0.280184, acc: 91.41%] [G loss: 6.135478]\n",
            "******* 3020 780 [D loss: 0.305059, acc: 92.97%] [G loss: 6.648592]\n",
            "******* 3021 780 [D loss: 0.059058, acc: 97.66%] [G loss: 8.308212]\n",
            "******* 3022 780 [D loss: 0.184716, acc: 93.75%] [G loss: 7.291115]\n",
            "******* 3023 780 [D loss: 0.155825, acc: 96.09%] [G loss: 6.379200]\n",
            "******* 3024 780 [D loss: 0.141597, acc: 96.09%] [G loss: 5.179642]\n",
            "******* 3025 780 [D loss: 0.286528, acc: 90.62%] [G loss: 4.600057]\n",
            "******* 3026 780 [D loss: 0.167863, acc: 92.19%] [G loss: 5.352843]\n",
            "******* 3027 780 [D loss: 0.135531, acc: 94.53%] [G loss: 4.952348]\n",
            "******* 3028 780 [D loss: 0.144940, acc: 95.31%] [G loss: 4.728865]\n",
            "******* 3029 780 [D loss: 0.229064, acc: 90.62%] [G loss: 3.928146]\n",
            "******* 3030 780 [D loss: 0.111853, acc: 95.31%] [G loss: 3.655783]\n",
            "******* 3031 780 [D loss: 0.098950, acc: 95.31%] [G loss: 4.734027]\n",
            "******* 3032 780 [D loss: 0.153663, acc: 92.19%] [G loss: 5.144459]\n",
            "******* 3033 780 [D loss: 0.223744, acc: 91.41%] [G loss: 4.602419]\n",
            "******* 3034 780 [D loss: 0.343911, acc: 89.84%] [G loss: 5.059419]\n",
            "******* 3035 780 [D loss: 0.101899, acc: 95.31%] [G loss: 5.459783]\n",
            "******* 3036 780 [D loss: 0.214212, acc: 89.84%] [G loss: 4.492011]\n",
            "******* 3037 780 [D loss: 0.217402, acc: 91.41%] [G loss: 3.423117]\n",
            "******* 3038 780 [D loss: 0.170125, acc: 94.53%] [G loss: 3.213531]\n",
            "******* 3039 780 [D loss: 0.138686, acc: 93.75%] [G loss: 3.661404]\n",
            "******* 3040 780 [D loss: 0.102975, acc: 96.09%] [G loss: 4.408467]\n",
            "******* 3041 780 [D loss: 0.167982, acc: 92.97%] [G loss: 4.309555]\n",
            "******* 3042 780 [D loss: 0.275684, acc: 91.41%] [G loss: 4.455396]\n",
            "******* 3043 780 [D loss: 0.090577, acc: 97.66%] [G loss: 4.386453]\n",
            "******* 3044 780 [D loss: 0.236718, acc: 91.41%] [G loss: 4.726879]\n",
            "******* 3045 780 [D loss: 0.118854, acc: 96.09%] [G loss: 4.757638]\n",
            "******* 3046 780 [D loss: 0.170903, acc: 94.53%] [G loss: 4.147289]\n",
            "******* 3047 780 [D loss: 0.219321, acc: 91.41%] [G loss: 3.864906]\n",
            "******* 3048 780 [D loss: 0.145069, acc: 96.09%] [G loss: 3.452173]\n",
            "******* 3049 780 [D loss: 0.100416, acc: 95.31%] [G loss: 4.190020]\n",
            "******* 3050 780 [D loss: 0.132579, acc: 95.31%] [G loss: 3.933492]\n",
            "******* 3051 780 [D loss: 0.101585, acc: 96.88%] [G loss: 4.182923]\n",
            "******* 3052 780 [D loss: 0.138571, acc: 95.31%] [G loss: 4.495228]\n",
            "******* 3053 780 [D loss: 0.091321, acc: 97.66%] [G loss: 4.245970]\n",
            "******* 3054 780 [D loss: 0.148362, acc: 95.31%] [G loss: 4.483247]\n",
            "******* 3055 780 [D loss: 0.045748, acc: 98.44%] [G loss: 4.624321]\n",
            "******* 3056 780 [D loss: 0.091600, acc: 96.88%] [G loss: 3.886638]\n",
            "******* 3057 780 [D loss: 0.089618, acc: 98.44%] [G loss: 3.934119]\n",
            "******* 3058 780 [D loss: 0.105797, acc: 96.88%] [G loss: 4.507272]\n",
            "******* 3059 780 [D loss: 0.110354, acc: 96.09%] [G loss: 5.077544]\n",
            "******* 3060 780 [D loss: 0.103518, acc: 97.66%] [G loss: 4.771160]\n",
            "******* 3061 780 [D loss: 0.232803, acc: 92.19%] [G loss: 4.202179]\n",
            "******* 3062 780 [D loss: 0.071936, acc: 96.88%] [G loss: 4.320733]\n",
            "******* 3063 780 [D loss: 0.153232, acc: 94.53%] [G loss: 4.552817]\n",
            "******* 3064 780 [D loss: 0.089617, acc: 96.09%] [G loss: 5.593473]\n",
            "******* 3065 780 [D loss: 0.157692, acc: 93.75%] [G loss: 4.871166]\n",
            "******* 3066 780 [D loss: 0.247147, acc: 88.28%] [G loss: 3.458493]\n",
            "******* 3067 780 [D loss: 0.205220, acc: 92.97%] [G loss: 3.847764]\n",
            "******* 3068 780 [D loss: 0.113731, acc: 96.09%] [G loss: 4.937089]\n",
            "******* 3069 780 [D loss: 0.134641, acc: 95.31%] [G loss: 4.904806]\n",
            "******* 3070 780 [D loss: 0.131518, acc: 95.31%] [G loss: 4.565908]\n",
            "******* 3071 780 [D loss: 0.159940, acc: 92.97%] [G loss: 3.420939]\n",
            "******* 3072 780 [D loss: 0.205914, acc: 90.62%] [G loss: 3.708480]\n",
            "******* 3073 780 [D loss: 0.247520, acc: 91.41%] [G loss: 4.657510]\n",
            "******* 3074 780 [D loss: 0.103703, acc: 96.88%] [G loss: 4.412767]\n",
            "******* 3075 780 [D loss: 0.210453, acc: 89.84%] [G loss: 3.756987]\n",
            "******* 3076 780 [D loss: 0.136792, acc: 92.97%] [G loss: 3.508391]\n",
            "******* 3077 780 [D loss: 0.113743, acc: 98.44%] [G loss: 3.979384]\n",
            "******* 3078 780 [D loss: 0.206272, acc: 93.75%] [G loss: 4.249222]\n",
            "******* 3079 780 [D loss: 0.216296, acc: 88.28%] [G loss: 4.128787]\n",
            "******* 3080 780 [D loss: 0.148237, acc: 94.53%] [G loss: 3.590620]\n",
            "******* 3081 780 [D loss: 0.148640, acc: 95.31%] [G loss: 4.015163]\n",
            "******* 3082 780 [D loss: 0.111054, acc: 96.88%] [G loss: 4.210265]\n",
            "******* 3083 780 [D loss: 0.111377, acc: 96.09%] [G loss: 4.481661]\n",
            "******* 3084 780 [D loss: 0.064990, acc: 99.22%] [G loss: 4.746537]\n",
            "******* 3085 780 [D loss: 0.134861, acc: 94.53%] [G loss: 4.618894]\n",
            "******* 3086 780 [D loss: 0.126739, acc: 92.97%] [G loss: 5.027852]\n",
            "******* 3087 780 [D loss: 0.130547, acc: 93.75%] [G loss: 5.270133]\n",
            "******* 3088 780 [D loss: 0.168697, acc: 93.75%] [G loss: 5.364635]\n",
            "******* 3089 780 [D loss: 0.079196, acc: 98.44%] [G loss: 5.346376]\n",
            "******* 3090 780 [D loss: 0.094886, acc: 94.53%] [G loss: 5.016438]\n",
            "******* 3091 780 [D loss: 0.126589, acc: 96.09%] [G loss: 4.469082]\n",
            "******* 3092 780 [D loss: 0.093974, acc: 96.88%] [G loss: 4.829836]\n",
            "******* 3093 780 [D loss: 0.068516, acc: 96.88%] [G loss: 6.059017]\n",
            "******* 3094 780 [D loss: 0.157568, acc: 93.75%] [G loss: 5.609852]\n",
            "******* 3095 780 [D loss: 0.214383, acc: 92.97%] [G loss: 4.623224]\n",
            "******* 3096 780 [D loss: 0.094647, acc: 96.09%] [G loss: 3.722136]\n",
            "******* 3097 780 [D loss: 0.213661, acc: 89.84%] [G loss: 4.542344]\n",
            "******* 3098 780 [D loss: 0.072847, acc: 98.44%] [G loss: 5.316819]\n",
            "******* 3099 780 [D loss: 0.117961, acc: 95.31%] [G loss: 5.837463]\n",
            "******* 3100 780 [D loss: 0.244521, acc: 91.41%] [G loss: 4.195978]\n",
            "******* 3101 780 [D loss: 0.281310, acc: 89.84%] [G loss: 3.241345]\n",
            "******* 3102 780 [D loss: 0.246149, acc: 90.62%] [G loss: 4.567436]\n",
            "******* 3103 780 [D loss: 0.086439, acc: 96.88%] [G loss: 7.439806]\n",
            "******* 3104 780 [D loss: 0.330439, acc: 86.72%] [G loss: 6.060557]\n",
            "******* 3105 780 [D loss: 0.177819, acc: 92.19%] [G loss: 3.670295]\n",
            "******* 3106 780 [D loss: 0.372007, acc: 84.38%] [G loss: 4.423791]\n",
            "******* 3107 780 [D loss: 0.091433, acc: 96.09%] [G loss: 5.877297]\n",
            "******* 3108 780 [D loss: 0.155428, acc: 92.19%] [G loss: 5.891887]\n",
            "******* 3109 780 [D loss: 0.106800, acc: 96.88%] [G loss: 4.753340]\n",
            "******* 3110 780 [D loss: 0.093758, acc: 96.88%] [G loss: 2.925013]\n",
            "******* 3111 780 [D loss: 0.314714, acc: 91.41%] [G loss: 3.994947]\n",
            "******* 3112 780 [D loss: 0.143389, acc: 94.53%] [G loss: 6.340514]\n",
            "******* 3113 780 [D loss: 0.132822, acc: 95.31%] [G loss: 6.482773]\n",
            "******* 3114 780 [D loss: 0.262007, acc: 89.84%] [G loss: 5.342645]\n",
            "******* 3115 780 [D loss: 0.110720, acc: 94.53%] [G loss: 3.423716]\n",
            "******* 3116 780 [D loss: 0.183187, acc: 92.97%] [G loss: 3.461128]\n",
            "******* 3117 780 [D loss: 0.117498, acc: 95.31%] [G loss: 4.249679]\n",
            "******* 3118 780 [D loss: 0.085862, acc: 97.66%] [G loss: 5.322216]\n",
            "******* 3119 780 [D loss: 0.048312, acc: 98.44%] [G loss: 5.757276]\n",
            "******* 3120 780 [D loss: 0.182451, acc: 89.06%] [G loss: 5.156581]\n",
            "******* 3121 780 [D loss: 0.096286, acc: 97.66%] [G loss: 4.202983]\n",
            "******* 3122 780 [D loss: 0.182357, acc: 93.75%] [G loss: 4.290450]\n",
            "******* 3123 780 [D loss: 0.080921, acc: 96.88%] [G loss: 5.126900]\n",
            "******* 3124 780 [D loss: 0.201278, acc: 92.19%] [G loss: 5.332564]\n",
            "******* 3125 780 [D loss: 0.130176, acc: 94.53%] [G loss: 4.407200]\n",
            "******* 3126 780 [D loss: 0.120320, acc: 96.09%] [G loss: 3.436756]\n",
            "******* 3127 780 [D loss: 0.227306, acc: 92.19%] [G loss: 3.983364]\n",
            "******* 3128 780 [D loss: 0.162764, acc: 94.53%] [G loss: 4.674644]\n",
            "******* 3129 780 [D loss: 0.329638, acc: 87.50%] [G loss: 3.603875]\n",
            "******* 3130 780 [D loss: 0.229638, acc: 89.06%] [G loss: 3.555486]\n",
            "******* 3131 780 [D loss: 0.125942, acc: 96.09%] [G loss: 3.539725]\n",
            "******* 3132 780 [D loss: 0.215115, acc: 91.41%] [G loss: 4.361271]\n",
            "******* 3133 780 [D loss: 0.194358, acc: 92.97%] [G loss: 3.304570]\n",
            "******* 3134 780 [D loss: 0.120570, acc: 96.09%] [G loss: 3.608275]\n",
            "******* 3135 780 [D loss: 0.089991, acc: 98.44%] [G loss: 4.653767]\n",
            "******* 3136 780 [D loss: 0.089170, acc: 96.88%] [G loss: 5.670404]\n",
            "******* 3137 780 [D loss: 0.206075, acc: 93.75%] [G loss: 4.114659]\n",
            "******* 3138 780 [D loss: 0.195752, acc: 94.53%] [G loss: 3.130256]\n",
            "******* 3139 780 [D loss: 0.150539, acc: 94.53%] [G loss: 3.705737]\n",
            "******* 3140 780 [D loss: 0.096618, acc: 96.88%] [G loss: 5.667135]\n",
            "******* 3141 780 [D loss: 0.092883, acc: 96.88%] [G loss: 6.400936]\n",
            "******* 3142 780 [D loss: 0.117664, acc: 96.09%] [G loss: 5.720557]\n",
            "******* 3143 780 [D loss: 0.099101, acc: 94.53%] [G loss: 5.141546]\n",
            "******* 3144 780 [D loss: 0.176405, acc: 94.53%] [G loss: 3.715130]\n",
            "******* 3145 780 [D loss: 0.100877, acc: 96.09%] [G loss: 4.341990]\n",
            "******* 3146 780 [D loss: 0.095495, acc: 96.88%] [G loss: 4.675459]\n",
            "******* 3147 780 [D loss: 0.141216, acc: 93.75%] [G loss: 4.827734]\n",
            "******* 3148 780 [D loss: 0.090622, acc: 96.88%] [G loss: 5.021013]\n",
            "******* 3149 780 [D loss: 0.087851, acc: 96.88%] [G loss: 5.104937]\n",
            "******* 3150 780 [D loss: 0.147176, acc: 94.53%] [G loss: 4.358328]\n",
            "******* 3151 780 [D loss: 0.143813, acc: 92.19%] [G loss: 3.726439]\n",
            "******* 3152 780 [D loss: 0.120719, acc: 97.66%] [G loss: 3.803849]\n",
            "******* 3153 780 [D loss: 0.174080, acc: 92.19%] [G loss: 3.587197]\n",
            "******* 3154 780 [D loss: 0.119708, acc: 95.31%] [G loss: 4.026920]\n",
            "******* 3155 780 [D loss: 0.094985, acc: 97.66%] [G loss: 4.450302]\n",
            "******* 3156 780 [D loss: 0.097191, acc: 95.31%] [G loss: 4.984945]\n",
            "******* 3157 780 [D loss: 0.092512, acc: 97.66%] [G loss: 5.080973]\n",
            "******* 3158 780 [D loss: 0.098429, acc: 97.66%] [G loss: 4.131134]\n",
            "******* 3159 780 [D loss: 0.134572, acc: 96.88%] [G loss: 4.049808]\n",
            "******* 3160 780 [D loss: 0.086549, acc: 96.09%] [G loss: 3.982005]\n",
            "******* 3161 780 [D loss: 0.061894, acc: 97.66%] [G loss: 4.294026]\n",
            "******* 3162 780 [D loss: 0.062816, acc: 98.44%] [G loss: 5.236843]\n",
            "******* 3163 780 [D loss: 0.156341, acc: 94.53%] [G loss: 4.186840]\n",
            "******* 3164 780 [D loss: 0.167617, acc: 91.41%] [G loss: 3.985564]\n",
            "******* 3165 780 [D loss: 0.027075, acc: 100.00%] [G loss: 5.824421]\n",
            "******* 3166 780 [D loss: 0.056169, acc: 99.22%] [G loss: 6.732771]\n",
            "******* 3167 780 [D loss: 0.200599, acc: 93.75%] [G loss: 4.645921]\n",
            "******* 3168 780 [D loss: 0.197076, acc: 92.19%] [G loss: 4.601560]\n",
            "******* 3169 780 [D loss: 0.134357, acc: 95.31%] [G loss: 6.924640]\n",
            "******* 3170 780 [D loss: 0.080849, acc: 96.09%] [G loss: 7.397485]\n",
            "******* 3171 780 [D loss: 0.229483, acc: 91.41%] [G loss: 4.596531]\n",
            "******* 3172 780 [D loss: 0.200068, acc: 92.19%] [G loss: 4.434205]\n",
            "******* 3173 780 [D loss: 0.033376, acc: 99.22%] [G loss: 5.260332]\n",
            "******* 3174 780 [D loss: 0.053989, acc: 98.44%] [G loss: 5.713079]\n",
            "******* 3175 780 [D loss: 0.042997, acc: 98.44%] [G loss: 6.216027]\n",
            "******* 3176 780 [D loss: 0.061763, acc: 97.66%] [G loss: 6.060678]\n",
            "******* 3177 780 [D loss: 0.161470, acc: 92.97%] [G loss: 4.767303]\n",
            "******* 3178 780 [D loss: 0.128284, acc: 94.53%] [G loss: 5.412940]\n",
            "******* 3179 780 [D loss: 0.139814, acc: 96.09%] [G loss: 5.187092]\n",
            "******* 3180 780 [D loss: 0.041921, acc: 99.22%] [G loss: 4.518749]\n",
            "******* 3181 780 [D loss: 0.204495, acc: 92.19%] [G loss: 5.323541]\n",
            "******* 3182 780 [D loss: 0.142368, acc: 95.31%] [G loss: 6.309820]\n",
            "******* 3183 780 [D loss: 0.161306, acc: 93.75%] [G loss: 6.556300]\n",
            "******* 3184 780 [D loss: 0.179225, acc: 92.97%] [G loss: 4.446647]\n",
            "******* 3185 780 [D loss: 0.247614, acc: 92.19%] [G loss: 3.152935]\n",
            "******* 3186 780 [D loss: 0.237697, acc: 89.84%] [G loss: 4.906056]\n",
            "******* 3187 780 [D loss: 0.196028, acc: 93.75%] [G loss: 6.313248]\n",
            "******* 3188 780 [D loss: 0.153856, acc: 94.53%] [G loss: 6.146152]\n",
            "******* 3189 780 [D loss: 0.253849, acc: 91.41%] [G loss: 3.769723]\n",
            "******* 3190 780 [D loss: 0.456640, acc: 82.81%] [G loss: 4.130216]\n",
            "******* 3191 780 [D loss: 0.075028, acc: 95.31%] [G loss: 6.420098]\n",
            "******* 3192 780 [D loss: 0.524357, acc: 81.25%] [G loss: 4.994508]\n",
            "******* 3193 780 [D loss: 0.330797, acc: 84.38%] [G loss: 4.141979]\n",
            "******* 3194 780 [D loss: 0.132671, acc: 92.97%] [G loss: 4.524615]\n",
            "******* 3195 780 [D loss: 0.146985, acc: 92.19%] [G loss: 5.110709]\n",
            "******* 3196 780 [D loss: 0.180776, acc: 93.75%] [G loss: 4.624739]\n",
            "******* 3197 780 [D loss: 0.183675, acc: 94.53%] [G loss: 4.048642]\n",
            "******* 3198 780 [D loss: 0.149420, acc: 92.19%] [G loss: 4.261085]\n",
            "******* 3199 780 [D loss: 0.176084, acc: 91.41%] [G loss: 4.483651]\n",
            "******* 3200 780 [D loss: 0.215420, acc: 92.19%] [G loss: 4.910487]\n",
            "******* 3201 780 [D loss: 0.115768, acc: 96.09%] [G loss: 5.573610]\n",
            "******* 3202 780 [D loss: 0.205268, acc: 92.19%] [G loss: 4.535610]\n",
            "******* 3203 780 [D loss: 0.217166, acc: 91.41%] [G loss: 3.923027]\n",
            "******* 3204 780 [D loss: 0.163748, acc: 96.09%] [G loss: 3.541650]\n",
            "******* 3205 780 [D loss: 0.267245, acc: 91.41%] [G loss: 3.516743]\n",
            "******* 3206 780 [D loss: 0.233717, acc: 92.19%] [G loss: 4.014834]\n",
            "******* 3207 780 [D loss: 0.094649, acc: 96.09%] [G loss: 4.013114]\n",
            "******* 3208 780 [D loss: 0.118478, acc: 96.09%] [G loss: 4.767353]\n",
            "******* 3209 780 [D loss: 0.083531, acc: 96.09%] [G loss: 4.593879]\n",
            "******* 3210 780 [D loss: 0.179534, acc: 93.75%] [G loss: 4.047627]\n",
            "******* 3211 780 [D loss: 0.110298, acc: 96.09%] [G loss: 3.854169]\n",
            "******* 3212 780 [D loss: 0.148858, acc: 91.41%] [G loss: 3.136225]\n",
            "******* 3213 780 [D loss: 0.122105, acc: 94.53%] [G loss: 3.614251]\n",
            "******* 3214 780 [D loss: 0.131684, acc: 95.31%] [G loss: 4.061365]\n",
            "******* 3215 780 [D loss: 0.090323, acc: 96.09%] [G loss: 4.247004]\n",
            "******* 3216 780 [D loss: 0.186774, acc: 92.97%] [G loss: 4.473217]\n",
            "******* 3217 780 [D loss: 0.117481, acc: 96.09%] [G loss: 3.826308]\n",
            "******* 3218 780 [D loss: 0.096129, acc: 97.66%] [G loss: 4.129180]\n",
            "******* 3219 780 [D loss: 0.065377, acc: 98.44%] [G loss: 4.491016]\n",
            "******* 3220 780 [D loss: 0.070817, acc: 98.44%] [G loss: 5.182325]\n",
            "******* 3221 780 [D loss: 0.180249, acc: 92.19%] [G loss: 4.344451]\n",
            "******* 3222 780 [D loss: 0.245998, acc: 92.19%] [G loss: 4.063620]\n",
            "******* 3223 780 [D loss: 0.066306, acc: 97.66%] [G loss: 4.671092]\n",
            "******* 3224 780 [D loss: 0.171401, acc: 94.53%] [G loss: 4.849961]\n",
            "******* 3225 780 [D loss: 0.161887, acc: 93.75%] [G loss: 3.554374]\n",
            "******* 3226 780 [D loss: 0.183887, acc: 89.84%] [G loss: 3.876546]\n",
            "******* 3227 780 [D loss: 0.058956, acc: 98.44%] [G loss: 5.259571]\n",
            "******* 3228 780 [D loss: 0.067546, acc: 97.66%] [G loss: 6.343013]\n",
            "******* 3229 780 [D loss: 0.217328, acc: 92.97%] [G loss: 4.725816]\n",
            "******* 3230 780 [D loss: 0.098526, acc: 96.88%] [G loss: 3.869874]\n",
            "******* 3231 780 [D loss: 0.096303, acc: 96.09%] [G loss: 3.339829]\n",
            "******* 3232 780 [D loss: 0.091258, acc: 97.66%] [G loss: 4.634363]\n",
            "******* 3233 780 [D loss: 0.092863, acc: 96.09%] [G loss: 4.713433]\n",
            "******* 3234 780 [D loss: 0.158468, acc: 95.31%] [G loss: 4.561771]\n",
            "******* 3235 780 [D loss: 0.080662, acc: 96.09%] [G loss: 4.941057]\n",
            "******* 3236 780 [D loss: 0.117499, acc: 96.09%] [G loss: 3.930092]\n",
            "******* 3237 780 [D loss: 0.057460, acc: 99.22%] [G loss: 4.511557]\n",
            "******* 3238 780 [D loss: 0.178781, acc: 93.75%] [G loss: 3.909849]\n",
            "******* 3239 780 [D loss: 0.084751, acc: 99.22%] [G loss: 4.194553]\n",
            "******* 3240 780 [D loss: 0.070223, acc: 98.44%] [G loss: 4.413281]\n",
            "******* 3241 780 [D loss: 0.129300, acc: 94.53%] [G loss: 4.032994]\n",
            "******* 3242 780 [D loss: 0.080654, acc: 98.44%] [G loss: 4.322870]\n",
            "******* 3243 780 [D loss: 0.126723, acc: 95.31%] [G loss: 3.962049]\n",
            "******* 3244 780 [D loss: 0.150013, acc: 93.75%] [G loss: 3.764918]\n",
            "******* 3245 780 [D loss: 0.141559, acc: 93.75%] [G loss: 4.067695]\n",
            "******* 3246 780 [D loss: 0.203702, acc: 90.62%] [G loss: 4.517164]\n",
            "******* 3247 780 [D loss: 0.118769, acc: 95.31%] [G loss: 5.940234]\n",
            "******* 3248 780 [D loss: 0.269839, acc: 90.62%] [G loss: 4.554586]\n",
            "******* 3249 780 [D loss: 0.209774, acc: 92.19%] [G loss: 2.396410]\n",
            "******* 3250 780 [D loss: 0.288351, acc: 87.50%] [G loss: 4.036943]\n",
            "******* 3251 780 [D loss: 0.119476, acc: 95.31%] [G loss: 5.826604]\n",
            "******* 3252 780 [D loss: 0.238544, acc: 89.84%] [G loss: 4.896174]\n",
            "******* 3253 780 [D loss: 0.171574, acc: 89.84%] [G loss: 3.537862]\n",
            "******* 3254 780 [D loss: 0.167219, acc: 96.88%] [G loss: 2.822315]\n",
            "******* 3255 780 [D loss: 0.144934, acc: 94.53%] [G loss: 4.004457]\n",
            "******* 3256 780 [D loss: 0.028772, acc: 100.00%] [G loss: 5.323634]\n",
            "******* 3257 780 [D loss: 0.090515, acc: 96.09%] [G loss: 5.749959]\n",
            "******* 3258 780 [D loss: 0.164073, acc: 93.75%] [G loss: 4.595655]\n",
            "******* 3259 780 [D loss: 0.156380, acc: 93.75%] [G loss: 3.340759]\n",
            "******* 3260 780 [D loss: 0.167325, acc: 92.19%] [G loss: 3.880360]\n",
            "******* 3261 780 [D loss: 0.064479, acc: 98.44%] [G loss: 5.290397]\n",
            "******* 3262 780 [D loss: 0.102435, acc: 95.31%] [G loss: 6.025197]\n",
            "******* 3263 780 [D loss: 0.127271, acc: 93.75%] [G loss: 6.340949]\n",
            "******* 3264 780 [D loss: 0.132211, acc: 93.75%] [G loss: 4.603014]\n",
            "******* 3265 780 [D loss: 0.140494, acc: 94.53%] [G loss: 3.114057]\n",
            "******* 3266 780 [D loss: 0.150937, acc: 93.75%] [G loss: 4.051716]\n",
            "******* 3267 780 [D loss: 0.090503, acc: 96.09%] [G loss: 5.799343]\n",
            "******* 3268 780 [D loss: 0.126139, acc: 94.53%] [G loss: 5.987469]\n",
            "******* 3269 780 [D loss: 0.116963, acc: 97.66%] [G loss: 5.017680]\n",
            "******* 3270 780 [D loss: 0.064470, acc: 97.66%] [G loss: 4.384427]\n",
            "******* 3271 780 [D loss: 0.139091, acc: 96.09%] [G loss: 5.174934]\n",
            "******* 3272 780 [D loss: 0.065956, acc: 96.88%] [G loss: 6.209519]\n",
            "******* 3273 780 [D loss: 0.118174, acc: 96.09%] [G loss: 6.358582]\n",
            "******* 3274 780 [D loss: 0.140911, acc: 93.75%] [G loss: 5.075520]\n",
            "******* 3275 780 [D loss: 0.144831, acc: 94.53%] [G loss: 4.582399]\n",
            "******* 3276 780 [D loss: 0.080193, acc: 95.31%] [G loss: 5.496522]\n",
            "******* 3277 780 [D loss: 0.114380, acc: 96.88%] [G loss: 6.355685]\n",
            "******* 3278 780 [D loss: 0.156901, acc: 94.53%] [G loss: 5.755387]\n",
            "******* 3279 780 [D loss: 0.156215, acc: 93.75%] [G loss: 5.880468]\n",
            "******* 3280 780 [D loss: 0.042558, acc: 98.44%] [G loss: 7.698615]\n",
            "******* 3281 780 [D loss: 0.151326, acc: 94.53%] [G loss: 5.703765]\n",
            "******* 3282 780 [D loss: 0.207891, acc: 92.19%] [G loss: 4.087728]\n",
            "******* 3283 780 [D loss: 0.231383, acc: 92.19%] [G loss: 4.877541]\n",
            "******* 3284 780 [D loss: 0.132135, acc: 94.53%] [G loss: 5.940265]\n",
            "******* 3285 780 [D loss: 0.140391, acc: 94.53%] [G loss: 6.601984]\n",
            "******* 3286 780 [D loss: 0.159735, acc: 95.31%] [G loss: 5.496290]\n",
            "******* 3287 780 [D loss: 0.212088, acc: 87.50%] [G loss: 4.172245]\n",
            "******* 3288 780 [D loss: 0.146492, acc: 95.31%] [G loss: 4.432410]\n",
            "******* 3289 780 [D loss: 0.148909, acc: 94.53%] [G loss: 4.932367]\n",
            "******* 3290 780 [D loss: 0.108417, acc: 96.09%] [G loss: 5.829209]\n",
            "******* 3291 780 [D loss: 0.371973, acc: 85.16%] [G loss: 4.297230]\n",
            "******* 3292 780 [D loss: 0.358050, acc: 88.28%] [G loss: 3.381485]\n",
            "******* 3293 780 [D loss: 0.218566, acc: 89.84%] [G loss: 3.845790]\n",
            "******* 3294 780 [D loss: 0.159459, acc: 92.97%] [G loss: 4.553235]\n",
            "******* 3295 780 [D loss: 0.109793, acc: 94.53%] [G loss: 4.093918]\n",
            "******* 3296 780 [D loss: 0.125349, acc: 93.75%] [G loss: 3.454290]\n",
            "******* 3297 780 [D loss: 0.155538, acc: 93.75%] [G loss: 3.278674]\n",
            "******* 3298 780 [D loss: 0.154623, acc: 93.75%] [G loss: 3.904493]\n",
            "******* 3299 780 [D loss: 0.091842, acc: 97.66%] [G loss: 4.755978]\n",
            "******* 3300 780 [D loss: 0.086145, acc: 97.66%] [G loss: 5.426122]\n",
            "******* 3301 780 [D loss: 0.059080, acc: 97.66%] [G loss: 5.563687]\n",
            "******* 3302 780 [D loss: 0.053308, acc: 97.66%] [G loss: 5.305770]\n",
            "******* 3303 780 [D loss: 0.105023, acc: 95.31%] [G loss: 5.144494]\n",
            "******* 3304 780 [D loss: 0.042193, acc: 99.22%] [G loss: 5.315233]\n",
            "******* 3305 780 [D loss: 0.067263, acc: 96.88%] [G loss: 5.638447]\n",
            "******* 3306 780 [D loss: 0.037211, acc: 99.22%] [G loss: 5.352740]\n",
            "******* 3307 780 [D loss: 0.046115, acc: 97.66%] [G loss: 5.667497]\n",
            "******* 3308 780 [D loss: 0.055502, acc: 99.22%] [G loss: 5.527952]\n",
            "******* 3309 780 [D loss: 0.005219, acc: 100.00%] [G loss: 6.735494]\n",
            "******* 3310 780 [D loss: 0.051015, acc: 97.66%] [G loss: 6.722822]\n",
            "******* 3311 780 [D loss: 0.140303, acc: 93.75%] [G loss: 5.934939]\n",
            "******* 3312 780 [D loss: 0.055838, acc: 97.66%] [G loss: 5.509626]\n",
            "******* 3313 780 [D loss: 0.031184, acc: 99.22%] [G loss: 5.062015]\n",
            "******* 3314 780 [D loss: 0.058433, acc: 97.66%] [G loss: 5.242665]\n",
            "******* 3315 780 [D loss: 0.062295, acc: 97.66%] [G loss: 5.444609]\n",
            "******* 3316 780 [D loss: 0.044216, acc: 97.66%] [G loss: 5.973271]\n",
            "******* 3317 780 [D loss: 0.026900, acc: 98.44%] [G loss: 6.682676]\n",
            "******* 3318 780 [D loss: 0.138983, acc: 95.31%] [G loss: 5.041241]\n",
            "******* 3319 780 [D loss: 0.184672, acc: 95.31%] [G loss: 4.289827]\n",
            "******* 3320 780 [D loss: 0.123156, acc: 92.97%] [G loss: 6.109649]\n",
            "******* 3321 780 [D loss: 0.070111, acc: 96.88%] [G loss: 7.472305]\n",
            "******* 3322 780 [D loss: 0.047081, acc: 97.66%] [G loss: 7.376171]\n",
            "******* 3323 780 [D loss: 0.163561, acc: 95.31%] [G loss: 5.041299]\n",
            "******* 3324 780 [D loss: 0.129040, acc: 96.09%] [G loss: 4.587233]\n",
            "******* 3325 780 [D loss: 0.038983, acc: 98.44%] [G loss: 7.616549]\n",
            "******* 3326 780 [D loss: 0.111955, acc: 96.09%] [G loss: 7.362550]\n",
            "******* 3327 780 [D loss: 0.285099, acc: 85.16%] [G loss: 2.503182]\n",
            "******* 3328 780 [D loss: 0.920924, acc: 75.78%] [G loss: 7.438451]\n",
            "******* 3329 780 [D loss: 0.229807, acc: 92.19%] [G loss: 11.490723]\n",
            "******* 3330 780 [D loss: 1.698011, acc: 67.19%] [G loss: 6.823942]\n",
            "******* 3331 780 [D loss: 0.490999, acc: 84.38%] [G loss: 2.530623]\n",
            "******* 3332 780 [D loss: 0.856098, acc: 68.75%] [G loss: 2.676937]\n",
            "******* 3333 780 [D loss: 0.194658, acc: 92.19%] [G loss: 4.471550]\n",
            "******* 3334 780 [D loss: 0.083585, acc: 96.88%] [G loss: 5.264638]\n",
            "******* 3335 780 [D loss: 0.205157, acc: 95.31%] [G loss: 5.962889]\n",
            "******* 3336 780 [D loss: 0.299899, acc: 89.06%] [G loss: 5.476443]\n",
            "******* 3337 780 [D loss: 0.151118, acc: 93.75%] [G loss: 4.723681]\n",
            "******* 3338 780 [D loss: 0.162499, acc: 95.31%] [G loss: 3.296721]\n",
            "******* 3339 780 [D loss: 0.357838, acc: 85.16%] [G loss: 3.542631]\n",
            "******* 3340 780 [D loss: 0.294359, acc: 89.84%] [G loss: 3.900977]\n",
            "******* 3341 780 [D loss: 0.069043, acc: 97.66%] [G loss: 4.668970]\n",
            "******* 3342 780 [D loss: 0.126142, acc: 92.97%] [G loss: 5.312223]\n",
            "******* 3343 780 [D loss: 0.325188, acc: 88.28%] [G loss: 4.712934]\n",
            "******* 3344 780 [D loss: 0.112278, acc: 94.53%] [G loss: 4.723091]\n",
            "******* 3345 780 [D loss: 0.226165, acc: 89.84%] [G loss: 3.663608]\n",
            "******* 3346 780 [D loss: 0.179259, acc: 92.97%] [G loss: 3.492716]\n",
            "******* 3347 780 [D loss: 0.178586, acc: 95.31%] [G loss: 3.431668]\n",
            "******* 3348 780 [D loss: 0.161925, acc: 93.75%] [G loss: 3.754265]\n",
            "******* 3349 780 [D loss: 0.093755, acc: 96.88%] [G loss: 4.066616]\n",
            "******* 3350 780 [D loss: 0.134079, acc: 96.09%] [G loss: 4.567160]\n",
            "******* 3351 780 [D loss: 0.136703, acc: 93.75%] [G loss: 3.526820]\n",
            "******* 3352 780 [D loss: 0.113895, acc: 96.88%] [G loss: 3.537383]\n",
            "******* 3353 780 [D loss: 0.073457, acc: 98.44%] [G loss: 3.757292]\n",
            "******* 3354 780 [D loss: 0.093088, acc: 97.66%] [G loss: 4.208995]\n",
            "******* 3355 780 [D loss: 0.097534, acc: 96.09%] [G loss: 5.217350]\n",
            "******* 3356 780 [D loss: 0.107472, acc: 96.09%] [G loss: 4.571207]\n",
            "******* 3357 780 [D loss: 0.161256, acc: 92.97%] [G loss: 4.880130]\n",
            "******* 3358 780 [D loss: 0.105576, acc: 96.88%] [G loss: 4.541994]\n",
            "******* 3359 780 [D loss: 0.115886, acc: 95.31%] [G loss: 4.708409]\n",
            "******* 3360 780 [D loss: 0.044869, acc: 98.44%] [G loss: 4.618566]\n",
            "******* 3361 780 [D loss: 0.061875, acc: 97.66%] [G loss: 4.993978]\n",
            "******* 3362 780 [D loss: 0.099027, acc: 96.88%] [G loss: 5.948917]\n",
            "******* 3363 780 [D loss: 0.050567, acc: 96.88%] [G loss: 6.115659]\n",
            "******* 3364 780 [D loss: 0.123500, acc: 95.31%] [G loss: 4.715915]\n",
            "******* 3365 780 [D loss: 0.047028, acc: 99.22%] [G loss: 4.269338]\n",
            "******* 3366 780 [D loss: 0.078406, acc: 97.66%] [G loss: 4.214963]\n",
            "******* 3367 780 [D loss: 0.047537, acc: 97.66%] [G loss: 4.970885]\n",
            "******* 3368 780 [D loss: 0.046618, acc: 99.22%] [G loss: 5.190176]\n",
            "******* 3369 780 [D loss: 0.083027, acc: 97.66%] [G loss: 5.487562]\n",
            "******* 3370 780 [D loss: 0.142499, acc: 94.53%] [G loss: 5.968825]\n",
            "******* 3371 780 [D loss: 0.142292, acc: 93.75%] [G loss: 5.383311]\n",
            "******* 3372 780 [D loss: 0.123057, acc: 94.53%] [G loss: 5.454554]\n",
            "******* 3373 780 [D loss: 0.226154, acc: 92.97%] [G loss: 4.313088]\n",
            "******* 3374 780 [D loss: 0.133316, acc: 94.53%] [G loss: 5.367862]\n",
            "******* 3375 780 [D loss: 0.103854, acc: 93.75%] [G loss: 6.137300]\n",
            "******* 3376 780 [D loss: 0.252995, acc: 92.97%] [G loss: 5.095558]\n",
            "******* 3377 780 [D loss: 0.117802, acc: 96.09%] [G loss: 4.266393]\n",
            "******* 3378 780 [D loss: 0.189650, acc: 91.41%] [G loss: 4.751132]\n",
            "******* 3379 780 [D loss: 0.112401, acc: 95.31%] [G loss: 5.679193]\n",
            "******* 3380 780 [D loss: 0.293000, acc: 91.41%] [G loss: 5.055064]\n",
            "******* 3381 780 [D loss: 0.212150, acc: 92.19%] [G loss: 4.470956]\n",
            "******* 3382 780 [D loss: 0.239100, acc: 89.84%] [G loss: 4.628974]\n",
            "******* 3383 780 [D loss: 0.129140, acc: 94.53%] [G loss: 4.865891]\n",
            "******* 3384 780 [D loss: 0.132309, acc: 93.75%] [G loss: 5.214998]\n",
            "******* 3385 780 [D loss: 0.143925, acc: 94.53%] [G loss: 4.897958]\n",
            "******* 3386 780 [D loss: 0.125786, acc: 94.53%] [G loss: 4.039004]\n",
            "******* 3387 780 [D loss: 0.115447, acc: 96.09%] [G loss: 5.032026]\n",
            "******* 3388 780 [D loss: 0.085718, acc: 96.09%] [G loss: 5.004193]\n",
            "******* 3389 780 [D loss: 0.098128, acc: 96.09%] [G loss: 3.745435]\n",
            "******* 3390 780 [D loss: 0.068439, acc: 96.88%] [G loss: 4.714416]\n",
            "******* 3391 780 [D loss: 0.058571, acc: 98.44%] [G loss: 5.892523]\n",
            "******* 3392 780 [D loss: 0.085304, acc: 97.66%] [G loss: 5.881831]\n",
            "******* 3393 780 [D loss: 0.153030, acc: 94.53%] [G loss: 4.770836]\n",
            "******* 3394 780 [D loss: 0.152782, acc: 94.53%] [G loss: 5.000074]\n",
            "******* 3395 780 [D loss: 0.085306, acc: 96.09%] [G loss: 5.821224]\n",
            "******* 3396 780 [D loss: 0.061579, acc: 97.66%] [G loss: 6.360492]\n",
            "******* 3397 780 [D loss: 0.064441, acc: 97.66%] [G loss: 5.924075]\n",
            "******* 3398 780 [D loss: 0.063588, acc: 97.66%] [G loss: 4.735906]\n",
            "******* 3399 780 [D loss: 0.107133, acc: 96.88%] [G loss: 4.968968]\n",
            "******* 3400 780 [D loss: 0.093159, acc: 95.31%] [G loss: 5.349679]\n",
            "******* 3401 780 [D loss: 0.053572, acc: 96.09%] [G loss: 6.309620]\n",
            "******* 3402 780 [D loss: 0.071528, acc: 96.88%] [G loss: 6.680618]\n",
            "******* 3403 780 [D loss: 0.129536, acc: 95.31%] [G loss: 3.967283]\n",
            "******* 3404 780 [D loss: 0.236259, acc: 90.62%] [G loss: 5.553470]\n",
            "******* 3405 780 [D loss: 0.068782, acc: 96.88%] [G loss: 7.685379]\n",
            "******* 3406 780 [D loss: 0.056670, acc: 98.44%] [G loss: 7.562270]\n",
            "******* 3407 780 [D loss: 0.124054, acc: 96.09%] [G loss: 6.218689]\n",
            "******* 3408 780 [D loss: 0.075205, acc: 96.09%] [G loss: 5.850374]\n",
            "******* 3409 780 [D loss: 0.101011, acc: 95.31%] [G loss: 5.673584]\n",
            "******* 3410 780 [D loss: 0.039103, acc: 98.44%] [G loss: 6.869082]\n",
            "******* 3411 780 [D loss: 0.085603, acc: 97.66%] [G loss: 8.411783]\n",
            "******* 3412 780 [D loss: 0.053012, acc: 97.66%] [G loss: 8.276126]\n",
            "******* 3413 780 [D loss: 0.026826, acc: 99.22%] [G loss: 7.867128]\n",
            "******* 3414 780 [D loss: 0.180713, acc: 92.97%] [G loss: 7.355057]\n",
            "******* 3415 780 [D loss: 0.069030, acc: 98.44%] [G loss: 6.734149]\n",
            "******* 3416 780 [D loss: 0.060897, acc: 97.66%] [G loss: 7.791609]\n",
            "******* 3417 780 [D loss: 0.131575, acc: 95.31%] [G loss: 7.888670]\n",
            "******* 3418 780 [D loss: 0.138500, acc: 95.31%] [G loss: 6.976779]\n",
            "******* 3419 780 [D loss: 0.105641, acc: 95.31%] [G loss: 6.668443]\n",
            "******* 3420 780 [D loss: 0.281112, acc: 88.28%] [G loss: 4.654058]\n",
            "******* 3421 780 [D loss: 0.194779, acc: 89.84%] [G loss: 5.386811]\n",
            "******* 3422 780 [D loss: 0.204380, acc: 95.31%] [G loss: 7.421222]\n",
            "******* 3423 780 [D loss: 0.291982, acc: 92.19%] [G loss: 6.842103]\n",
            "******* 3424 780 [D loss: 0.311970, acc: 90.62%] [G loss: 4.433469]\n",
            "******* 3425 780 [D loss: 0.231095, acc: 89.84%] [G loss: 5.253045]\n",
            "******* 3426 780 [D loss: 0.141872, acc: 96.09%] [G loss: 5.358358]\n",
            "******* 3427 780 [D loss: 0.267135, acc: 89.06%] [G loss: 5.310894]\n",
            "******* 3428 780 [D loss: 0.391583, acc: 89.84%] [G loss: 4.203805]\n",
            "******* 3429 780 [D loss: 0.386313, acc: 87.50%] [G loss: 4.935320]\n",
            "******* 3430 780 [D loss: 0.133739, acc: 95.31%] [G loss: 5.581287]\n",
            "******* 3431 780 [D loss: 0.257500, acc: 92.19%] [G loss: 4.465119]\n",
            "******* 3432 780 [D loss: 0.276057, acc: 89.84%] [G loss: 3.641810]\n",
            "******* 3433 780 [D loss: 0.196935, acc: 92.97%] [G loss: 3.026321]\n",
            "******* 3434 780 [D loss: 0.170091, acc: 94.53%] [G loss: 3.625566]\n",
            "******* 3435 780 [D loss: 0.139496, acc: 93.75%] [G loss: 4.392393]\n",
            "******* 3436 780 [D loss: 0.091251, acc: 96.88%] [G loss: 4.532743]\n",
            "******* 3437 780 [D loss: 0.133267, acc: 96.88%] [G loss: 4.548814]\n",
            "******* 3438 780 [D loss: 0.121325, acc: 96.09%] [G loss: 4.609457]\n",
            "******* 3439 780 [D loss: 0.087542, acc: 96.09%] [G loss: 4.132306]\n",
            "******* 3440 780 [D loss: 0.084728, acc: 96.09%] [G loss: 4.409362]\n",
            "******* 3441 780 [D loss: 0.073813, acc: 96.88%] [G loss: 4.624667]\n",
            "******* 3442 780 [D loss: 0.049971, acc: 99.22%] [G loss: 4.906220]\n",
            "******* 3443 780 [D loss: 0.081463, acc: 96.88%] [G loss: 4.824976]\n",
            "******* 3444 780 [D loss: 0.063434, acc: 97.66%] [G loss: 5.120884]\n",
            "******* 3445 780 [D loss: 0.059917, acc: 98.44%] [G loss: 4.758306]\n",
            "******* 3446 780 [D loss: 0.072347, acc: 97.66%] [G loss: 4.765622]\n",
            "******* 3447 780 [D loss: 0.058484, acc: 98.44%] [G loss: 4.587953]\n",
            "******* 3448 780 [D loss: 0.052903, acc: 98.44%] [G loss: 4.980322]\n",
            "******* 3449 780 [D loss: 0.057839, acc: 97.66%] [G loss: 5.291053]\n",
            "******* 3450 780 [D loss: 0.066643, acc: 97.66%] [G loss: 4.799818]\n",
            "******* 3451 780 [D loss: 0.077353, acc: 97.66%] [G loss: 4.283764]\n",
            "******* 3452 780 [D loss: 0.102631, acc: 96.09%] [G loss: 4.762582]\n",
            "******* 3453 780 [D loss: 0.052264, acc: 99.22%] [G loss: 5.022072]\n",
            "******* 3454 780 [D loss: 0.048051, acc: 98.44%] [G loss: 5.233875]\n",
            "******* 3455 780 [D loss: 0.035779, acc: 99.22%] [G loss: 5.396697]\n",
            "******* 3456 780 [D loss: 0.053245, acc: 97.66%] [G loss: 5.459880]\n",
            "******* 3457 780 [D loss: 0.101212, acc: 93.75%] [G loss: 4.408965]\n",
            "******* 3458 780 [D loss: 0.093052, acc: 95.31%] [G loss: 4.406274]\n",
            "******* 3459 780 [D loss: 0.091895, acc: 97.66%] [G loss: 4.706981]\n",
            "******* 3460 780 [D loss: 0.040913, acc: 98.44%] [G loss: 5.271772]\n",
            "******* 3461 780 [D loss: 0.103603, acc: 96.88%] [G loss: 5.993539]\n",
            "******* 3462 780 [D loss: 0.110541, acc: 96.88%] [G loss: 4.611384]\n",
            "******* 3463 780 [D loss: 0.137063, acc: 96.09%] [G loss: 4.329885]\n",
            "******* 3464 780 [D loss: 0.079439, acc: 96.09%] [G loss: 4.933041]\n",
            "******* 3465 780 [D loss: 0.138898, acc: 94.53%] [G loss: 5.089448]\n",
            "******* 3466 780 [D loss: 0.224845, acc: 89.84%] [G loss: 3.823458]\n",
            "******* 3467 780 [D loss: 0.160424, acc: 92.97%] [G loss: 3.792111]\n",
            "******* 3468 780 [D loss: 0.111791, acc: 96.09%] [G loss: 4.077483]\n",
            "******* 3469 780 [D loss: 0.111988, acc: 96.09%] [G loss: 5.368285]\n",
            "******* 3470 780 [D loss: 0.085823, acc: 96.09%] [G loss: 5.606822]\n",
            "******* 3471 780 [D loss: 0.087256, acc: 97.66%] [G loss: 5.513021]\n",
            "******* 3472 780 [D loss: 0.097584, acc: 96.88%] [G loss: 4.538513]\n",
            "******* 3473 780 [D loss: 0.199448, acc: 92.97%] [G loss: 4.826058]\n",
            "******* 3474 780 [D loss: 0.080261, acc: 96.88%] [G loss: 6.021262]\n",
            "******* 3475 780 [D loss: 0.116009, acc: 94.53%] [G loss: 6.061319]\n",
            "******* 3476 780 [D loss: 0.132364, acc: 92.19%] [G loss: 6.270275]\n",
            "******* 3477 780 [D loss: 0.085357, acc: 97.66%] [G loss: 5.469517]\n",
            "******* 3478 780 [D loss: 0.106197, acc: 95.31%] [G loss: 4.944253]\n",
            "******* 3479 780 [D loss: 0.226280, acc: 92.19%] [G loss: 5.608339]\n",
            "******* 3480 780 [D loss: 0.053988, acc: 98.44%] [G loss: 6.568427]\n",
            "******* 3481 780 [D loss: 0.163838, acc: 93.75%] [G loss: 5.696473]\n",
            "******* 3482 780 [D loss: 0.162205, acc: 94.53%] [G loss: 4.798032]\n",
            "******* 3483 780 [D loss: 0.228069, acc: 92.97%] [G loss: 4.812643]\n",
            "******* 3484 780 [D loss: 0.074276, acc: 98.44%] [G loss: 5.592804]\n",
            "******* 3485 780 [D loss: 0.015752, acc: 100.00%] [G loss: 6.113369]\n",
            "******* 3486 780 [D loss: 0.087025, acc: 95.31%] [G loss: 5.753529]\n",
            "******* 3487 780 [D loss: 0.286264, acc: 90.62%] [G loss: 4.249206]\n",
            "******* 3488 780 [D loss: 0.145984, acc: 93.75%] [G loss: 3.519765]\n",
            "******* 3489 780 [D loss: 0.099776, acc: 96.09%] [G loss: 4.612811]\n",
            "******* 3490 780 [D loss: 0.122514, acc: 95.31%] [G loss: 5.182912]\n",
            "******* 3491 780 [D loss: 0.069543, acc: 97.66%] [G loss: 5.670933]\n",
            "******* 3492 780 [D loss: 0.101928, acc: 95.31%] [G loss: 5.017849]\n",
            "******* 3493 780 [D loss: 0.030631, acc: 99.22%] [G loss: 5.032132]\n",
            "******* 3494 780 [D loss: 0.093288, acc: 96.88%] [G loss: 5.497636]\n",
            "******* 3495 780 [D loss: 0.073082, acc: 97.66%] [G loss: 5.983004]\n",
            "******* 3496 780 [D loss: 0.049097, acc: 98.44%] [G loss: 5.694743]\n",
            "******* 3497 780 [D loss: 0.119358, acc: 96.09%] [G loss: 5.130061]\n",
            "******* 3498 780 [D loss: 0.084828, acc: 96.88%] [G loss: 3.947592]\n",
            "******* 3499 780 [D loss: 0.175124, acc: 91.41%] [G loss: 5.325089]\n",
            "******* 3500 780 [D loss: 0.163654, acc: 94.53%] [G loss: 7.072953]\n",
            "******* 3501 780 [D loss: 0.216131, acc: 92.97%] [G loss: 5.701691]\n",
            "******* 3502 780 [D loss: 0.101612, acc: 96.09%] [G loss: 4.189541]\n",
            "******* 3503 780 [D loss: 0.200485, acc: 92.19%] [G loss: 5.048040]\n",
            "******* 3504 780 [D loss: 0.116931, acc: 94.53%] [G loss: 6.056650]\n",
            "******* 3505 780 [D loss: 0.198515, acc: 94.53%] [G loss: 5.245099]\n",
            "******* 3506 780 [D loss: 0.149138, acc: 94.53%] [G loss: 3.762588]\n",
            "******* 3507 780 [D loss: 0.229580, acc: 91.41%] [G loss: 4.892746]\n",
            "******* 3508 780 [D loss: 0.152045, acc: 93.75%] [G loss: 5.321757]\n",
            "******* 3509 780 [D loss: 0.129158, acc: 94.53%] [G loss: 4.457449]\n",
            "******* 3510 780 [D loss: 0.133364, acc: 94.53%] [G loss: 3.788270]\n",
            "******* 3511 780 [D loss: 0.145716, acc: 93.75%] [G loss: 3.654851]\n",
            "******* 3512 780 [D loss: 0.170601, acc: 92.19%] [G loss: 3.827156]\n",
            "******* 3513 780 [D loss: 0.097126, acc: 96.88%] [G loss: 4.244492]\n",
            "******* 3514 780 [D loss: 0.165342, acc: 93.75%] [G loss: 4.178492]\n",
            "******* 3515 780 [D loss: 0.146024, acc: 93.75%] [G loss: 4.006131]\n",
            "******* 3516 780 [D loss: 0.070401, acc: 99.22%] [G loss: 3.951100]\n",
            "******* 3517 780 [D loss: 0.044886, acc: 99.22%] [G loss: 4.564479]\n",
            "******* 3518 780 [D loss: 0.069746, acc: 96.88%] [G loss: 4.805371]\n",
            "******* 3519 780 [D loss: 0.102127, acc: 94.53%] [G loss: 5.136968]\n",
            "******* 3520 780 [D loss: 0.079960, acc: 99.22%] [G loss: 5.103389]\n",
            "******* 3521 780 [D loss: 0.016061, acc: 100.00%] [G loss: 4.944161]\n",
            "******* 3522 780 [D loss: 0.035638, acc: 99.22%] [G loss: 5.856770]\n",
            "******* 3523 780 [D loss: 0.129468, acc: 96.88%] [G loss: 5.249490]\n",
            "******* 3524 780 [D loss: 0.106066, acc: 96.09%] [G loss: 4.592367]\n",
            "******* 3525 780 [D loss: 0.080951, acc: 98.44%] [G loss: 4.287732]\n",
            "******* 3526 780 [D loss: 0.074108, acc: 98.44%] [G loss: 4.894698]\n",
            "******* 3527 780 [D loss: 0.145186, acc: 95.31%] [G loss: 6.066224]\n",
            "******* 3528 780 [D loss: 0.090223, acc: 95.31%] [G loss: 5.383091]\n",
            "******* 3529 780 [D loss: 0.057288, acc: 97.66%] [G loss: 5.606781]\n",
            "******* 3530 780 [D loss: 0.043902, acc: 97.66%] [G loss: 5.599178]\n",
            "******* 3531 780 [D loss: 0.148072, acc: 95.31%] [G loss: 4.514899]\n",
            "******* 3532 780 [D loss: 0.050793, acc: 97.66%] [G loss: 4.920997]\n",
            "******* 3533 780 [D loss: 0.045730, acc: 98.44%] [G loss: 5.248039]\n",
            "******* 3534 780 [D loss: 0.062702, acc: 96.88%] [G loss: 5.254488]\n",
            "******* 3535 780 [D loss: 0.102393, acc: 96.09%] [G loss: 5.324771]\n",
            "******* 3536 780 [D loss: 0.103578, acc: 96.88%] [G loss: 4.234472]\n",
            "******* 3537 780 [D loss: 0.144996, acc: 92.97%] [G loss: 4.196206]\n",
            "******* 3538 780 [D loss: 0.030166, acc: 100.00%] [G loss: 5.343891]\n",
            "******* 3539 780 [D loss: 0.028608, acc: 99.22%] [G loss: 6.493007]\n",
            "******* 3540 780 [D loss: 0.068685, acc: 98.44%] [G loss: 5.463122]\n",
            "******* 3541 780 [D loss: 0.086017, acc: 96.88%] [G loss: 5.605389]\n",
            "******* 3542 780 [D loss: 0.064225, acc: 96.88%] [G loss: 5.417862]\n",
            "******* 3543 780 [D loss: 0.056772, acc: 98.44%] [G loss: 5.343557]\n",
            "******* 3544 780 [D loss: 0.085710, acc: 96.88%] [G loss: 5.945753]\n",
            "******* 3545 780 [D loss: 0.152246, acc: 94.53%] [G loss: 4.718529]\n",
            "******* 3546 780 [D loss: 0.064972, acc: 98.44%] [G loss: 4.903941]\n",
            "******* 3547 780 [D loss: 0.110807, acc: 96.09%] [G loss: 5.874656]\n",
            "******* 3548 780 [D loss: 0.074596, acc: 97.66%] [G loss: 5.788441]\n",
            "******* 3549 780 [D loss: 0.075765, acc: 97.66%] [G loss: 5.184342]\n",
            "******* 3550 780 [D loss: 0.127153, acc: 94.53%] [G loss: 5.103421]\n",
            "******* 3551 780 [D loss: 0.105636, acc: 97.66%] [G loss: 5.866223]\n",
            "******* 3552 780 [D loss: 0.113596, acc: 94.53%] [G loss: 6.036691]\n",
            "******* 3553 780 [D loss: 0.247215, acc: 95.31%] [G loss: 5.487062]\n",
            "******* 3554 780 [D loss: 0.339407, acc: 88.28%] [G loss: 4.615968]\n",
            "******* 3555 780 [D loss: 0.037032, acc: 97.66%] [G loss: 5.292964]\n",
            "******* 3556 780 [D loss: 0.218239, acc: 91.41%] [G loss: 4.227392]\n",
            "******* 3557 780 [D loss: 0.254944, acc: 90.62%] [G loss: 4.875767]\n",
            "******* 3558 780 [D loss: 0.122206, acc: 94.53%] [G loss: 5.881440]\n",
            "******* 3559 780 [D loss: 0.167608, acc: 91.41%] [G loss: 4.941713]\n",
            "******* 3560 780 [D loss: 0.177560, acc: 94.53%] [G loss: 3.745095]\n",
            "******* 3561 780 [D loss: 0.201313, acc: 90.62%] [G loss: 3.463723]\n",
            "******* 3562 780 [D loss: 0.106923, acc: 95.31%] [G loss: 4.711893]\n",
            "******* 3563 780 [D loss: 0.171670, acc: 92.97%] [G loss: 4.084987]\n",
            "******* 3564 780 [D loss: 0.428944, acc: 78.91%] [G loss: 3.793142]\n",
            "******* 3565 780 [D loss: 0.112345, acc: 96.09%] [G loss: 4.552391]\n",
            "******* 3566 780 [D loss: 0.299570, acc: 86.72%] [G loss: 4.212145]\n",
            "******* 3567 780 [D loss: 0.206581, acc: 88.28%] [G loss: 3.661109]\n",
            "******* 3568 780 [D loss: 0.364296, acc: 85.94%] [G loss: 3.420981]\n",
            "******* 3569 780 [D loss: 0.222651, acc: 91.41%] [G loss: 4.169528]\n",
            "******* 3570 780 [D loss: 0.175190, acc: 94.53%] [G loss: 4.552145]\n",
            "******* 3571 780 [D loss: 0.169504, acc: 93.75%] [G loss: 3.760624]\n",
            "******* 3572 780 [D loss: 0.229158, acc: 89.06%] [G loss: 3.581316]\n",
            "******* 3573 780 [D loss: 0.277157, acc: 89.06%] [G loss: 4.138389]\n",
            "******* 3574 780 [D loss: 0.108085, acc: 96.09%] [G loss: 4.988777]\n",
            "******* 3575 780 [D loss: 0.190895, acc: 91.41%] [G loss: 4.153789]\n",
            "******* 3576 780 [D loss: 0.094608, acc: 96.88%] [G loss: 3.203888]\n",
            "******* 3577 780 [D loss: 0.233689, acc: 89.84%] [G loss: 3.079905]\n",
            "******* 3578 780 [D loss: 0.096394, acc: 94.53%] [G loss: 4.515471]\n",
            "******* 3579 780 [D loss: 0.048317, acc: 98.44%] [G loss: 5.363245]\n",
            "******* 3580 780 [D loss: 0.089703, acc: 95.31%] [G loss: 5.205623]\n",
            "******* 3581 780 [D loss: 0.139918, acc: 92.97%] [G loss: 4.130304]\n",
            "******* 3582 780 [D loss: 0.145718, acc: 94.53%] [G loss: 4.429896]\n",
            "******* 3583 780 [D loss: 0.155378, acc: 94.53%] [G loss: 5.405335]\n",
            "******* 3584 780 [D loss: 0.146720, acc: 94.53%] [G loss: 5.641010]\n",
            "******* 3585 780 [D loss: 0.082668, acc: 94.53%] [G loss: 4.841089]\n",
            "******* 3586 780 [D loss: 0.063206, acc: 97.66%] [G loss: 4.096836]\n",
            "******* 3587 780 [D loss: 0.065371, acc: 96.88%] [G loss: 4.507363]\n",
            "******* 3588 780 [D loss: 0.052129, acc: 98.44%] [G loss: 4.755845]\n",
            "******* 3589 780 [D loss: 0.043209, acc: 98.44%] [G loss: 5.839419]\n",
            "******* 3590 780 [D loss: 0.043193, acc: 98.44%] [G loss: 5.421695]\n",
            "******* 3591 780 [D loss: 0.048768, acc: 97.66%] [G loss: 5.326514]\n",
            "******* 3592 780 [D loss: 0.073561, acc: 96.88%] [G loss: 5.327917]\n",
            "******* 3593 780 [D loss: 0.024210, acc: 100.00%] [G loss: 5.663879]\n",
            "******* 3594 780 [D loss: 0.068820, acc: 97.66%] [G loss: 5.766958]\n",
            "******* 3595 780 [D loss: 0.035774, acc: 97.66%] [G loss: 6.384712]\n",
            "******* 3596 780 [D loss: 0.123476, acc: 94.53%] [G loss: 4.558605]\n",
            "******* 3597 780 [D loss: 0.197955, acc: 91.41%] [G loss: 6.247687]\n",
            "******* 3598 780 [D loss: 0.200260, acc: 93.75%] [G loss: 7.087363]\n",
            "******* 3599 780 [D loss: 0.298287, acc: 89.84%] [G loss: 5.389254]\n",
            "******* 3600 780 [D loss: 0.201681, acc: 92.97%] [G loss: 4.278030]\n",
            "******* 3601 780 [D loss: 0.341106, acc: 87.50%] [G loss: 4.994497]\n",
            "******* 3602 780 [D loss: 0.286191, acc: 94.53%] [G loss: 6.087135]\n",
            "******* 3603 780 [D loss: 0.287672, acc: 89.06%] [G loss: 4.419462]\n",
            "******* 3604 780 [D loss: 0.245505, acc: 85.94%] [G loss: 5.233667]\n",
            "******* 3605 780 [D loss: 0.122485, acc: 94.53%] [G loss: 5.893569]\n",
            "******* 3606 780 [D loss: 0.195870, acc: 92.19%] [G loss: 4.922849]\n",
            "******* 3607 780 [D loss: 0.046651, acc: 98.44%] [G loss: 4.607909]\n",
            "******* 3608 780 [D loss: 0.152825, acc: 94.53%] [G loss: 5.130712]\n",
            "******* 3609 780 [D loss: 0.121262, acc: 95.31%] [G loss: 5.393147]\n",
            "******* 3610 780 [D loss: 0.070368, acc: 96.88%] [G loss: 6.042430]\n",
            "******* 3611 780 [D loss: 0.087221, acc: 96.09%] [G loss: 6.633510]\n",
            "******* 3612 780 [D loss: 0.080598, acc: 95.31%] [G loss: 5.454496]\n",
            "******* 3613 780 [D loss: 0.079825, acc: 96.09%] [G loss: 4.750165]\n",
            "******* 3614 780 [D loss: 0.103707, acc: 95.31%] [G loss: 5.178246]\n",
            "******* 3615 780 [D loss: 0.168892, acc: 95.31%] [G loss: 5.732146]\n",
            "******* 3616 780 [D loss: 0.150735, acc: 94.53%] [G loss: 6.342320]\n",
            "******* 3617 780 [D loss: 0.147446, acc: 96.09%] [G loss: 5.608954]\n",
            "******* 3618 780 [D loss: 0.131164, acc: 96.09%] [G loss: 4.696038]\n",
            "******* 3619 780 [D loss: 0.314370, acc: 86.72%] [G loss: 3.878020]\n",
            "******* 3620 780 [D loss: 0.107023, acc: 95.31%] [G loss: 4.388640]\n",
            "******* 3621 780 [D loss: 0.200189, acc: 92.97%] [G loss: 5.182227]\n",
            "******* 3622 780 [D loss: 0.371121, acc: 85.94%] [G loss: 3.681747]\n",
            "******* 3623 780 [D loss: 0.341238, acc: 83.59%] [G loss: 3.027998]\n",
            "******* 3624 780 [D loss: 0.160806, acc: 92.19%] [G loss: 3.577854]\n",
            "******* 3625 780 [D loss: 0.149770, acc: 92.97%] [G loss: 4.092031]\n",
            "******* 3626 780 [D loss: 0.151731, acc: 92.19%] [G loss: 3.728349]\n",
            "******* 3627 780 [D loss: 0.158546, acc: 92.97%] [G loss: 3.580890]\n",
            "******* 3628 780 [D loss: 0.173246, acc: 92.97%] [G loss: 2.976911]\n",
            "******* 3629 780 [D loss: 0.101045, acc: 99.22%] [G loss: 3.358236]\n",
            "******* 3630 780 [D loss: 0.124639, acc: 95.31%] [G loss: 4.107877]\n",
            "******* 3631 780 [D loss: 0.107973, acc: 96.09%] [G loss: 4.346016]\n",
            "******* 3632 780 [D loss: 0.079804, acc: 97.66%] [G loss: 4.659064]\n",
            "******* 3633 780 [D loss: 0.063017, acc: 97.66%] [G loss: 4.135228]\n",
            "******* 3634 780 [D loss: 0.062418, acc: 98.44%] [G loss: 4.043038]\n",
            "******* 3635 780 [D loss: 0.039876, acc: 100.00%] [G loss: 4.141029]\n",
            "******* 3636 780 [D loss: 0.094354, acc: 96.88%] [G loss: 4.751148]\n",
            "******* 3637 780 [D loss: 0.053825, acc: 98.44%] [G loss: 5.562716]\n",
            "******* 3638 780 [D loss: 0.036606, acc: 98.44%] [G loss: 6.059964]\n",
            "******* 3639 780 [D loss: 0.059974, acc: 98.44%] [G loss: 5.423089]\n",
            "******* 3640 780 [D loss: 0.042216, acc: 98.44%] [G loss: 5.236849]\n",
            "******* 3641 780 [D loss: 0.074729, acc: 96.88%] [G loss: 4.742382]\n",
            "******* 3642 780 [D loss: 0.067484, acc: 97.66%] [G loss: 5.036980]\n",
            "******* 3643 780 [D loss: 0.026251, acc: 99.22%] [G loss: 6.377101]\n",
            "******* 3644 780 [D loss: 0.128980, acc: 94.53%] [G loss: 5.526448]\n",
            "******* 3645 780 [D loss: 0.047240, acc: 99.22%] [G loss: 5.275214]\n",
            "******* 3646 780 [D loss: 0.078342, acc: 97.66%] [G loss: 5.046475]\n",
            "******* 3647 780 [D loss: 0.064060, acc: 97.66%] [G loss: 6.179599]\n",
            "******* 3648 780 [D loss: 0.079720, acc: 97.66%] [G loss: 5.527945]\n",
            "******* 3649 780 [D loss: 0.060114, acc: 97.66%] [G loss: 5.801357]\n",
            "******* 3650 780 [D loss: 0.132925, acc: 94.53%] [G loss: 4.516073]\n",
            "******* 3651 780 [D loss: 0.055785, acc: 98.44%] [G loss: 5.640620]\n",
            "******* 3652 780 [D loss: 0.107197, acc: 96.88%] [G loss: 6.734210]\n",
            "******* 3653 780 [D loss: 0.100236, acc: 95.31%] [G loss: 6.495369]\n",
            "******* 3654 780 [D loss: 0.121351, acc: 95.31%] [G loss: 5.324953]\n",
            "******* 3655 780 [D loss: 0.159216, acc: 93.75%] [G loss: 6.638412]\n",
            "******* 3656 780 [D loss: 0.090716, acc: 96.88%] [G loss: 8.752086]\n",
            "******* 3657 780 [D loss: 0.191396, acc: 94.53%] [G loss: 7.820882]\n",
            "******* 3658 780 [D loss: 0.072767, acc: 97.66%] [G loss: 6.134275]\n",
            "******* 3659 780 [D loss: 0.141628, acc: 95.31%] [G loss: 4.950508]\n",
            "******* 3660 780 [D loss: 0.086670, acc: 96.09%] [G loss: 5.622261]\n",
            "******* 3661 780 [D loss: 0.038321, acc: 98.44%] [G loss: 7.196016]\n",
            "******* 3662 780 [D loss: 0.044963, acc: 98.44%] [G loss: 7.348305]\n",
            "******* 3663 780 [D loss: 0.035471, acc: 99.22%] [G loss: 7.668878]\n",
            "******* 3664 780 [D loss: 0.056437, acc: 97.66%] [G loss: 7.439868]\n",
            "******* 3665 780 [D loss: 0.012355, acc: 100.00%] [G loss: 6.772820]\n",
            "******* 3666 780 [D loss: 0.077890, acc: 99.22%] [G loss: 5.837052]\n",
            "******* 3667 780 [D loss: 0.153654, acc: 92.97%] [G loss: 5.600689]\n",
            "******* 3668 780 [D loss: 0.093160, acc: 96.88%] [G loss: 7.120811]\n",
            "******* 3669 780 [D loss: 0.052756, acc: 98.44%] [G loss: 7.037226]\n",
            "******* 3670 780 [D loss: 0.156620, acc: 93.75%] [G loss: 4.697924]\n",
            "******* 3671 780 [D loss: 0.169103, acc: 92.19%] [G loss: 5.573610]\n",
            "******* 3672 780 [D loss: 0.061013, acc: 96.88%] [G loss: 7.029171]\n",
            "******* 3673 780 [D loss: 0.139291, acc: 93.75%] [G loss: 5.430627]\n",
            "******* 3674 780 [D loss: 0.193288, acc: 92.97%] [G loss: 4.100327]\n",
            "******* 3675 780 [D loss: 0.043420, acc: 99.22%] [G loss: 4.943511]\n",
            "******* 3676 780 [D loss: 0.054515, acc: 97.66%] [G loss: 5.348214]\n",
            "******* 3677 780 [D loss: 0.056159, acc: 97.66%] [G loss: 5.290195]\n",
            "******* 3678 780 [D loss: 0.102398, acc: 96.09%] [G loss: 5.447961]\n",
            "******* 3679 780 [D loss: 0.064702, acc: 96.09%] [G loss: 5.001554]\n",
            "******* 3680 780 [D loss: 0.066211, acc: 98.44%] [G loss: 5.115158]\n",
            "******* 3681 780 [D loss: 0.079018, acc: 97.66%] [G loss: 5.233407]\n",
            "******* 3682 780 [D loss: 0.094104, acc: 94.53%] [G loss: 5.269388]\n",
            "******* 3683 780 [D loss: 0.155457, acc: 93.75%] [G loss: 4.473139]\n",
            "******* 3684 780 [D loss: 0.062645, acc: 97.66%] [G loss: 5.181128]\n",
            "******* 3685 780 [D loss: 0.105806, acc: 96.09%] [G loss: 5.277050]\n",
            "******* 3686 780 [D loss: 0.101106, acc: 96.88%] [G loss: 4.511627]\n",
            "******* 3687 780 [D loss: 0.209158, acc: 92.19%] [G loss: 4.083930]\n",
            "******* 3688 780 [D loss: 0.055582, acc: 96.88%] [G loss: 5.952622]\n",
            "******* 3689 780 [D loss: 0.170363, acc: 96.09%] [G loss: 5.585323]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-28416c689e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-28416c689e4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#inverse y label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"******* %d %d [D loss: %f, acc: %.2f%%] [G loss: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                                     class_weight)\n\u001b[1;32m   1899\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9wDLeRLUOB"
      },
      "source": [
        "noise = np.random.normal(0, 1, (1,latent_dim))\n",
        "gen_imgs = generator.predict(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rlgu8g9Lik9"
      },
      "source": [
        "gen_imgs = (gen_imgs + 1) / 2.0\n",
        "plt.imshow(gen_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-jSQoN1Azl"
      },
      "source": [
        "### **8) Making GIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPShgQpg1EMy"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "# def display_image(epoch_no):\n",
        "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('generated_images/*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}